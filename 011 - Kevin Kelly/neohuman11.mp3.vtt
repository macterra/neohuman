WEBVTT

00:00.000 --> 00:03.340
The way I put this is at Vanity Trump's privacy.

00:03.340 --> 00:14.840
Hello, and welcome to the 11th episode of Neohuman Podcast.

00:14.840 --> 00:20.740
I'm Agha Bahari, at Agologist on Twitter and Instagram, and you can follow the show on

00:20.740 --> 00:25.360
liveonlimbo.com, iTunes, and soon on YouTube.

00:25.360 --> 00:30.840
With me today is Kevin Kelly. Kevin is a founding executive editor of Wired Magazine and a former

00:30.840 --> 00:35.000
editor publisher of the Whole Earth Review. Welcome to Neohuman Podcast, Kevin.

00:35.000 --> 00:36.880
It's my pleasure to be here.

00:36.880 --> 00:40.420
Let's start with a little bit of your background, the works you've done, and what you're working

00:40.420 --> 00:41.920
on now these days.

00:41.920 --> 00:52.240
It's a long story. I'm a pretty old guy. Let me just start from the current. I just finished

00:52.240 --> 00:59.720
a book called The Inevitable, which is about the next 20 to 30 years, primarily in the

00:59.720 --> 01:08.760
digital technology space. I kind of outline what I think are going to be the inevitable

01:08.760 --> 01:15.200
changes, such as things as artificial intelligence and virtual reality, which are coming whether

01:15.200 --> 01:17.120
we want them or not.

01:17.120 --> 01:23.800
My take on these is that we should embrace these fully as a way to steer them and manage

01:23.800 --> 01:31.560
them. We can't prohibit them. We can't stop them. We can only put our arms around, immerse

01:31.560 --> 01:38.320
ourselves fully in them, and with use, try and steer them.

01:38.320 --> 01:43.320
What inspired you to write this book now? I was actually going to ask you about the book,

01:43.320 --> 01:48.280
but what tools do you use to see into the future, and what are the 12 technological forces

01:48.280 --> 01:53.760
that you think will shape our future? Let's begin with why you saw the necessity to write

01:53.760 --> 01:55.880
this book now at this time.

01:55.880 --> 02:07.280
The origins of the book, truthfully, started on my blog, where I began writing what seemed

02:07.280 --> 02:13.040
to me to be very obvious things that I think were difficult for other people to see, and

02:13.040 --> 02:20.200
an example would be the fact that the Internet is the world's largest copy machine. Anything

02:20.200 --> 02:24.480
that touches the Internet is going to be copied, no matter what it is. If it can be copied,

02:24.480 --> 02:30.520
it will be copied when it touches it, and yet people were trying to stop the copying,

02:30.520 --> 02:40.640
and so my understanding, my realization was that you can't stop the copying. Copying is

02:40.640 --> 02:47.360
just an inherent, inevitable part of the Internet, and anyone who's trying to prohibit copying

02:47.360 --> 02:56.360
or outlaw it or prevent it with copy protection stuff is just working against the grain, and

02:56.360 --> 03:01.120
what you want to do is you want to work with the grain. You want to work with the fact

03:01.120 --> 03:04.680
that the copies are going to be promiscuous, and they're going to be ubiquitous, and you

03:04.680 --> 03:09.560
have to kind of understand that, and you have to embrace the idea that the copies are ubiquitous.

03:09.560 --> 03:15.320
It also means that they become worthless, too, and so you have to therefore have an

03:15.320 --> 03:20.240
economy, your own business, based on some things that can't be copied, and those become

03:20.240 --> 03:25.240
the valuable. That's the kind of insight that I was writing about on my blog, and there

03:25.240 --> 03:28.960
are others, and I just felt that it would really be beneficial for people to kind of

03:28.960 --> 03:36.720
understand this, that we would, as a society as a whole, benefit from accepting these technologies,

03:36.720 --> 03:41.840
and even, individually, if you were in business, you would also benefit. The origins of the

03:41.840 --> 03:48.440
book was trying to convey some basic notions of how technology works like that.

03:48.440 --> 03:53.320
Mm-hmm. What are the 12 technological forces, in your opinion?

03:53.320 --> 04:01.360
Yeah. In the book, I kind of gather these forces and give them a verb. They're actually

04:01.360 --> 04:13.680
technically a gerund. They're a constant motion. It ends ING, so there's screening, filtering,

04:13.680 --> 04:23.120
accessing, cognifying, things like that. I don't think we have time in this podcast

04:23.120 --> 04:32.040
to go through all 12 of them, and they're kind of larger umbrellas for other, they're

04:32.040 --> 04:38.720
not just 12 trends. There's 12 categories that I put these trends into, and they're

04:38.720 --> 04:42.320
somewhat arbitrary in the sense that they're a convenient way to organize things, but they're

04:42.320 --> 04:50.520
not really distinct trends. In fact, there's a great interdependency of them. Sharing is

04:50.520 --> 05:02.680
one of them. To share and to interact, interacting is another. Each of those encourage and empower

05:02.680 --> 05:08.720
the other. There's a deep interdependence of these forces, and so they're not even really

05:08.720 --> 05:14.080
that distinct. The things I cover, though, I cover artificial

05:14.080 --> 05:22.640
intelligence, and I cover what's coming in, the increase in interaction and interacting

05:22.640 --> 05:29.440
in virtual reality, and I cover tracking, which is the quantified self and the surveillance

05:29.440 --> 05:36.040
that we're going to be enduring. I would say the same thing about tracking, as I would

05:36.040 --> 05:42.480
say it by copying, which is that the Internet wants to track stuff. If you're touching the

05:42.480 --> 05:46.400
Internet, you're going to be tracked. If you're going into VR, we'll be tracked to an extent

05:46.400 --> 05:52.680
that has not been possible before. Everything that you do in VR will be tracked.

05:52.680 --> 05:59.920
We can't stop tracking. People who are thinking that we're going to make laws or whatever

05:59.920 --> 06:05.200
to stop tracking are wrong. We're going to have more tracking. The thing to do is to

06:05.200 --> 06:13.640
work with tracking and to make the tracking work for us, make it civil, make it domesticated,

06:13.640 --> 06:17.400
make it symmetrical. There's many things that we have to do, but we're not going to stop

06:17.400 --> 06:22.720
the fact that 50 years from now, 30 years, whatever, most of our lives are going to be

06:22.720 --> 06:29.960
tracked in some capacity. How do we make that livable? How do we make that work? How do

06:29.960 --> 06:33.720
we steer that? How do we make that kind of tracking? It's going to be tracked, but what

06:33.720 --> 06:40.240
kind of tracking is not inevitable? That's the kinds of things that I cover.

06:40.240 --> 06:47.800
Excellent. You mentioned to adapt the change and change with it in a way. What comes to

06:47.800 --> 06:55.040
mind is that general public has always made the argument for privacy, that all these technologies

06:55.040 --> 07:00.000
are intruding our privacy, and that government is making an argument. We saw a very good

07:00.000 --> 07:09.840
example with Apple versus FBI case, the argument for security. How do you think these two will

07:09.840 --> 07:14.520
come maybe to some sort of a mutual understanding with the tech side of things and grow with

07:14.520 --> 07:19.520
it in the upcoming future? I don't think they come to a common understanding. I think this

07:19.520 --> 07:27.160
tension will be with us forever. One of the important things to understand is that there's

07:27.160 --> 07:32.120
a really, there's a big linkage between two dimensions. The one dimension is this sort

07:32.120 --> 07:41.240
of, we may call it the privacy. On one end of this dimension on this axis is privacy.

07:41.240 --> 07:46.840
On the other one would be transparency. In one sense, you are sharing information about

07:46.840 --> 07:52.680
yourself and that would be transparent. The other one is you share nothing. At the extreme

07:52.680 --> 08:01.560
end, you are the Unabomber, Ted Konzinski, living in a shack somewhere off the grid.

08:01.560 --> 08:07.440
You have no friends. You communicate with nobody. You're a loner. You're a hermit. Nobody

08:07.440 --> 08:13.540
knows anything about you. At the other end, you have somebody who is living in everything

08:13.540 --> 08:21.600
about them is their sharing, their thoughts, their oversharing, whatever it is. That's

08:21.600 --> 08:30.720
one dimension. But there's another axis that's actually linked to that. That linkage is personalization.

08:30.720 --> 08:38.680
At one end, you, at the extreme end, everything about you is personalized. Everything, you

08:38.680 --> 08:48.440
get customized, everything. Your clothes are customized. Your food is customized. Your

08:48.440 --> 08:56.880
medical attention is all personalized just to you. At the other end of that axis is generic.

08:56.880 --> 09:00.960
Nothing is personalized. You just get, you're just a number. You're treated just like an

09:00.960 --> 09:05.520
average person. Everything is, average is generic. Here, the thing is, the thing is,

09:05.520 --> 09:14.360
those two axis, the transparency and the personalization are linked so that the only way that you can

09:14.360 --> 09:20.560
get something personalized is that you have to reveal something about yourself. I want

09:20.560 --> 09:24.640
my friends to treat me as individual, and therefore, I have to open up and reveal myself

09:24.640 --> 09:28.960
to my friends. The only way that a company can give you some kind of personalized service

09:28.960 --> 09:35.280
is if they know something about you. Those two things are linked so that if we want to

09:35.280 --> 09:42.200
have maximum personalization, we have to have maximum transparency. If we don't want any

09:42.200 --> 09:49.920
kind of transparency, then the price is going to be, you can be treated as generic number,

09:49.920 --> 09:55.000
not as an individual. The surprise has, and so there's a little slider that you can go

09:55.000 --> 10:02.480
back and forth. I think we should have that choice. Here's the thing, and technology gives

10:02.480 --> 10:07.720
us those kind of choices. Whenever the surprise has been in the last 10 years, is that when

10:07.720 --> 10:13.880
people are given the choice to push the slider, they are pushing it to the personalized transparent

10:13.880 --> 10:24.440
side. The way I put this is that vanity trumps privacy. People would much, in other words,

10:24.440 --> 10:32.040
are saying, treat me as an individual, personalized. I am unique. I am special. I'm not a number.

10:32.040 --> 10:39.280
The cost of that is being transparent and then people say, fine. The other end of like,

10:39.280 --> 10:43.240
I don't want anybody to know anything about me and just treat me as a number. Not so many

10:43.240 --> 10:54.840
people are there. As we go into the future, the demands and the requirements of personalization

10:54.840 --> 10:59.600
will require and encourage people to be transparent.

10:59.600 --> 11:04.680
Do you think there will be aspect of, because Internet is coming out of the machines into

11:04.680 --> 11:09.880
the world that we call the real world as we are experiencing, right? With virtual reality

11:09.880 --> 11:16.800
and augmented reality. Do you think there will be aspect of it that will be an equivalent

11:16.800 --> 11:23.480
of deep web and dark net that people can do many different things, a lot of them illegal

11:23.480 --> 11:25.800
and at the same time stay anonymous?

11:25.800 --> 11:35.520
Yeah. I think anonymity has to remain as an option, but it should be discouraged as much

11:35.520 --> 11:43.520
as possible. You should keep it to the smallest amount. I liken it to a rare earth element

11:43.520 --> 11:49.440
if you have the periodic table of all the elements. There are some elements that are

11:49.440 --> 11:58.120
required by our cells biologically, so cadmium, arsenic. These are elements that we require

11:58.120 --> 12:04.080
trace amounts that are necessary, almost like vitamins, that are necessary to have our cells

12:04.080 --> 12:11.360
working. While they are necessary in very low amounts, in any significant amount, they're

12:11.360 --> 12:22.200
toxic. The same thing with anonymity. We have to allow that as a possibility for the very

12:22.200 --> 12:27.160
rare political persecution whistleblowers, but you want to keep it down to an absolute

12:27.160 --> 12:33.840
minimum. If you have a lot of rare earth metals in your body, you die. If you have a lot of

12:33.840 --> 12:42.680
anonymity on your website or your firm, you die. It's toxic. The uses of it are very,

12:42.680 --> 12:49.440
very rare, are very special. We have to have that option, but to use it on a daily basis

12:49.440 --> 13:03.360
is toxic. If you look at all the places where there's trolling, harassment, all this kind

13:03.360 --> 13:07.240
of stuff, it all comes from places where people are anonymous or pseudo-anonymous because

13:07.240 --> 13:15.480
it brings out the worst in people. We do need to have an option, but it should be really

13:15.480 --> 13:27.920
kept and worked hard to keep it to the exception, to the rare earth element level of 0.00%.

13:27.920 --> 13:32.360
It should be low. If there's a lot of anonymity, it's going to be toxic.

13:32.360 --> 13:37.360
Even without being anonymous, I think the best example would be the Microsoft bot that they

13:37.360 --> 13:42.440
put on Twitter and in 24 hours, it became into a monster basically.

13:42.440 --> 13:47.000
That's because Twitter is often anonymous. It has nothing to do with the bot. It has

13:47.000 --> 13:55.520
to do with the fact that Twitter allows anonymous accounts. It's the anonymity of Twitter that

13:55.520 --> 14:03.640
caused it, not the bots. You don't see actually what happened in China. China did the same

14:03.640 --> 14:08.480
thing. They had a bot that was programming, but because China requires you to have your

14:08.480 --> 14:15.200
identity, a verified identity, there wasn't that same problem.

14:15.200 --> 14:19.360
You're suggesting a system that has to verify your identity and it has to be a singular

14:19.360 --> 14:23.840
identity because now it's not. I can be something in this world and I can be a completely different

14:23.840 --> 14:30.520
person in let's say second life, but the world of second life is becoming more and more real.

14:30.520 --> 14:36.640
Will there be VR companies or places that you can go to as anonymous? Yes, but I can

14:36.640 --> 14:52.440
tell you right now that a lot of those places will be like 4chan. They won't be a very pleasant

14:52.440 --> 15:01.560
place to be. That's all I can say. They won't be a pleasant place to be. There's also pseudo

15:01.560 --> 15:07.240
anonymity, which is where you have a consistent, you don't have your real name, but you have

15:07.240 --> 15:18.200
a consistent identity that can be linked back if needed with some effort. Boar people try

15:18.200 --> 15:26.480
out different identities that can be linked back. Again, I think that we have to have

15:26.480 --> 15:35.760
that option, but if it reaches any sizable degree, it becomes toxic.

15:35.760 --> 15:43.320
To control those elements, essentially we need to regulate them again. What's the elements?

15:43.320 --> 15:51.200
You give a very good example that if you go to a virtual reality company and want to sign

15:51.200 --> 15:56.440
up with them, you definitely need to have an identity, but for that virtual reality

15:56.440 --> 16:01.600
company to be required to collect your identity, they need to be regulated by a bigger body

16:01.600 --> 16:10.640
of governance. I would imagine. No, I'm saying that. There's no government

16:10.640 --> 16:15.520
entity that requires Facebook to try and verify your identity. They're doing it for business

16:15.520 --> 16:25.360
reasons, is what I'm saying. Facebook, even now, requires that you be a real person. There's

16:25.360 --> 16:32.160
no government regulation to that. That's their decision. The same thing with the VR. It's

16:32.160 --> 16:35.880
I'm saying good business practice is going to dictate. If you want to have a place that

16:35.880 --> 16:42.440
people are going to be comfortable with, you are going to require identities. I think there

16:42.440 --> 16:48.720
will be, over time, just like Facebook's biggest asset, I believe, is their verified

16:48.720 --> 16:57.720
identity. Other companies will either try to recreate that or many have many ride on

16:57.720 --> 17:03.440
top of Facebook's verified identity. That becomes an extremely valuable thing because

17:03.440 --> 17:09.360
they realize that if they want to have a place that people are comfortable with, they can't

17:09.360 --> 17:13.240
have high anonymity. It's just toxic.

17:13.240 --> 17:19.800
Well, you would agree that there will be alternative words. Let's say alternative social medias

17:19.800 --> 17:25.960
that are based on anonymity and encryption. Because one side of it is that people like

17:25.960 --> 17:30.600
Edward Snowden are warning us that government is monitoring you and using your information

17:30.600 --> 17:34.760
for bad. Therefore, these are the tools that you have to say anonymous, to say encrypted

17:34.760 --> 17:39.120
and all of that. But at the same time, you're making a very good point that more anonymity

17:39.120 --> 17:44.560
will create more shadowy places that wrong kind of characters can.

17:44.560 --> 17:55.440
Yeah, encryption should not be confused with anonymity. A lot of the information that, say,

17:55.440 --> 18:01.640
flows back and forth between my computer and Facebook can be encrypted. Don't confuse encryption

18:01.640 --> 18:06.040
with anonymity. Those are two different things. They have some overlap in some cases, but

18:06.040 --> 18:12.000
they can be completely separate. My credit cards are encrypted, but they're

18:12.000 --> 18:23.640
not anonymous. First of all, we do want encryption everywhere. We're only talking about anonymity

18:23.640 --> 18:28.000
here, which is not the same as encryption. So don't confuse those two things.

18:28.000 --> 18:33.280
What do you think about Bitcoin? I think Bitcoin is really interesting. The thing about Bitcoin,

18:33.280 --> 18:38.360
of course, is that it's only one of a hundred different cryptocurrencies. The thing about

18:38.360 --> 18:42.120
the cryptocurrencies is that you can kind of engineer them in any way. Bitcoin happens

18:42.120 --> 18:50.480
to have anonymity engineered into that, but it doesn't have to be. You can have a version

18:50.480 --> 18:55.520
of a cryptocurrency that is not anonymous. I think that the anonymity of Bitcoins is

18:55.520 --> 19:00.080
completely distracting to its really fundamental breakthrough, which is the blockchain. So the

19:00.080 --> 19:09.920
blockchain is the real core thing. The anonymity is actually harmful to it in the long term,

19:09.920 --> 19:13.760
but the blockchain is the really brilliant technological innovation, which is a kind

19:13.760 --> 19:19.000
of a distributed accounting system. It's distributed trust. It's a way of distributing trust.

19:19.000 --> 19:24.120
I think actually in the long term that many governments will actually mandate blockchain

19:24.120 --> 19:29.920
technology without the anonymity in order to make a completely accountable economy where

19:29.920 --> 19:35.960
every single transaction is accounted for. Do you think the advancement of modern technology,

19:35.960 --> 19:43.200
it's been advancing quite crazily after the turn of the century, it will essentially and

19:43.200 --> 19:48.120
ultimately forces all the other aspects of society, economical, political, everything

19:48.120 --> 19:52.640
to change with it. So we need a new political system. We need a new economic system.

19:52.640 --> 20:00.280
Yeah, I think it's, you cannot use distributed peer to peer open source technology and not

20:00.280 --> 20:04.000
have it affect your politics eventually.

20:04.000 --> 20:10.400
You dropped out of college, if I'm correct, and backpacked around Asia taking photographs.

20:10.400 --> 20:14.400
Would you talk a little about the experience and also the experience of learning from life

20:14.400 --> 20:18.280
versus academic institutions?

20:18.280 --> 20:25.400
Yeah, I mean, I was sort of grew, came to age in the kind of the arrow of the hippies

20:25.400 --> 20:30.800
and I read the whole earth catalog, which said that you should invent your life. And

20:30.800 --> 20:38.400
I took that to heart. I was in high school, I kind of was an overachiever. I doubled up

20:38.400 --> 20:46.200
in math and science every year. And the problem with college, at least when I was there, my

20:46.200 --> 20:52.000
first year, it was grade 13, it was more the same sitting in a classroom and I just, you

20:52.000 --> 20:57.960
know, if they had had things like a gap year, or internships or something, but I needed

20:57.960 --> 21:06.000
to do something at that point. And the only alternative I had was basically to do it myself.

21:06.000 --> 21:14.040
So I dropped out and went to Asia as a photographer, which was a passion of mine at that point.

21:14.040 --> 21:20.560
And by the way, this was at a time when very few people had cameras. I tried to describe

21:20.560 --> 21:27.680
this to my kids where a family would have a little brownie camera and they would have

21:27.680 --> 21:33.280
a roll of film in it and they would get it developed. It would have like 24 exposures

21:33.280 --> 21:38.160
and they would get it developed and it would come back and there would be pictures of Easter,

21:38.160 --> 21:45.120
4th of July, and Halloween on the same roll. I remember those days.

21:45.120 --> 21:49.960
24 pictures for a year. Okay. So that, you know, the average family might have taken

21:49.960 --> 22:00.480
24 pictures in a year. And so I had a camera and I filled my backpack with 500 rolls of

22:00.480 --> 22:09.920
film, which was, you know, been saving up for forever to buy, almost no clothes. And

22:09.920 --> 22:16.240
I would take, I would shoot two rolls a day. That was 70 pictures and I would come back

22:16.240 --> 22:21.640
and I would tell people that I shot two rolls of film and their eyes would bug out. That

22:21.640 --> 22:29.160
would just be unbelievable. 70 pictures in one day. What are you shooting?

22:29.160 --> 22:36.760
So I was often the only person with a camera within 100 miles in different parts of Asia.

22:36.760 --> 22:46.280
So that's what I did and what I got from that was I experienced a whole continent basically

22:46.280 --> 22:55.800
that was in transformation. But when I arrived in places like Afghanistan or Nepal, I had

22:55.800 --> 23:00.720
arrived in a time machine. I had gotten into a time machine and I traveled back to the

23:00.720 --> 23:10.000
1500s. I landed there and it was in every respect, the 1500s. The, I mean, their lives

23:10.000 --> 23:18.320
had not changed the feudal mindset, the feudal culture. There was no metal. There was, I

23:18.320 --> 23:22.720
mean, every, there was no electricity. There was no TV. There was no radio. I mean, there

23:22.720 --> 23:31.280
was, it was 1500s. And so I had the experience of living in the past in a real way in these

23:31.280 --> 23:38.760
cultures. And so when I, when came out of that into, you know, the capital cities and

23:38.760 --> 23:46.080
back to the US, I could see with my own eyes and witness it with my own being what technology

23:46.080 --> 23:52.200
was doing, what progress was, the fact that the progress was real and what it was like

23:52.200 --> 23:57.880
to not have technology because I lived in that time when there wasn't these things.

23:57.880 --> 24:03.520
So I got a very good sense of the benefits of progress and technology.

24:03.520 --> 24:07.280
Did you go to Iran too? I'm originally from Iran. That's why I'm curious.

24:07.280 --> 24:08.280
I lived in Iran.

24:08.280 --> 24:09.280
Oh yeah, which city?

24:09.280 --> 24:10.280
Tehran.

24:10.280 --> 24:11.280
This is in 70.

24:11.280 --> 24:19.200
79, 79 during the Khomeini Revolution. I lived in Medan Fadosi down the carpet bazaar.

24:19.200 --> 24:20.200
Wow.

24:20.200 --> 24:27.080
Fair the, all the chanting and the demonstrations, death to Americans was happening. And I would,

24:27.080 --> 24:32.000
I would actually lived above a carpet shop and I would come down and hang out with the

24:32.000 --> 24:36.840
people. And when the cameras weren't on, they were talking to me and the newest American

24:36.840 --> 24:40.880
and they say, we love Americans. We just hate your government. And I thought, oh my gosh,

24:40.880 --> 24:43.680
I wish Americans were that sophisticated.

24:43.680 --> 24:47.760
So I was learning Farsi, which I've also, I was going to school learning Farsi, which

24:47.760 --> 24:54.760
I've mostly forgotten, but I would have probably still be in Iran if I hadn't been kicked out

24:54.760 --> 25:00.640
because I loved it. And I unfortunately saw very little of it because the day I arrived,

25:00.640 --> 25:05.800
the day I arrived in Iran, I came here from Afghanistan, there was a day that they had

25:05.800 --> 25:10.720
the helicopter shooting the students from the helicopters. And I was like, travel was

25:10.720 --> 25:18.000
really hard. You know, it was, it was anyway, so I never got to Persepolis and we got to

25:18.000 --> 25:20.000
Esfahan someday.

25:20.000 --> 25:23.720
Yeah, you were there at the very key moment.

25:23.720 --> 25:29.520
And yes, yeah, it was, it was, yeah, it was a bad time for Iran. It really fell.

25:29.520 --> 25:33.600
You know, unfortunately, it's very sad what's, what's been happening and what's still happening

25:33.600 --> 25:34.600
to that country.

25:34.600 --> 25:35.600
Yeah.

25:35.600 --> 25:36.600
You mentioned.

25:36.600 --> 25:37.600
Someday I'll return.

25:37.600 --> 25:39.720
Yeah. Yeah. That would be awesome.

25:39.720 --> 25:44.920
I'll tell you, I have a lot of fans in Iran. I'm in touch with a lot of Iranians and the

25:44.920 --> 25:48.720
people who are into technology and they go to Sharif University. All those people are

25:48.720 --> 25:49.720
big fans.

25:49.720 --> 25:55.160
Yeah, yeah, I know. And I occasionally get emails from them. And, and I, you know, would

25:55.160 --> 25:59.840
very much like to go back and visit. In fact, I was just talking to a friend of mine who

25:59.840 --> 26:06.040
Tyler McNeven, who was for the past six years has been, we're trying to work with the government

26:06.040 --> 26:13.680
to do a project. He calls Iran Iran, which he wants to run the length of Iran and make

26:13.680 --> 26:19.280
a film about it, just meeting the people on the way. And several times it came very close

26:19.280 --> 26:23.560
to giving. Actually, they started one time. They gave him permits. He started, he ran

26:23.560 --> 26:29.520
part of it. And then they just kind of, I don't know, something happened. And so, so

26:29.520 --> 26:35.400
he hasn't been able to complete it. But we were just talking just a couple of weeks ago

26:35.400 --> 26:39.120
about, well, maybe we'd just go back as tourists at this point.

26:39.120 --> 26:43.120
Yeah, it's politics against all the good ideas.

26:43.120 --> 26:50.840
Yeah, yeah. No, I mean, again, I loved Iran. I loved the Iranians. I just, it was just

26:50.840 --> 26:57.120
really great. But I haven't seen enough of it, of the country to really claim the day.

26:57.120 --> 26:59.320
Yeah, hopefully one day.

26:59.320 --> 27:00.320
Yeah.

27:00.320 --> 27:05.080
Speaking of politics, how do you see the politics in the US affecting the growth of technology?

27:05.080 --> 27:14.040
Well, you know, the rise of Trumpism is a real step backwards in that most of the jobs

27:14.040 --> 27:19.280
that causing the anger for people are not, they haven't been taken by China. They've

27:19.280 --> 27:27.400
been taken by technology. I mean, it's automation. Outsourcing is just the first step in robots.

27:27.400 --> 27:33.040
So whatever goes to China will go into robots. In fact, China itself, 1 million people work

27:33.040 --> 27:38.960
for Foxconn, which makes the iPhones, they've committed even three or four years ago to

27:38.960 --> 27:47.520
buy 1 million robots. So they're going to automate, China is beginning to automate their

27:47.520 --> 27:56.520
own work. And so these things are inevitable. Automation, AI robots are inevitable, and they're

27:56.520 --> 28:05.040
going to cause even more friction, conflict, as some of the tasks that we currently do,

28:05.040 --> 28:09.080
or many of the tasks that we currently do, whether we're manual or white color, are

28:09.080 --> 28:19.240
going to go to the bots. And so I think this is, I think some of the backlash is just beginning.

28:19.240 --> 28:24.120
There's going to be more of it. But I think my message would be that this is nothing to

28:24.120 --> 28:30.000
do with other countries because it's happening there too. This is about automation and we

28:30.000 --> 28:37.880
can't stop it. We can't prohibit it. We have to embrace it. We have to, so in the future,

28:37.880 --> 28:43.320
in 20 years from now, people will be paid with how well you work with an AI robot. That

28:43.320 --> 28:50.080
will be the skill. You're going to work with them, not against them, but understanding,

28:50.080 --> 28:59.480
being able to talk, to converse well, partner with AI robot is going to be the very valuable

28:59.480 --> 29:03.000
skill. And that's sort of what we should be teaching.

29:03.000 --> 29:06.880
Interesting. How would you categorize that skill? Like if you want to call someone a

29:06.880 --> 29:11.600
doctor or an engineer, what would be the title of that person? Or this will be around the

29:11.600 --> 29:12.600
fields.

29:12.600 --> 29:16.880
It'll be around the fields. But in fact, doctoring is one of the things that was just going

29:16.880 --> 29:24.280
that direction. So the Watson, which is being retrained after playing Jeopardy, is being

29:24.280 --> 29:34.400
trained as a diagnostic doctor. And their market is not people in Africa with a smartphone

29:34.400 --> 29:39.120
accessing that because you could do that and that would be better than no doctor. But it

29:39.120 --> 29:43.720
actually requires a certain, to get the most out of it, requires a certain amount of intelligence

29:43.720 --> 29:50.480
to working with the person. So it's like the patient doesn't quite know how to make the

29:50.480 --> 29:56.960
best use of the AI, but the doctor does. And so it's the doctor plus the AI that are going

29:56.960 --> 30:02.560
to be the best diagnosis. It's not just the AI itself, not the doctor by itself, it's

30:02.560 --> 30:03.960
the doctor plus AI.

30:03.960 --> 30:12.080
So doctors who learn, it's like learning how to search or learning, being a power user

30:12.080 --> 30:19.680
for Google. They'll be power users, AI power users who really know how the AI thinks, how

30:19.680 --> 30:26.400
to best optimize its knowledge and its use. And they know people too. So they're kind

30:26.400 --> 30:31.560
of like the interface. And so that will certainly be for several decades, that will be the,

30:31.560 --> 30:36.360
I think, the pattern, which is you have AI plus humans as being the world's expert.

30:36.360 --> 30:43.240
It's also true by the way right now in chess. When Gary Kasparov, the world chess champion

30:43.240 --> 30:51.560
lost to Deep Blue, the IBM Deep Blue, he complained afterwards saying, look, you know, Deep Blue

30:51.560 --> 30:59.680
had a record of every single chess play ever. All chess moves. He said, if I had access

30:59.680 --> 31:05.560
to that same database while I was playing, I would have beat Deep Blue. So he made a

31:05.560 --> 31:10.960
new chess league called the Freestyle Chess League. And there you could play, humans could

31:10.960 --> 31:21.760
play with AI database. And so now it's freestyle because you can play any, it's like kind of

31:21.760 --> 31:28.960
freestyle martial arts. You can play any method you want. You can play as a single, solitary

31:28.960 --> 31:34.640
human chess champ. You could play as an AI or you can play as what they call centaurs

31:34.640 --> 31:41.800
and AI plus human. And in the past couple of years, the world's best chess player on

31:41.800 --> 31:49.600
the planet is not an AI. It's not a human. It's a centaur. It's an AI plus human. And

31:49.600 --> 31:54.200
that's just showing you that that partnership is really the way that we're going to go at

31:54.200 --> 31:55.800
least for the first couple of decades.

31:55.800 --> 31:59.280
Oh, I totally agree. And that makes a lot of sense because I was going to say that access

31:59.280 --> 32:03.960
to database is one thing, but processing all that information to the speed that AI is.

32:03.960 --> 32:08.520
But yeah, that makes a lot of sense. Speaking of AI, some prominent figures in the world

32:08.520 --> 32:14.640
of tech expressed their concern about negative possibilities that can be caused by the rise

32:14.640 --> 32:19.360
of artificial intelligence. Where do you stand on pros and cons of artificial intelligence?

32:19.360 --> 32:27.040
Yeah, yeah. I mean, it's certainly, we have to consider that possibility. And I think

32:27.040 --> 32:33.720
even though I think that possibility is very, very low and very unlikely for a number of

32:33.720 --> 32:40.720
reasons, I think that the solution to that problem is something we should be doing anyway.

32:40.720 --> 32:51.320
So I endorse the solution, which is that we want to train our AIs to be, to have values,

32:51.320 --> 32:56.000
to be ethical and moral. And that's what's happening right now. There's Google has a

32:56.000 --> 33:00.440
group. They're trying to teach the ethics to the self-driving cars because you have

33:00.440 --> 33:06.200
to, you have to program all that kind of stuff in beforehand. So like, who, if there's an

33:06.200 --> 33:13.240
accident with pedestrian, who should get priorities? Should it be the passenger or the pedestrians?

33:13.240 --> 33:20.560
You have to actually decide that right now. And so those are ethical questions. And

33:20.560 --> 33:27.800
I was going to ask you about ethics and morality. Then first of all, do you think it's objective

33:27.800 --> 33:36.560
and how we would translate from organic analog human thought process to a digital machine

33:36.560 --> 33:48.120
process? Yeah, I think we humans overestimate the uniqueness or the distinctiveness. And

33:48.120 --> 33:54.080
that's that's the humans. And we're not that much. Most of what we can do, including our

33:54.080 --> 33:59.240
emotions can be programmed. And that's been the sort of never ending surprise. We keep

33:59.240 --> 34:04.160
being surprise, surprise, surprise, surprise. And we should realize by now that things that

34:04.160 --> 34:07.680
we thought only humans can do, obviously machines can do. And then once they machines

34:07.680 --> 34:15.200
do, we say, of course, machines can do that. That's just machine learning. Well, yeah,

34:15.200 --> 34:20.680
so emotions will be programmed into machines. It's not that difficult, and they'll be very

34:20.680 --> 34:27.360
valuable to have emotions in machines. Our animals, our pets have emotions. And so it's

34:27.360 --> 34:34.520
not, it's not just us. And so most of the things that animals can do, it's just kind

34:34.520 --> 34:41.920
of programming will program into machines. And so ethics turns out to be, it turns out

34:41.920 --> 34:46.800
that actually humans are not very good at ethics. We're very inconsistent. We're very

34:46.800 --> 34:52.720
opportunistic, we're very situationalist, relativistic. But what's going to happen as

34:52.720 --> 34:56.640
we try to program them into machines, we're going to realize this and actually will help

34:56.640 --> 35:01.440
us to become better, just like just like having children makes you a better person. We're

35:01.440 --> 35:10.680
going to try to teach our mind children, our technological children, ethics, we will we

35:10.680 --> 35:15.920
will divide we will realize and we will make ourselves better ethically, because we'll

35:15.920 --> 35:20.240
see the inconsistencies and we'll try to overcome them.

35:20.240 --> 35:24.680
Kevin has a new book coming. It's called the inevitable understanding the 12 technological

35:24.680 --> 35:28.480
forces that will shape our future. I think it's coming in June.

35:28.480 --> 35:33.360
That's right. June 7 is the pub date. It's available on Amazon for preorder right now.

35:33.360 --> 35:37.640
Excellent. We talked a little about future. I want to ask you about another future is

35:37.640 --> 35:44.080
Ray Kurzweil. I know you respect him, but you disagree with his perhaps optimism about

35:44.080 --> 35:48.520
the singularity. Do you think the singularity is near?

35:48.520 --> 35:54.640
So yeah, I've known Ray for a while and I respect him and actually I'm in total agreement

35:54.640 --> 36:01.080
with his optimism, except I disagree with his idea about the singularity. So I'm optimistic

36:01.080 --> 36:08.680
without the singularity. The singularity just to recap, I think there's two versions, at

36:08.680 --> 36:13.640
least two versions of it, maybe more. I would kind of reduce them right now in a kind of

36:13.640 --> 36:18.920
oversimplification as being a strong singularity and a weak one. The strong one is the one

36:18.920 --> 36:25.560
that Ray believes and it's that intelligence explosion where you make an AI and AI gets

36:25.560 --> 36:35.840
so smart that it can design an AI that's smarter than itself and then that AI will then design

36:35.840 --> 36:41.240
an AI that's smarter than itself and each time it does it, it may do it a little quicker.

36:41.240 --> 36:45.880
So from outside, it looks like all of a sudden once you make an AI that's smarter than humans,

36:45.880 --> 36:53.360
it suddenly instantly is God. It's infinite wisdom and knowledge and the first thing it

36:53.360 --> 37:01.520
does is it makes us immortal. It figures out how to make us immortal and once it's immortal,

37:01.520 --> 37:10.440
then maybe it can even bring back the dead. So therefore, all these good things happen

37:10.440 --> 37:15.800
once you have the first AI that's smarter than humans and so if you can live to that

37:15.800 --> 37:21.040
point, whatever year that is, then you'll live forever. Ray believes that and that's

37:21.040 --> 37:26.720
why he's taking 250 pills a day because he wants to live until that moment so that he

37:26.720 --> 37:33.080
can actually resurrect his father. I don't even know where to begin to say all the reasons

37:33.080 --> 37:40.800
why I think that's not going to happen. There's two couple things. One is he just says, well,

37:40.800 --> 37:47.600
we're on exponential growth of computation and therefore the singularity is near. Well,

37:47.600 --> 37:54.880
there's the thing. Any point on an exponential curve is near the singularity. That's the

37:54.880 --> 38:01.160
whole thing. I mean, it's like the singularity was near 200 years ago if we're on a singularity

38:01.160 --> 38:09.320
curve and it will be 200 years from now. It's always by definition the singularity is always

38:09.320 --> 38:21.120
near on an exponential curve. Second thing is that I think this idea that an AI will

38:21.120 --> 38:28.280
both either can design itself smarter or make us immortal is what I call the fallacy of

38:28.280 --> 38:35.480
think-ism, which is that by thinking about things, you can solve problems. So the idea

38:35.480 --> 38:40.360
is that if you had an AI that's really smart, it would read all the medical literature in

38:40.360 --> 38:45.160
the world and then cure cancer. That's not how you cure cancer. You can't cure cancer

38:45.160 --> 38:50.720
by thinking about it. We don't have enough information. You have to perform experiments.

38:50.720 --> 38:56.280
There's just so much we don't know that we're not going to get out by thinking about it,

38:56.280 --> 39:01.680
no matter how smart we are. We have to actually do experiments which take biological time

39:01.680 --> 39:07.760
and most of them fail. And no matter how smart you are, you have to spend a lot of time

39:07.760 --> 39:13.520
doing experiments on biological subjects like humans, which just take times. Even simulations

39:13.520 --> 39:21.120
aren't enough to answer those questions because you have to ground-proof assimilation. So

39:21.120 --> 39:27.320
this idea that AI's can do these things, including making themselves more just by thinking

39:27.320 --> 39:32.760
about it, is just a total fantasy. You mentioned the examination through experimentation.

39:32.760 --> 39:38.440
Isn't the part of the argument that the part of examination also will be done by AI and

39:38.440 --> 39:45.800
robotics, nanobots, for example, in our bloodstream and between our neurons. So on both sides,

39:45.800 --> 39:53.560
there will be machines and nanobots and AI doing the work. My thinking is that why would

39:53.560 --> 39:59.600
they want to do something that we can survive because they will have very different values

39:59.600 --> 40:02.520
based on the needs that they will have?

40:02.520 --> 40:13.520
So I think, as I said back, I think we can put our values into the AI's we make. I think

40:13.520 --> 40:19.680
the whole point of cultural evolution is that it's not necessarily Darwinian. There's every

40:19.680 --> 40:27.080
reason. One of the things we realize as humans in our culture is that the more species, the

40:27.080 --> 40:32.800
more variety diversity is a good thing for the economy, for ourselves. So we want to

40:32.800 --> 40:37.840
have as many different ways of thinking. And one of the things, going back to this whole

40:37.840 --> 40:42.000
thing of AI, and this is another point, is that we tend to think of intelligence as a

40:42.000 --> 40:48.800
single dimension. It's not a single dimension. Our own intelligence is a whole suite, a spectrum

40:48.800 --> 40:59.040
of probably about 100 different types of thinking from spatial deduction, rationalization, emotional

40:59.040 --> 41:05.360
intelligence. I mean, there's hundreds of them. We don't have a general purpose intelligence

41:05.360 --> 41:12.600
at all. If we have a very, very specific kind of collective of intelligence suited to our

41:12.600 --> 41:21.440
survival evolutionarily. First of all, the only way you can make this kind of intelligence

41:21.440 --> 41:26.080
is to have the same substrate, a biological substrate. But secondly, there's not much

41:26.080 --> 41:32.320
reason to make this suite, this collective of intelligences, artificially. What we want

41:32.320 --> 41:36.360
and what we're doing is making other kinds of thinking. So your calculator is smarter

41:36.360 --> 41:41.640
than you are in arithmetic, your GPS is smarter than you are in spatial navigation, Google

41:41.640 --> 41:49.200
is smarter than you are in total recar. And the self-driving car will drive in an inhuman

41:49.200 --> 41:52.280
way. That's the whole point. That's why we want it driving. We don't want it to drive

41:52.280 --> 41:58.560
like a human. And so what we'll be doing is making different species of thinking. They'll

41:58.560 --> 42:03.240
think differently. The AIs that we're going to make are going to think differently than

42:03.240 --> 42:09.720
humans. That's their main value, because we can get them to help us, work with us to

42:09.720 --> 42:15.520
solve problems that we can't. So these are going to be different species. And the AIs

42:15.520 --> 42:21.320
won't be able to think like us. Our thinking will be different. And there's every reason

42:21.320 --> 42:31.240
to work with us. This idea that the AIs need to kill us is just a crazy, insane Hollywood

42:31.240 --> 42:37.200
trope. It's a cliche. It doesn't make any sense at all. I can't really think of it.

42:37.200 --> 42:43.160
In fact, I think that would be even hard to do, even if it was your job to program this.

42:43.160 --> 42:44.280
I don't think you could do it.

42:44.280 --> 42:48.640
Isn't it interesting that humans find that scenario interesting enough?

42:48.640 --> 42:55.840
Yeah, right. And it's kind of the only vision of the AI future is they take over and terminate

42:55.840 --> 43:04.040
us. And I think it's because this is so cinematic. I mean, it's just a cheap cinematic device.

43:04.040 --> 43:13.480
And the idea that they would find is useful. But more importantly, it's not going to be

43:13.480 --> 43:18.160
that separate from us. And this is the other important thing. So that was the strong version.

43:18.160 --> 43:24.080
I think the weak version of the singularity is that we are making a planetary super-organism

43:24.080 --> 43:34.360
of something, that we are weaving ourselves 7 billion people plus 15 quintillion computers

43:34.360 --> 43:40.200
and smartphones together into one thing that's always on, that there is an intelligence at

43:40.200 --> 43:43.200
this higher level that we can't understand.

43:43.200 --> 43:48.000
So the whole point of the singularity is you can't see beyond it. The insight was that

43:48.000 --> 43:53.640
you have something that was the original idea of the singularity is that there's a horizon

43:53.640 --> 43:59.960
beyond which you cannot see at all. And that you can't even imagine. And I think that there's

43:59.960 --> 44:06.720
a soft version of that where we have a planetary intelligence that we as neurons sort of can't

44:06.720 --> 44:12.520
really understand. And that seems to me to be very, very likely. Again, we are then part

44:12.520 --> 44:18.480
of the thing. So really not this sense of us against them. It's like, no, we are them.

44:18.480 --> 44:26.640
It is us. We're part of it. We may not understand it when it does stuff, but that's us. And

44:26.640 --> 44:33.840
so I think that's a second reason. So on that kind of singularity, I'm saying, yeah, I think

44:33.840 --> 44:38.680
there could be this soft singularity where the future and what happens is really hard

44:38.680 --> 44:45.600
for us to see because we have this thing that has not existed before and it has its own

44:45.600 --> 44:46.600
thoughts.

44:46.600 --> 44:48.720
Do you have a frame for that or we just don't know?

44:48.720 --> 44:54.880
Yes, it's now. We've already begun. I mean, we're building it now. And I'm trying to take

44:54.880 --> 45:00.440
this idea seriously. It's not just the metaphor. I think, no, we really do have a machine that's

45:00.440 --> 45:08.760
I think the things like the flash crash in the world finance system is an example of

45:08.760 --> 45:16.800
kind of like a synchronized thought or something that happens globally. We're not even sure

45:16.800 --> 45:21.640
why it happened. And we will never know. And I think those are the kinds of things that

45:21.640 --> 45:22.640
we'll see more of.

45:22.640 --> 45:28.720
Yeah, I agree. Things are changing and changing fast at the planetary level. So a lot of the

45:28.720 --> 45:34.520
impossible things that we have encountered like Wikipedia are because we have a technology

45:34.520 --> 45:42.000
to allow a billion people to collaborate in real time. That's never happened before.

45:42.000 --> 45:48.280
Most of the kind of cool things are happening, social media, all these other things are due

45:48.280 --> 45:55.680
to the fact that we now have this technology to allow collaboration, cooperation in real

45:55.680 --> 45:58.600
time at the planetary scale.

45:58.600 --> 46:03.600
Speaking of cool things, the cover story of the May issue of Wired Magazine is about

46:03.600 --> 46:10.240
this mysterious unicorn startup, Magic Leap, who as stated on the cover of this month,

46:10.240 --> 46:15.000
Wired are on the quest to create a new kind of reality. Now you spent some time with them

46:15.000 --> 46:16.000
and wrote it.

46:16.000 --> 46:17.000
And by the way, I wrote the article.

46:17.000 --> 46:20.480
Yes, I was exactly going to say that you spent some time and wrote that extensive piece

46:20.480 --> 46:25.480
about them. Would you explain to our listeners what exactly Magic Leap is and what did they

46:25.480 --> 46:31.800
do and why are they so important that without a better version of even being available to

46:31.800 --> 46:34.680
the developers, they raise more than a billion dollars?

46:34.680 --> 46:44.680
Yeah, I can't explain the last one. I mean, why people have given them so much money. So

46:44.680 --> 46:50.840
I did get to see the current version of their technology and I saw all the other VR companies

46:50.840 --> 46:59.080
as well. And a lot of the demos and most of the content that was available say at the

46:59.080 --> 47:09.480
first of the year. And Magic Leap, there's two distinct brands, two different categories

47:09.480 --> 47:16.360
of virtual reality. There's the VR, which is you put on the headset, the goggles and

47:16.360 --> 47:24.440
you are immersed into a total world. So everything you see is this synthetically created world.

47:24.440 --> 47:29.560
And then there's what they call MR or AR, Mixed Reality or Augmented Reality. There's

47:29.560 --> 47:34.800
some transitions, MR or AR. And that is where you were kind of a transparent spectacle like

47:34.800 --> 47:40.400
a pair of glasses and you see your room or even outside or your office. And then the

47:40.400 --> 47:49.320
virtual is inserted into or on top of or within the real world that you see. So you can see

47:49.320 --> 47:55.400
virtual objects or you can see virtual people or you can see virtual screens.

47:55.400 --> 48:02.280
So MR and AR are the same thing. MR and AR are basically the same thing. And if you

48:02.280 --> 48:07.760
can do MR or AR, you can do VR because all you have to do is turn the lights in the room

48:07.760 --> 48:14.440
down and fill, not just an object, but you can fill everything in. So technically, VR

48:14.440 --> 48:22.480
is a subset of MR or AR, we'll call it MR. So VR is a subset of MR, meaning that again,

48:22.480 --> 48:32.240
if your technology can do MR really, really well, you can easily do VR too. So technically,

48:32.240 --> 48:41.160
MR is more difficult to do. And magically it's doing MR, which is this augmented mixed

48:41.160 --> 48:47.760
reality where you have a pair of visors or spectacles or glasses, which are mostly kind

48:47.760 --> 48:54.880
of clear. And you can see everything around you, but you have this virtual aspect to it.

48:54.880 --> 49:06.280
And the thing about magic leaf stuff is that it really does appear as if it's there. Now

49:06.280 --> 49:14.960
the it, the image is there's no pixels that you can detect. It's pretty stationary, but

49:14.960 --> 49:24.440
the lighting is off. And let me say this is that to really pass for that as to be really

49:24.440 --> 49:30.320
real, the virtual object would have to be lit with the same light that's in the room

49:30.320 --> 49:36.720
that you're in. And that would require another level of computation of detecting and measuring

49:36.720 --> 49:42.360
all the light in the room as you move around and reproducing that entire lighting onto

49:42.360 --> 49:47.720
the virtual object. That does not happen right now. So what that means, and there's a couple

49:47.720 --> 49:54.680
other glitches or things to overcome, what that means is that what you see today in the

49:54.680 --> 50:00.640
MR is a artificial looking, it's an artificial thing. It doesn't look real, but it looks

50:00.640 --> 50:07.520
really present. So its presence is absolutely real. It's like having, you know, so there's

50:07.520 --> 50:13.760
often there's a fantasy thing, you know, it's a baby elephant or it's a little robot thing,

50:13.760 --> 50:18.800
or it's Mickey Mouse or it's a person, but they don't look entirely real in that room

50:18.800 --> 50:25.960
because the lighting is off among other things. But their presence is absolutely real. You're

50:25.960 --> 50:32.000
totally convinced. And that's the same thing with VR is even in the cartoon world, you

50:32.000 --> 50:37.920
know that it can't really be real world, but you really feel present that presence is real.

50:37.920 --> 50:45.720
And so that real presence is sort of the key because what's happening with VR and MR is

50:45.720 --> 50:51.680
that what you're getting is we're moving from internet of information to internet of experiences.

50:51.680 --> 50:58.640
So the experiences are real. They're incredibly vivid. They feel you feel them rather than

50:58.640 --> 51:04.880
know them. And there's a huge difference there between knowing things like information and

51:04.880 --> 51:11.360
feeling them. And that shift is going to be very, very important. I think VR the most

51:11.360 --> 51:15.720
important, the most interesting things in VR are not other landscapes, not other objects,

51:15.720 --> 51:20.000
but other people. And I think VR is going to be the most social of all the social media

51:20.000 --> 51:21.000
that we have.

51:21.000 --> 51:23.000
Is there any audio aspect to what they do as well?

51:23.000 --> 51:27.800
Oh, yeah, absolutely. So there's actually 3D or, you know, by neuro or audio. So it's

51:27.800 --> 51:36.720
not stereo, it's beyond stereo. Because to do true 3D audio, the audio has to change

51:36.720 --> 51:41.400
depending on where you are as you move around the room. So it's not just that you have a

51:41.400 --> 51:48.880
sense of three dimensions. It's a sense that you have like four dimensions. It's X. So

51:48.880 --> 51:49.880
it's changing.

51:49.880 --> 51:50.880
Motion tracking, basically.

51:50.880 --> 51:58.720
Yeah, right. Motion tracking. So they have, there's bionary recording, which is a different

51:58.720 --> 52:04.160
way of recording things so that you actually have a full, true three-dimensional recording

52:04.160 --> 52:08.480
that you can actually navigate through. And that's a large part of it. And it turns out

52:08.480 --> 52:15.480
that actually your hands, the tactile, having hands touching, moving your whole body, having

52:15.480 --> 52:25.080
vibrations come back is 50% or more than 50% of the total sensation or this total illusion

52:25.080 --> 52:30.200
of being there. And that that is a huge part in a lot of the, some of the new arcades,

52:30.200 --> 52:36.040
the VR arcades. Take advantage of that by, you know, giving you a vest that you wear

52:36.040 --> 52:44.320
in gloves and other things where you can actually feel your whole body is there. And then that

52:44.320 --> 52:50.320
transportation is incredible. You really are somewhere different.

52:50.320 --> 52:55.440
How can someone write for Wired Magazine?

52:55.440 --> 53:03.440
I think the general path, and this is true not just for Wired, is with small stuff, start

53:03.440 --> 53:11.080
writing small things. So I think generally most of the writers who've come to Wired have

53:11.080 --> 53:17.360
been writing somewhere else first. So they either have a blog, they have an audience,

53:17.360 --> 53:23.840
or they're writing little things, probably the digital side first. They're doing little

53:23.840 --> 53:28.800
short things. And they are noticed and they move on to longer things that seems to be

53:28.800 --> 53:31.160
the general pattern.

53:31.160 --> 53:36.360
We've been talking to Kevin Kelly, his upcoming book, Inevitable, understanding the 12 technological

53:36.360 --> 53:40.560
forces that will shape our future. I'm going to ask you the final question that I ask all

53:40.560 --> 53:46.320
my guests. And that's, if you come across an intelligent alien from a different civilization,

53:46.320 --> 53:49.960
what would you say as the worst thing that humanity has done? And what would you say

53:49.960 --> 53:54.480
as humanity's greatest achievement?

53:54.480 --> 54:04.200
I think the worst thing that we've done would have to be the enslavement and the dehumanization

54:04.200 --> 54:18.800
of races of people who we declared were not really us. So that kind of completely artificial

54:18.800 --> 54:28.440
arbitrary separation. And I would say, depending on the circumstances, but the best thing we

54:28.440 --> 54:33.440
would have done would have been meeting an alien in another planet. I mean, that's going

54:33.440 --> 54:39.400
to be an achievement that would be quite remarkable. I don't think we're going to meet them on

54:39.400 --> 54:45.000
our own planet. I think there's just going to be a restriction for AIs not to interfere

54:45.000 --> 54:51.720
with us, so they're not going to reveal themselves. But I think our ability to make contact with

54:51.720 --> 55:20.720
another one will be our greatest achievement to that point.

