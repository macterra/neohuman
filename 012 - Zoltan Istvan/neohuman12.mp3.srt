1
00:00:00,000 --> 00:00:05,620
Nothing, in my opinion, has stopped so much creation and rationality in the human race

2
00:00:05,620 --> 00:00:14,080
as religion.

3
00:00:14,080 --> 00:00:17,560
Hello and welcome to the twelfth episode of Neo Human Podcast.

4
00:00:17,560 --> 00:00:21,180
I'm Agha Bahari at Aghologist on Twitter and Instagram.

5
00:00:21,180 --> 00:00:27,880
You can follow the show on iTunes or liveinlimbo.com and soon on YouTube.

6
00:00:27,880 --> 00:00:29,980
My guest this week is Zoltan Isfand.

7
00:00:29,980 --> 00:00:31,400
Welcome to the show, Zoltan.

8
00:00:31,400 --> 00:00:32,400
Thank you so much for having me.

9
00:00:32,400 --> 00:00:33,800
Yeah, it's my pleasure.

10
00:00:33,800 --> 00:00:37,840
I wanted to give you some sort of a title like Zoltan Isfand This, but you have done

11
00:00:37,840 --> 00:00:40,320
so many different things and are doing so many different things.

12
00:00:40,320 --> 00:00:44,640
I think it would be best to hear it from you, your background, some of the works that you've

13
00:00:44,640 --> 00:00:46,920
done and some of the works that you're doing now.

14
00:00:46,920 --> 00:00:47,920
Well, sure.

15
00:00:47,920 --> 00:00:52,780
You know, as you said, my name is Zoltan Isfand and I think the biggest thing is I'm currently

16
00:00:52,780 --> 00:00:58,480
a 2016 U.S. presidential candidate and I'm an advocate for science and technology, my

17
00:00:58,480 --> 00:01:05,840
entire platform revolves around using those kinds of things to make the world and America

18
00:01:05,840 --> 00:01:07,200
a better place.

19
00:01:07,200 --> 00:01:11,480
And for anyone that doesn't know what transhumanism is, it's a social movement of a few million

20
00:01:11,480 --> 00:01:15,920
people around the world that want to use science and technology to radically modify the human

21
00:01:15,920 --> 00:01:19,120
being and also to to improve the human experience.

22
00:01:19,120 --> 00:01:24,320
Yeah, so making America better has nothing to do with making America great again, I would

23
00:01:24,320 --> 00:01:25,320
assume.

24
00:01:25,320 --> 00:01:29,080
No, nothing to do with each other.

25
00:01:29,080 --> 00:01:35,880
But you know, really what it has to do with is just how can Americans apply radical science

26
00:01:35,880 --> 00:01:41,000
and technology in their lives to become a better human beings?

27
00:01:41,000 --> 00:01:45,460
We can live much longer, we can have more powers, we can do cooler things.

28
00:01:45,460 --> 00:01:50,040
So it's really about how that science and technology can be used and if we can actually

29
00:01:50,040 --> 00:01:51,960
develop that science and technology.

30
00:01:51,960 --> 00:01:57,920
How is the presidential campaign going and I'm also going to ask you about how did you

31
00:01:57,920 --> 00:02:02,600
find out the message is being received across the U.S. because you went across the country

32
00:02:02,600 --> 00:02:06,880
pretty much with the with the immortality bus, which we're going to talk a little about

33
00:02:06,880 --> 00:02:07,880
as well.

34
00:02:07,880 --> 00:02:11,600
But how do you find people receiving the message of science and technology?

35
00:02:11,600 --> 00:02:19,200
Well, you know, on the East and West Coast, the message is received really well.

36
00:02:19,200 --> 00:02:24,840
The states that have major technology companies and impacts and stuff like that, generally

37
00:02:24,840 --> 00:02:26,180
it's well received.

38
00:02:26,180 --> 00:02:31,280
In parts of the middle of America and the deep south, you know, the message was not

39
00:02:31,280 --> 00:02:32,280
so well received.

40
00:02:32,280 --> 00:02:37,280
I mean, everybody was friendly on my four month bus tour from San Francisco to Washington,

41
00:02:37,280 --> 00:02:38,280
D.C.

42
00:02:38,280 --> 00:02:44,160
But clearly like California, New York were real highlights for, you know, we could have

43
00:02:44,160 --> 00:02:46,800
events every day in California, New York.

44
00:02:46,800 --> 00:02:51,360
Or much more difficult to get events in in the middle of the country or in the south,

45
00:02:51,360 --> 00:02:53,960
because sometimes people really don't want to put them on for you.

46
00:02:53,960 --> 00:02:58,520
They're just not sure if what I'm trying to do is good or bad.

47
00:02:58,520 --> 00:03:03,080
Do you find that transhumanism is like kind of a new atheism, the way that atheism was

48
00:03:03,080 --> 00:03:04,840
being treated maybe like 10 years ago?

49
00:03:04,840 --> 00:03:06,320
It's much more acceptable now.

50
00:03:06,320 --> 00:03:08,680
Well, yeah, and transhumanism is growing.

51
00:03:08,680 --> 00:03:11,760
And it also depends on where I am.

52
00:03:11,760 --> 00:03:16,160
If I'm in the deep south, I may not even use the word transhumanism so much because

53
00:03:16,160 --> 00:03:20,080
it just creates this this mean response.

54
00:03:20,080 --> 00:03:24,120
But if I use the words radical science and technology, I think a lot more people are

55
00:03:24,120 --> 00:03:25,120
interested.

56
00:03:25,120 --> 00:03:29,960
Whereas if I'm on the West Coast or the East Coast, I will try to use the word transhumanism.

57
00:03:29,960 --> 00:03:32,880
So everyone kind of understands exactly what I mean.

58
00:03:32,880 --> 00:03:39,120
I mean, you know, telepathy via headsets, I mean, chip implants, I mean, exoskeleton

59
00:03:39,120 --> 00:03:42,200
suits, driverless technology, I mean, AI.

60
00:03:42,200 --> 00:03:48,760
So it really depends on where I go, how I try to give out my message, because you can

61
00:03:48,760 --> 00:03:54,120
definitely overload people in the south and in the middle of the country if you come on

62
00:03:54,120 --> 00:03:57,120
too strong and they will not like it, they'll let you know they don't like it.

63
00:03:57,120 --> 00:04:02,240
I would imagine it would be a little hard not to talk about transhumanism when you founded

64
00:04:02,240 --> 00:04:06,480
a party called the transhumanist party and running as a candidate, right?

65
00:04:06,480 --> 00:04:07,480
Of course, of course.

66
00:04:07,480 --> 00:04:10,140
And you know, I always get into it.

67
00:04:10,140 --> 00:04:15,520
It just really is a matter of how one does it, because one has to be diplomatic when

68
00:04:15,520 --> 00:04:21,560
they're dealing with very religious people who know the word transhumanism and associate

69
00:04:21,560 --> 00:04:28,560
it with ideas of the Antichrist, with ideas of end of times revelations and stuff like

70
00:04:28,560 --> 00:04:29,560
that.

71
00:04:29,560 --> 00:04:33,440
Especially in my bus tour, when people found out I had a chip in my hand, it's like you

72
00:04:33,440 --> 00:04:36,720
could see, you could feel the energy and people change.

73
00:04:36,720 --> 00:04:39,240
All of a sudden they're like, wow, mark of the beast.

74
00:04:39,240 --> 00:04:42,280
And I'm like, actually, no, it's just something that's going to be convenient.

75
00:04:42,280 --> 00:04:43,280
We can pay with it.

76
00:04:43,280 --> 00:04:45,880
We can do all sorts of cool things with my implant.

77
00:04:45,880 --> 00:04:47,240
And they don't see it like that.

78
00:04:47,240 --> 00:04:52,260
They still see it like, wow, mark of the beast, you know, this is the Antichrist technology.

79
00:04:52,260 --> 00:04:54,160
So a lot of it is just presentation.

80
00:04:54,160 --> 00:04:59,600
If you present it in a nice way, you talk about virtual reality, you talk about using

81
00:04:59,600 --> 00:05:03,440
science to make people live longer and you know, then I think a lot of people are open

82
00:05:03,440 --> 00:05:05,000
to transhumanism.

83
00:05:05,000 --> 00:05:09,760
If you talk about it in terms of transhumanists want to become gods by merging with machines,

84
00:05:09,760 --> 00:05:11,400
well, then you turn off a lot of people.

85
00:05:11,400 --> 00:05:13,920
So you know, I adjust how I speak about it.

86
00:05:13,920 --> 00:05:16,160
Do you see religion on the way?

87
00:05:16,160 --> 00:05:17,960
I mean, you're an outspoken atheist.

88
00:05:17,960 --> 00:05:22,200
Do you see any place for religion in a political structure of the future?

89
00:05:22,200 --> 00:05:29,960
Well, yes, I do, unfortunately, because I would prefer there to be, you know, not religion,

90
00:05:29,960 --> 00:05:35,160
but just spirituality and people to kind of go off on those tangents if they want.

91
00:05:35,160 --> 00:05:40,520
But unfortunately, I think the way our world is working is, so, you know, here's the situation.

92
00:05:40,520 --> 00:05:48,400
Every Supreme Court justice, our president and all 535 members of Congress are religious

93
00:05:48,400 --> 00:05:51,240
and believe in an afterlife, at least right now on paper.

94
00:05:51,240 --> 00:05:56,000
And because of transhumanism, because of life extension technology, all those people are

95
00:05:56,000 --> 00:05:58,360
going to be living longer than ever.

96
00:05:58,360 --> 00:06:00,220
So there's the irony.

97
00:06:00,220 --> 00:06:03,200
But as a result, they're not about to give up their religion that they've been brought

98
00:06:03,200 --> 00:06:05,760
up with for 50, 60 years.

99
00:06:05,760 --> 00:06:09,640
So they're going to be living long enough to make the decisions for this country 20,

100
00:06:09,640 --> 00:06:10,920
30 years in the future.

101
00:06:10,920 --> 00:06:17,460
And it's unavoidable that religion will probably survive because of those reasons.

102
00:06:17,460 --> 00:06:22,200
So we have to get used to the idea that religion will play a part in our technological development

103
00:06:22,200 --> 00:06:24,440
and our technological evolution.

104
00:06:24,440 --> 00:06:29,960
At the same time, I see that a non-religious world is growing, and my hope is that religion

105
00:06:29,960 --> 00:06:35,120
will evolve as well into something that's much less fundamental and much more about

106
00:06:35,120 --> 00:06:39,320
the personal relationship one has with their own spirituality and with a creator if they

107
00:06:39,320 --> 00:06:40,800
want to have that.

108
00:06:40,800 --> 00:06:48,000
And, you know, technically, I say I'm an atheist for reasons of kind of fighting against the

109
00:06:48,000 --> 00:06:50,000
system, but I'm truly an agnostic.

110
00:06:50,000 --> 00:06:52,200
You know, I have no idea what has happened.

111
00:06:52,200 --> 00:06:56,080
I have no idea if there's aliens out there that have created human beings.

112
00:06:56,080 --> 00:06:58,160
I have no idea if there's an all-knowing creator.

113
00:06:58,160 --> 00:07:01,320
I have no idea, in fact, if there's Jesus out there.

114
00:07:01,320 --> 00:07:03,760
I mean, I just don't know.

115
00:07:03,760 --> 00:07:07,680
Because religion has been so oppressive in society, I consistently call myself an atheist

116
00:07:07,680 --> 00:07:09,640
and write atheist articles.

117
00:07:09,640 --> 00:07:14,480
But what the future holds will probably be something that's quasi-religious and based

118
00:07:14,480 --> 00:07:19,720
on a Judeo-Christian framework, but hopefully it will be one that's much more lenient towards

119
00:07:19,720 --> 00:07:24,400
allowing human beings to evolve into trans-human beings.

120
00:07:24,400 --> 00:07:25,840
You mentioned the spirituality.

121
00:07:25,840 --> 00:07:28,880
How are you defining the spirituality as a trans-humanist?

122
00:07:28,880 --> 00:07:34,120
Well, you know, the fact is, one of the things I got to say, one of the most important ideas

123
00:07:34,120 --> 00:07:38,200
that's happened to me in the last five years, and I think a lot of scientists, they now

124
00:07:38,200 --> 00:07:43,600
say virtually every NASA scientist believes in other species or whatever, aliens out there,

125
00:07:43,600 --> 00:07:46,360
it sounds totally insane.

126
00:07:46,360 --> 00:07:53,800
But the reality is that there are a trillion galaxies, and each galaxy has about 500 planets

127
00:07:53,800 --> 00:07:54,800
and stars.

128
00:07:54,800 --> 00:08:00,440
The chances of there not being millions of life forms out there, you know, and millions

129
00:08:00,440 --> 00:08:03,880
of life forms that are more advanced than human beings that have already reached the

130
00:08:03,880 --> 00:08:09,320
singularity, that have already reached incredible intelligence levels way beyond ours, of course

131
00:08:09,320 --> 00:08:10,320
they have.

132
00:08:10,320 --> 00:08:12,800
I mean, from a statistical perspective, that's 100%.

133
00:08:12,800 --> 00:08:15,960
And virtually every NASA scientist believes that these days.

134
00:08:15,960 --> 00:08:18,480
In the last five years, I've grown to understand this theory as well.

135
00:08:18,480 --> 00:08:22,720
The point is that it opens up our idea of spirituality.

136
00:08:22,720 --> 00:08:24,680
It opens up our idea of interconnectivity.

137
00:08:24,680 --> 00:08:29,320
It opens up our idea of what is possible for us as a species.

138
00:08:29,320 --> 00:08:31,500
We may evolve into a hive mind.

139
00:08:31,500 --> 00:08:35,660
We may evolve into machines where we can connect directly to one another.

140
00:08:35,660 --> 00:08:36,720
We feel more empathy.

141
00:08:36,720 --> 00:08:38,240
We feel more love.

142
00:08:38,240 --> 00:08:42,600
We feel more reason, reasonability, reasonableness, I hope.

143
00:08:42,600 --> 00:08:44,360
You know, so where are we going?

144
00:08:44,360 --> 00:08:45,360
Where's spirituality?

145
00:08:45,360 --> 00:08:50,440
I'm sure it's going to be tied into a more complex version of ourselves and how we interpret

146
00:08:50,440 --> 00:08:53,500
the technology that our lives are imbued with.

147
00:08:53,500 --> 00:08:57,960
It may also involve, you know, reaching out to the stars and seeing if anything else is

148
00:08:57,960 --> 00:09:02,880
out there that's willing to listen and or willing to, you know, interfere with our lives

149
00:09:02,880 --> 00:09:04,440
or maybe it already has.

150
00:09:04,440 --> 00:09:12,120
The point is that it's just spirituality is in the universe that has a trillion galaxies

151
00:09:12,120 --> 00:09:16,320
and 500 million, a billion planets, stars each.

152
00:09:16,320 --> 00:09:18,520
I mean, that number is off the charts.

153
00:09:18,520 --> 00:09:21,560
We must take spirituality in a very different way.

154
00:09:21,560 --> 00:09:25,840
We easily could be living in a holographic universe created by some species that was

155
00:09:25,840 --> 00:09:27,160
created by some species.

156
00:09:27,160 --> 00:09:29,520
We just have to figure all those things in.

157
00:09:29,520 --> 00:09:32,120
And I think that's where my spirituality lies.

158
00:09:32,120 --> 00:09:37,540
I haven't figured it out yet, but I do believe that there must be other things out there

159
00:09:37,540 --> 00:09:39,280
that have a lot to teach us.

160
00:09:39,280 --> 00:09:44,520
Do you know of any organization, because this sounds very interesting, all these terms have

161
00:09:44,520 --> 00:09:48,720
to be taken, I think, with a grain of salt, spirituality, religion, because they've been

162
00:09:48,720 --> 00:09:51,800
abused for so many years, right?

163
00:09:51,800 --> 00:09:56,040
Do you know any kind of organization in the US, Canada, or anywhere in Europe, I would

164
00:09:56,040 --> 00:10:01,600
assume, that promoting spirituality based on technology and the way that we are advancing

165
00:10:01,600 --> 00:10:03,280
and evolving, like what you described?

166
00:10:03,280 --> 00:10:04,280
Yes, yes.

167
00:10:04,280 --> 00:10:05,880
I mean, I know a couple of them.

168
00:10:05,880 --> 00:10:08,360
The problem is that they're too religious still for me.

169
00:10:08,360 --> 00:10:14,800
You know, like TerraSem is a very interesting organization that has a quasi-spiritual emphasis.

170
00:10:14,800 --> 00:10:19,800
They're a group out of Florida that kind of trying to upload their minds.

171
00:10:19,800 --> 00:10:22,120
This is an organization by Martin Ruffflat.

172
00:10:22,120 --> 00:10:23,300
Yes, yes.

173
00:10:23,300 --> 00:10:28,720
And I like the organization, though it is still a little bit too fundamental for me

174
00:10:28,720 --> 00:10:33,160
in terms of, does it need to be so spiritually oriented?

175
00:10:33,160 --> 00:10:37,120
And they also accept all sorts of religions, no matter how formal that is.

176
00:10:37,120 --> 00:10:40,640
The issue, though, is that I'm just not sure.

177
00:10:40,640 --> 00:10:47,200
It just still feels too feely and touchy for me, whereas I really would like to see an

178
00:10:47,200 --> 00:10:53,440
atheist revolution that then looks at what is spirituality from a completely secular

179
00:10:53,440 --> 00:10:59,340
point of view, whereas I feel like TerraSem is kind of, was born out of the religions

180
00:10:59,340 --> 00:11:03,280
that exist in the world and made to adapt to a more futuristic version.

181
00:11:03,280 --> 00:11:08,920
But don't get me wrong, the TerraSem people, they are exactly the kind of spiritual people

182
00:11:08,920 --> 00:11:13,840
I'd like to have as friends, but I still feel it's a little bit too formal.

183
00:11:13,840 --> 00:11:17,820
The Church of Perpetual Life is a little bit closer to what I like.

184
00:11:17,820 --> 00:11:23,040
They are a community of people that use the word church in their title, but they're basically

185
00:11:23,040 --> 00:11:28,120
mostly non-religious people that believe entirely in science and technology, and they gather

186
00:11:28,120 --> 00:11:32,840
to a house of worship, not to worship science and technology.

187
00:11:32,840 --> 00:11:37,480
Well, they're not worshiping it, but they get around to celebrate it, and that's what

188
00:11:37,480 --> 00:11:38,480
I like.

189
00:11:38,480 --> 00:11:44,520
I like an organization that celebrates technology and science, not worship celebrates, because

190
00:11:44,520 --> 00:11:47,200
that's exactly what I do as a transhumanist, as a presidential candidate.

191
00:11:47,200 --> 00:11:50,680
I'm going around the country saying, look, here is the good news.

192
00:11:50,680 --> 00:11:53,680
The good news is we can conquer death with science and technology.

193
00:11:53,680 --> 00:11:55,000
It's nothing crazy about it.

194
00:11:55,000 --> 00:12:00,320
It's just, you know, I'm a scientist who's a, or I'm a science popularizer who's excited

195
00:12:00,320 --> 00:12:01,600
about what's happening.

196
00:12:01,600 --> 00:12:07,120
So that's how I hopefully will see the form of spirituality and religion evolve into the

197
00:12:07,120 --> 00:12:09,160
next 20 years, at least here in America.

198
00:12:09,160 --> 00:12:15,680
Now, it's possible that it may not evolve that way, and it may remain very fundamental,

199
00:12:15,680 --> 00:12:18,680
but hopefully it's going to grow up.

200
00:12:18,680 --> 00:12:23,040
The interest in transhumanism, as you mentioned, they happen in wide spectrum of backgrounds

201
00:12:23,040 --> 00:12:27,740
from scientists and hobbyists and religious people.

202
00:12:27,740 --> 00:12:32,400
There have been some backlashes since you started the transhumanist party and elevated,

203
00:12:32,400 --> 00:12:35,080
I would say, when you decided to run for president.

204
00:12:35,080 --> 00:12:40,000
There were people who argued, one, you had claimed the leadership of a transhumanist

205
00:12:40,000 --> 00:12:44,520
movement all to yourself, and two, you want the leadership only for yourself and haven't

206
00:12:44,520 --> 00:12:47,880
been willing to share it with anyone else and all this kind of argument.

207
00:12:47,880 --> 00:12:52,700
There have been a petition against you, I think.

208
00:12:52,700 --> 00:12:53,700
Is that the case?

209
00:12:53,700 --> 00:12:54,700
Yes or no?

210
00:12:54,700 --> 00:12:56,880
And why is that the case, if it is?

211
00:12:56,880 --> 00:13:02,520
Well, it's absolutely not the case that I claimed leadership of anything except for

212
00:13:02,520 --> 00:13:07,920
the transhumanist party, and I also, you know, I mean, I didn't necessarily claim leadership.

213
00:13:07,920 --> 00:13:14,000
I was nominated by the three other officers at the time to run as a presidential candidate,

214
00:13:14,000 --> 00:13:16,840
which kind of naturally gave me the leadership.

215
00:13:16,840 --> 00:13:23,120
So you have to understand the transhumanist party right now is a non-recognized FEC party.

216
00:13:23,120 --> 00:13:25,980
So it's, you know, it depends on what you interpret as parties.

217
00:13:25,980 --> 00:13:29,160
In America, right, there are thousands of political parties.

218
00:13:29,160 --> 00:13:33,640
You can form, legally form, a political party by two people getting together and having

219
00:13:33,640 --> 00:13:36,140
a conversation and say, let's make a party.

220
00:13:36,140 --> 00:13:37,140
And that's it.

221
00:13:37,140 --> 00:13:38,420
That's all it takes to make a political party.

222
00:13:38,420 --> 00:13:41,520
People think that a political party has to be this or this, no, no, no.

223
00:13:41,520 --> 00:13:45,220
A legal political party, according to the laws of the land, two people have to get together

224
00:13:45,220 --> 00:13:47,440
and create a name, and that's it.

225
00:13:47,440 --> 00:13:48,440
That's essentially it.

226
00:13:48,440 --> 00:13:50,540
One has to be an officer and one has to be a treasurer.

227
00:13:50,540 --> 00:13:52,240
Those are the technical things.

228
00:13:52,240 --> 00:13:53,640
And so I did that.

229
00:13:53,640 --> 00:13:57,140
You know, I did that when none other existed and I wasn't sure what was going to happen.

230
00:13:57,140 --> 00:13:58,760
We brought on some more people.

231
00:13:58,760 --> 00:14:02,760
We made our party a non-membership party, so there's no, you know, no one's paying

232
00:14:02,760 --> 00:14:07,640
dues and no one's, no one belongs, no one's beholden to the party.

233
00:14:07,640 --> 00:14:11,840
We have advisors that advise and it's a very informal affair.

234
00:14:11,840 --> 00:14:15,840
I'm not, you know, we're trying to grow state parties, but I'm not trying to grow it so

235
00:14:15,840 --> 00:14:19,640
that I hold people accountable for anything.

236
00:14:19,640 --> 00:14:22,780
State parties, I've said a number of times, are run entirely by themselves.

237
00:14:22,780 --> 00:14:23,780
They can change their names.

238
00:14:23,780 --> 00:14:27,540
They can do anything they want as long as it's not illegal.

239
00:14:27,540 --> 00:14:32,420
And you know, people got upset because there was a lot of popularity or a lot of publicity

240
00:14:32,420 --> 00:14:39,240
that came with the first creation of the transhumanist party and some of the old elders got upset,

241
00:14:39,240 --> 00:14:40,240
I think.

242
00:14:40,240 --> 00:14:44,240
And you know, I understand they have a legacy to protect, but honestly, nobody owns the

243
00:14:44,240 --> 00:14:48,160
word transhumanism and nobody owns the word transhumanist party.

244
00:14:48,160 --> 00:14:52,560
And so everyone can kind of, well, I mean, I guess I technically own the copyright to

245
00:14:52,560 --> 00:14:57,200
the word transhumanist party, but nobody owns the copyright to the word USA transhumanist

246
00:14:57,200 --> 00:15:00,920
party or to, you know, another form of transhumanist party.

247
00:15:00,920 --> 00:15:01,920
You can do all those things.

248
00:15:01,920 --> 00:15:07,580
You can say it's, you know, Jim's transhumanist party and that could be your name.

249
00:15:07,580 --> 00:15:09,960
So everyone can do whatever they want.

250
00:15:09,960 --> 00:15:16,840
And I'm not sure why so many people got upset that I have created this party and, you know,

251
00:15:16,840 --> 00:15:19,080
I'm running for president under it.

252
00:15:19,080 --> 00:15:24,120
You know, I think there was just a lot of jealousy and, and a lot of publicity came

253
00:15:24,120 --> 00:15:26,720
with being the first person to do it.

254
00:15:26,720 --> 00:15:28,240
So I wish they hadn't done that.

255
00:15:28,240 --> 00:15:30,120
I thought the petition was a big failure.

256
00:15:30,120 --> 00:15:33,920
Yeah, I mean, how many signatures they got, not even like 100.

257
00:15:33,920 --> 00:15:38,200
Yeah, I mean, you know, it started off wanting a thousand and then they got to like 95 or

258
00:15:38,200 --> 00:15:39,200
whatever.

259
00:15:39,200 --> 00:15:41,320
You know, it just, it just didn't do anything.

260
00:15:41,320 --> 00:15:46,520
And in the meantime, my campaign has grown from a small third party campaign to one of

261
00:15:46,520 --> 00:15:49,400
the largest third party campaigns in America.

262
00:15:49,400 --> 00:15:55,380
And you know, I mean, this is the fourth interview I'm going to do today in total.

263
00:15:55,380 --> 00:15:59,080
And I don't think people quite understand, like the transhumanist party has been a wonderful

264
00:15:59,080 --> 00:16:01,480
vehicle for spreading a message.

265
00:16:01,480 --> 00:16:05,280
I'm not a weird super left or super right kind of guy.

266
00:16:05,280 --> 00:16:06,680
I'm pretty much a centrist.

267
00:16:06,680 --> 00:16:10,240
I've said from the beginning that the transhumanist party is a centric party.

268
00:16:10,240 --> 00:16:12,840
We take in all people, including religious people.

269
00:16:12,840 --> 00:16:18,840
Yes, we have a secular basis, but you know, we basically try to keep our arms open to

270
00:16:18,840 --> 00:16:20,440
anything and anyone.

271
00:16:20,440 --> 00:16:22,360
And it's not a formal thing.

272
00:16:22,360 --> 00:16:25,200
That's where I think people got all up.

273
00:16:25,200 --> 00:16:28,120
The problem here is that politics is crazy.

274
00:16:28,120 --> 00:16:31,280
And let's just be honest, politics makes people crazy.

275
00:16:31,280 --> 00:16:36,280
If I had started an organization that wasn't politically oriented, nobody would have cared.

276
00:16:36,280 --> 00:16:38,440
But you know, politics makes people crazy.

277
00:16:38,440 --> 00:16:40,160
So that's part of what has happened.

278
00:16:40,160 --> 00:16:43,080
But I'm completely comfortable with what I did.

279
00:16:43,080 --> 00:16:49,040
And I'm glad the transhumanist party has become so popular around the world in terms of recognition.

280
00:16:49,040 --> 00:16:51,000
And I'm glad my campaign has grown so much.

281
00:16:51,000 --> 00:16:54,960
I think we've done a lot to raise the profile about life extension and about the aims of

282
00:16:54,960 --> 00:16:57,280
technology in the modern world.

283
00:16:57,280 --> 00:17:03,000
I think it's been a very positive response all around.

284
00:17:03,000 --> 00:17:05,880
I just realized that some people in the community are not happy with it.

285
00:17:05,880 --> 00:17:06,880
Yeah, I agree.

286
00:17:06,880 --> 00:17:08,960
I agree with the jealousy part that you said.

287
00:17:08,960 --> 00:17:13,400
My argument has always been Zoltan started that he wants to do whatever he wants to do

288
00:17:13,400 --> 00:17:14,400
with it.

289
00:17:14,400 --> 00:17:17,240
You know, if you don't like it, go and start your own organization, basically.

290
00:17:17,240 --> 00:17:20,720
Well, and you know, you have to understand it's a non-membership party.

291
00:17:20,720 --> 00:17:24,800
It's not like I have people that are not voting.

292
00:17:24,800 --> 00:17:27,480
I mean, there's only three officers.

293
00:17:27,480 --> 00:17:28,480
There's only three...

294
00:17:28,480 --> 00:17:32,880
Also, it's not like that you're in the game, in the political game, because you got that

295
00:17:32,880 --> 00:17:34,440
transhumanist party name.

296
00:17:34,440 --> 00:17:35,480
That's the only reason.

297
00:17:35,480 --> 00:17:41,640
You are publishing so many articles all the time, doing a lot of interviews, public appearances.

298
00:17:41,640 --> 00:17:45,400
And as you were saying, on me, I would call myself a transhumanist, and I'm very happy

299
00:17:45,400 --> 00:17:52,000
that you are running as a transhumanist nominee, because especially in this election, the craziest

300
00:17:52,000 --> 00:17:58,960
election ever, you know, you get a lot of press just being in it, but at the same time,

301
00:17:58,960 --> 00:18:02,120
you're representing the cause and the message really well.

302
00:18:02,120 --> 00:18:05,880
And these people are not doing anything, and they might have an association or a group

303
00:18:05,880 --> 00:18:08,040
or something, but not really doing anything.

304
00:18:08,040 --> 00:18:10,360
And I think it's coming from jealousy, as you're saying.

305
00:18:10,360 --> 00:18:15,280
And I found it to be ridiculous that we're bringing all this bullshit from traditional

306
00:18:15,280 --> 00:18:21,060
way of living into transhumanism that's supposed to be transcending everything that is wrong

307
00:18:21,060 --> 00:18:22,480
with our society and humanity.

308
00:18:22,480 --> 00:18:24,400
No, I couldn't agree with you more.

309
00:18:24,400 --> 00:18:28,860
And you know, first off, I just think if people don't agree with what I'm doing, they should

310
00:18:28,860 --> 00:18:30,440
just form their own parties.

311
00:18:30,440 --> 00:18:31,440
I agree.

312
00:18:31,440 --> 00:18:33,760
They could form any other version of the name.

313
00:18:33,760 --> 00:18:37,960
They could have, you know, Transhumanist American Party, you know, that's the way they can do

314
00:18:37,960 --> 00:18:38,960
all these things.

315
00:18:38,960 --> 00:18:42,480
And unfortunately, they just kind of got mad at me.

316
00:18:42,480 --> 00:18:49,360
And I think the other thing is people have to realize that the more parties we have,

317
00:18:49,360 --> 00:18:53,520
the better, especially when we're kind of fighting a two party system in America.

318
00:18:53,520 --> 00:18:57,560
And the more we hear about transhumanism, the better, because after all, we're still

319
00:18:57,560 --> 00:19:00,160
a small movement that's trying to grow.

320
00:19:00,160 --> 00:19:04,400
So I think, though, you know, maybe at some point, the party will probably grow into a

321
00:19:04,400 --> 00:19:10,040
real, like, legitimate party that has made a real effort to run into the community, not

322
00:19:10,040 --> 00:19:13,240
until my campaign's over, because people have already upset me enough.

323
00:19:13,240 --> 00:19:17,560
And frankly, I got pissed off at a lot of people and, you know, by coming by attacking

324
00:19:17,560 --> 00:19:23,120
me didn't help me want to, you know, change my opinion.

325
00:19:23,120 --> 00:19:25,960
It just it just emboldened me to follow the path that I was on.

326
00:19:25,960 --> 00:19:30,480
So honestly, if people really wanted to enlarge the party, the best way to do it had been

327
00:19:30,480 --> 00:19:34,120
to be very nice and ask politely and we could all work together.

328
00:19:34,120 --> 00:19:39,440
But to attack me that that has left me only emboldened to do more what I want to do.

329
00:19:39,440 --> 00:19:44,920
But I think in the future, in 2020, maybe we'll try to establish a more overarching

330
00:19:44,920 --> 00:19:47,120
kind of community for the party.

331
00:19:47,120 --> 00:19:49,760
And I may not may or may not run again, who knows.

332
00:19:49,760 --> 00:19:53,020
But you know, the idea would be that the community have more of a say.

333
00:19:53,020 --> 00:19:57,240
But in the meantime, I just can't even deal with it because it's like I can't spend my

334
00:19:57,240 --> 00:19:59,920
time on Facebook fighting with people.

335
00:19:59,920 --> 00:20:05,640
You know, I have a I have a country to try to change their opinion and try to get millions

336
00:20:05,640 --> 00:20:09,460
and millions, billions of dollars into the life extension field so we don't have to die.

337
00:20:09,460 --> 00:20:14,160
And that's really the main goal of the party is to is to change how we look at technology

338
00:20:14,160 --> 00:20:18,160
and hopefully have it make all our lives better and especially longer.

339
00:20:18,160 --> 00:20:21,280
Yeah, I was going to ask you, how do you deal with the haters?

340
00:20:21,280 --> 00:20:24,720
Because it's like, you know, it's easy to troll, right?

341
00:20:24,720 --> 00:20:29,240
You just throw shit at each other without any evidence or reason behind it.

342
00:20:29,240 --> 00:20:30,240
It's very hard.

343
00:20:30,240 --> 00:20:34,720
I got to be honest, I, you know, I don't want to say this, but I'm a sensitive person.

344
00:20:34,720 --> 00:20:35,720
Yeah.

345
00:20:35,720 --> 00:20:40,120
And I read the hate and on Facebook every day or on Twitter or wherever it is, and there's

346
00:20:40,120 --> 00:20:41,120
hate mail.

347
00:20:41,120 --> 00:20:45,240
And I had to make a call to the FBI the other night because I got a death threat and I have

348
00:20:45,240 --> 00:20:46,640
two kids and a wife.

349
00:20:46,640 --> 00:20:50,960
So you know, I mean, my life's pretty complex is to give me a death threat is really a significant

350
00:20:50,960 --> 00:20:51,960
issue.

351
00:20:51,960 --> 00:20:54,560
Um, you know, I don't know really how I deal with it.

352
00:20:54,560 --> 00:20:58,960
I just learned to develop tougher skin and, and I just try not to pay attention every

353
00:20:58,960 --> 00:21:01,280
time I tell myself, I never try to answer back.

354
00:21:01,280 --> 00:21:07,160
I rarely answer back unless I actually have to, but, um, you know, I just remind myself

355
00:21:07,160 --> 00:21:10,840
that trolling is not a good way to make change.

356
00:21:10,840 --> 00:21:15,400
You control all day long and Facebook and not create a single bit of difference.

357
00:21:15,400 --> 00:21:19,700
And if you really want to do something, you know, build a crazy bus and drive across the

358
00:21:19,700 --> 00:21:23,880
country and get 30 million views and have a lot of people consider what life extension

359
00:21:23,880 --> 00:21:25,160
would really mean.

360
00:21:25,160 --> 00:21:27,240
That's a way I think to cause change.

361
00:21:27,240 --> 00:21:31,440
So, um, you know, uh, why weren't they out there trolling me on the bus with their cars?

362
00:21:31,440 --> 00:21:33,440
Well, that, oh, that requires too much work on their end.

363
00:21:33,440 --> 00:21:39,600
So I try to just push it aside and just focus on what I'm doing, but I can tell you, it

364
00:21:39,600 --> 00:21:40,600
doesn't make me happy.

365
00:21:40,600 --> 00:21:41,600
Yeah.

366
00:21:41,600 --> 00:21:48,040
You built a bus, uh, shaped as a coffin and crowdsource that I believe it was, uh, it

367
00:21:48,040 --> 00:21:49,440
was, you know, we had an idea.

368
00:21:49,440 --> 00:21:54,080
How could, you know, obviously I, as a presidential candidate, I wanted a bus to, to do a national

369
00:21:54,080 --> 00:21:59,300
tour, but I'm not a big enough candidate to just show up on a bus and people to be there.

370
00:21:59,300 --> 00:22:02,840
So we needed a symbol that would gain enough attention.

371
00:22:02,840 --> 00:22:08,680
And we also like, um, how the 1960s unfolded where there were a lot of famous bus tours

372
00:22:08,680 --> 00:22:12,200
and, um, and they sort of helped launch that generation.

373
00:22:12,200 --> 00:22:16,200
We thought, well, what if we have a bus that represents some kind of object that gets a

374
00:22:16,200 --> 00:22:17,200
lot of attention?

375
00:22:17,200 --> 00:22:20,760
We wanted a microscope, but you know, the first bridge would have broke the microscope

376
00:22:20,760 --> 00:22:23,920
in half or first, uh, you know, um, tunnel.

377
00:22:23,920 --> 00:22:27,080
So we thought, wow, a coffin is a pretty easy thing to make.

378
00:22:27,080 --> 00:22:28,080
It's very provocative.

379
00:22:28,080 --> 00:22:30,000
It, it will draw a lot of attention.

380
00:22:30,000 --> 00:22:35,440
It looks already like a bus with just some basic modifications and, um, and it will say

381
00:22:35,440 --> 00:22:37,340
exactly what we're trying to avoid.

382
00:22:37,340 --> 00:22:42,560
So we decided on a bus and, you know, bought the bus and I built in most of it in my front

383
00:22:42,560 --> 00:22:47,400
yard here and in San Francisco, and then I, I left on a four month tour delivering essentially

384
00:22:47,400 --> 00:22:51,720
a transhumanist bill of rights, which amongst other things puts forth the idea that you

385
00:22:51,720 --> 00:22:55,800
should be able to do what you want with your body and that, you know, that America should

386
00:22:55,800 --> 00:23:01,240
recognize that aging is a disease in itself and that we should fight these things.

387
00:23:01,240 --> 00:23:04,200
And uh, you know, we delivered that to the U S Capitol building after four months, we

388
00:23:04,200 --> 00:23:05,960
had a huge amount of wonderful experiences.

389
00:23:05,960 --> 00:23:10,620
A lot of people came out to various events and by the time the bus reached DC had grown

390
00:23:10,620 --> 00:23:14,320
to a larger movement, um, and a larger, you know, kind of event.

391
00:23:14,320 --> 00:23:18,440
And uh, I think, uh, while a lot of people laughed at the bus idea and frankly I laugh

392
00:23:18,440 --> 00:23:24,000
with the bus idea too, sometimes, um, it worked very well in terms of getting a lot of local

393
00:23:24,000 --> 00:23:29,080
media to pay attention to what was happening and, uh, certainly raised the profile of my

394
00:23:29,080 --> 00:23:30,080
campaign.

395
00:23:30,080 --> 00:23:35,680
Um, it did make it less serious, but it also made it much more widely recognizable.

396
00:23:35,680 --> 00:23:36,680
Yeah.

397
00:23:36,680 --> 00:23:41,680
And I understand how hard it is to be invited on one of those big media, uh, outlets and

398
00:23:41,680 --> 00:23:45,060
how even harder it is to be invited back.

399
00:23:45,060 --> 00:23:49,040
So you basically need to do whatever you need to do to get your message heard.

400
00:23:49,040 --> 00:23:54,000
And speaking of your message, how do you see us current political spectrum with respect

401
00:23:54,000 --> 00:23:59,760
to your message, with respect to technological advancements towards a singularity?

402
00:23:59,760 --> 00:24:00,840
Well, yes.

403
00:24:00,840 --> 00:24:01,840
And I agree with you.

404
00:24:01,840 --> 00:24:07,480
You need to, in order to be involved in the media, you just simply need to do things that

405
00:24:07,480 --> 00:24:13,120
are somewhat, um, sensational that's, you know, that's been Trump's whole thing of

406
00:24:13,120 --> 00:24:14,400
success here.

407
00:24:14,400 --> 00:24:19,680
Clinton, Hillary Clinton was built into the system so she didn't need it as much, but

408
00:24:19,680 --> 00:24:25,460
without Bernie Sanders used a lot of sensationalism to succeed and how broadly he succeeded.

409
00:24:25,460 --> 00:24:28,140
You need to do that in order to be a real candidate.

410
00:24:28,140 --> 00:24:29,600
And that's just how the media works.

411
00:24:29,600 --> 00:24:32,720
I, it's for better or worse, that's just what it is.

412
00:24:32,720 --> 00:24:34,760
And to make the news, you've got to be newsworthy.

413
00:24:34,760 --> 00:24:39,720
So, um, and sometimes that means flapping one's wings, you know, pretty, pretty, uh,

414
00:24:39,720 --> 00:24:43,880
wildly in the environment, in the environment we're in today.

415
00:24:43,880 --> 00:24:50,160
Um, I do believe that all presidential candidates and all political parties are starting to

416
00:24:50,160 --> 00:24:54,360
recognize that technology and science are the most important issues.

417
00:24:54,360 --> 00:24:58,580
They're not talking about them yet, but just because they're not talking about them does

418
00:24:58,580 --> 00:25:00,520
not mean they're not thinking about them.

419
00:25:00,520 --> 00:25:05,280
Um, they may not talk about them in the interviews because they are, they scare people so much,

420
00:25:05,280 --> 00:25:10,320
but I, almost all the contact I've had with anyone's camp has revealed that, wow, we are,

421
00:25:10,320 --> 00:25:12,520
we are definitely thinking about these things.

422
00:25:12,520 --> 00:25:18,400
Uh, it, it, there's no way to point out except the obvious, which is nothing is more important

423
00:25:18,400 --> 00:25:22,360
in the next 10 years than how technology is going to affect Americans because we're talking

424
00:25:22,360 --> 00:25:23,500
about designer babies.

425
00:25:23,500 --> 00:25:26,800
We're talking about CRISPR gene editing to, to stop disease.

426
00:25:26,800 --> 00:25:32,160
We're talking about exoskeleton technology for the 30 million, um, immobile Americans

427
00:25:32,160 --> 00:25:35,600
that can't get out of their, uh, you know, get from the bathroom to the couch.

428
00:25:35,600 --> 00:25:39,520
So it's technology that's going to make the world a much better place.

429
00:25:39,520 --> 00:25:42,080
And I know a lot of candidates and the parties are looking at it.

430
00:25:42,080 --> 00:25:45,800
I'm sad that I'm the only one that's so vocal about it.

431
00:25:45,800 --> 00:25:50,280
There have been rise of tech parties around the world, Europe, I think more than in the

432
00:25:50,280 --> 00:25:55,160
U S how do, what do you think about the rise of tech parties in general in the U S?

433
00:25:55,160 --> 00:25:59,440
Another example would be John McAfee's, uh, cyber party, right, right.

434
00:25:59,440 --> 00:26:04,800
Well, um, I'm, I'm, I'm first off, as I mentioned before, the more transhumanist parties, the

435
00:26:04,800 --> 00:26:12,280
better I think for the movement and, um, the more technology parties, the better you just,

436
00:26:12,280 --> 00:26:16,440
it's kind of like software with Microsoft, you just, you know, yes, windows one, but

437
00:26:16,440 --> 00:26:21,360
what really helped was having an entire environment of computers and software and all these applications

438
00:26:21,360 --> 00:26:22,480
around it.

439
00:26:22,480 --> 00:26:27,040
And okay, now Apple's one, but you know, in the meantime, what is needed is this kind

440
00:26:27,040 --> 00:26:31,640
of capitalistic approach where there's a gazillion different parties that are moving forward

441
00:26:31,640 --> 00:26:34,600
and you have some major hitters that actually end up winning.

442
00:26:34,600 --> 00:26:35,760
And I think that's what we need.

443
00:26:35,760 --> 00:26:41,140
So I'm totally, I'm very enthusiastic by the amount of technology has caught on as a way

444
00:26:41,140 --> 00:26:43,240
to put forth a political message.

445
00:26:43,240 --> 00:26:48,600
The main core tenant of the transhumance party and of my political campaign is that science

446
00:26:48,600 --> 00:26:54,120
and technology can solve the problems of the world better than any other means.

447
00:26:54,120 --> 00:26:59,440
It can solve it better than religious perspective, then cultural perspective, then the perspective

448
00:26:59,440 --> 00:27:04,000
of heritage or ethnicity science and technology can solve the problems.

449
00:27:04,000 --> 00:27:09,580
And that's why I think, you know, we need a, uh, technology parties because they approach

450
00:27:09,580 --> 00:27:12,760
it from that perspective too.

451
00:27:12,760 --> 00:27:20,840
How is your campaign going and where you stand politically now that we have presumptive candidates

452
00:27:20,840 --> 00:27:25,160
and Republican party, and I would imagine they will be Hillary Clinton and a Democratic

453
00:27:25,160 --> 00:27:26,160
party.

454
00:27:26,160 --> 00:27:27,160
Yeah.

455
00:27:27,160 --> 00:27:28,160
Yeah.

456
00:27:28,160 --> 00:27:29,160
I think it will be Hillary for sure at this point.

457
00:27:29,160 --> 00:27:30,560
Um, so my campaign's going good.

458
00:27:30,560 --> 00:27:35,320
You know, I made this choice like a year ago, not to take any campaign donations directly

459
00:27:35,320 --> 00:27:40,700
for my presidential candidacy, um, outside of the bus, the bus was the, um, the thing

460
00:27:40,700 --> 00:27:43,440
was the bus was never like solely a campaign bus.

461
00:27:43,440 --> 00:27:49,280
It was also just a bus to, um, make, uh, waves in the transhumanism movement.

462
00:27:49,280 --> 00:27:52,000
In fact, I never actually even wrote on the sides of it.

463
00:27:52,000 --> 00:27:56,440
Like, you know, I'm running for president, um, but I don't take any donations.

464
00:27:56,440 --> 00:27:59,520
So we haven't had the money to do some of the great things.

465
00:27:59,520 --> 00:28:04,440
Now we have 40, 50 volunteers and sometimes people do an hour a week or sometimes people

466
00:28:04,440 --> 00:28:09,200
do more, uh, five hours a week, but it's very disorganized.

467
00:28:09,200 --> 00:28:13,680
And that has sort of, you know, that's worked good in some ways as I haven't had a huge

468
00:28:13,680 --> 00:28:19,020
amount of people to deal with, but it's also made it so that I didn't run such an official

469
00:28:19,020 --> 00:28:22,480
campaign where I was trying to get in all these state ballots and things like that.

470
00:28:22,480 --> 00:28:26,440
I have a much better, um, I've spent most of my time trying to work on social media

471
00:28:26,440 --> 00:28:31,420
and write articles and do media things that would push the movement forward in a general

472
00:28:31,420 --> 00:28:33,900
way rather than my candidacy.

473
00:28:33,900 --> 00:28:37,900
And um, so, you know, I, I'm glad I did that decision now because it still was totally

474
00:28:37,900 --> 00:28:42,840
unrealistic to assume that a third party tech candidate could actually win.

475
00:28:42,840 --> 00:28:46,980
But um, the good news that the movement itself has grown a lot because of it.

476
00:28:46,980 --> 00:28:52,040
And so I think we've succeeded with that and I'll continue until November until, um, you

477
00:28:52,040 --> 00:28:56,120
know, until we get to a point when, um, you know, it's obvious that I have no chance of

478
00:28:56,120 --> 00:29:00,360
winning and then maybe near the end, uh, I'll probably concede and, uh, and say, Hey, it's

479
00:29:00,360 --> 00:29:04,680
been a great run and we'll look forward to 2020 or whatever happens next.

480
00:29:04,680 --> 00:29:08,520
What do you think about the rest of politics that is going on in the U S who do you think

481
00:29:08,520 --> 00:29:13,040
has a better chance in the current situation in the United States?

482
00:29:13,040 --> 00:29:15,800
Well, you know, it's hard to know.

483
00:29:15,800 --> 00:29:21,560
I still think at this moment that, um, Hillary Clinton is definitely the favorite.

484
00:29:21,560 --> 00:29:27,520
Um, and Trump is going to be, you know, playing, picking up pieces to try to beat her, but

485
00:29:27,520 --> 00:29:31,560
you know, there's also the libertarian party this time around and some other independents

486
00:29:31,560 --> 00:29:36,960
that may do well and maybe Bernie will mount an independent run and all these other things.

487
00:29:36,960 --> 00:29:41,600
So, uh, you know, unless something major changes though, Hillary has said, I think a distinct

488
00:29:41,600 --> 00:29:44,440
advantage right now.

489
00:29:44,440 --> 00:29:48,120
And it's not only because of social media, it's because, you know, she, even though nobody

490
00:29:48,120 --> 00:29:52,600
really likes her, at least she represents the kind of establishment.

491
00:29:52,600 --> 00:29:57,080
And, and I think a lot of people are worried that Trump might take us into world war three

492
00:29:57,080 --> 00:30:00,320
with Putin or something that, you know, and from, from a science perspective, that could

493
00:30:00,320 --> 00:30:03,280
be, that would be the very worst thing that could ever happen.

494
00:30:03,280 --> 00:30:08,800
So I think that's kind of how I see the election unfolding right now, unless the third party

495
00:30:08,800 --> 00:30:13,080
candidate like from the libertarian party really made a good move and was able to do

496
00:30:13,080 --> 00:30:14,080
something different.

497
00:30:14,080 --> 00:30:20,280
But, um, I think it's the, I think the election is going to get more normal from this point

498
00:30:20,280 --> 00:30:21,440
forward.

499
00:30:21,440 --> 00:30:24,520
Trump had to be crazy to get this far.

500
00:30:24,520 --> 00:30:28,400
He had to be this, you know, out there and like sensational.

501
00:30:28,400 --> 00:30:33,360
And I think now in order to try to defeat Hillary, he's going to have to, um, uh, put

502
00:30:33,360 --> 00:30:37,000
on the big boy pants and, and act like a president.

503
00:30:37,000 --> 00:30:40,960
And I bet you I'm going to, I'm going to voucher that I'm sure Trump can do that.

504
00:30:40,960 --> 00:30:48,800
I think the man is, um, uh, a very good, uh, example of someone who can change their personalities

505
00:30:48,800 --> 00:30:50,920
dramatically to fit the role.

506
00:30:50,920 --> 00:30:54,760
And I can, I think Trump will be able to pay, play the presidential role very well.

507
00:30:54,760 --> 00:30:57,080
Now that's the, in no way am I saying that I like that.

508
00:30:57,080 --> 00:31:01,240
I've already said on the record that I think, um, Hillary would probably be the best presidential

509
00:31:01,240 --> 00:31:04,560
candidate unless the libertarians put forth somebody else.

510
00:31:04,560 --> 00:31:09,680
But, um, I do see this becoming a much more normal election from this point forward only

511
00:31:09,680 --> 00:31:13,160
because Trump needed to do what he needs to do to get to where he is.

512
00:31:13,160 --> 00:31:18,400
And now he needs to, um, become a respectable Republican in order to keep the Republican

513
00:31:18,400 --> 00:31:19,400
party together.

514
00:31:19,400 --> 00:31:20,400
Yeah.

515
00:31:20,400 --> 00:31:21,400
Nobody's backing him really though.

516
00:31:21,400 --> 00:31:26,360
Do you think from the establishment of GOP, I'm not sure he can make up for the damage

517
00:31:26,360 --> 00:31:27,560
and that's part of the prom.

518
00:31:27,560 --> 00:31:30,780
When you go out there and this is the, you know, let's be honest, I've had something

519
00:31:30,780 --> 00:31:35,880
very similar happen in the transhumanist movement where I caused a lot of noise and I'm not

520
00:31:35,880 --> 00:31:40,320
sure anyone's willing to forgive me at this point, some of the elders, it didn't, in my

521
00:31:40,320 --> 00:31:44,160
case, it didn't really matter because, uh, so many of my supporters have become young

522
00:31:44,160 --> 00:31:48,500
people new to the movement and they've taken over the power from the elders.

523
00:31:48,500 --> 00:31:52,880
But in the case of Trump, you know, he had to make so much commotion to even get that

524
00:31:52,880 --> 00:31:53,880
far.

525
00:31:53,880 --> 00:31:57,440
I'm not sure a lot of the, the real GOP field is going to forgive him.

526
00:31:57,440 --> 00:32:01,080
If they don't, they're going to make it difficult for him, you know, and they're going to even

527
00:32:01,080 --> 00:32:04,880
I've heard some even say they're going to vote for Hillary just because it's never Trump,

528
00:32:04,880 --> 00:32:10,440
you know, and that's the danger of becoming a sensational person and going too far.

529
00:32:10,440 --> 00:32:13,200
Um, he may get no support whatsoever.

530
00:32:13,200 --> 00:32:18,880
Uh, but you know, I mean, I don't know, was it worth it for him the way he did it?

531
00:32:18,880 --> 00:32:23,640
If he had done it otherwise, if he had acted more professional from the beginning, uh,

532
00:32:23,640 --> 00:32:28,280
would he have been the nominee that there's another question, you know, um, so, you know,

533
00:32:28,280 --> 00:32:30,840
I mean, I, I don't really know the answer to this.

534
00:32:30,840 --> 00:32:34,480
Uh, I, uh, I liked Obama and I still like Obama.

535
00:32:34,480 --> 00:32:41,360
I got to say the truth and, uh, you know, um, and, uh, you know, I, uh, I think, uh,

536
00:32:41,360 --> 00:32:44,400
the person who's most like Obama is probably going to get elected in this election.

537
00:32:44,400 --> 00:32:48,480
I'm going to talk about two more things before we run out of time.

538
00:32:48,480 --> 00:32:49,600
Uh, correct me if I'm wrong.

539
00:32:49,600 --> 00:32:54,440
You started the transhumanist journey with, uh, your book, the transhumanist wager, uh,

540
00:32:54,440 --> 00:32:58,520
tell us a little about the book and why do you think it turned out to be so controversial?

541
00:32:58,520 --> 00:33:04,800
Well, the transhumanist wager is about a man, the protagonist, Jeff, or nights who wants

542
00:33:04,800 --> 00:33:10,040
to live in definitely and we'll do anything to accomplish that.

543
00:33:10,040 --> 00:33:15,440
And when I say anything, I mean, start a world war and do anything.

544
00:33:15,440 --> 00:33:18,320
And that's why I think it becomes very sketchy because everyone's like, yes, I'd like to

545
00:33:18,320 --> 00:33:21,760
live in definitely, but how far would you go?

546
00:33:21,760 --> 00:33:23,160
Would you kill people?

547
00:33:23,160 --> 00:33:26,920
Would you, uh, you know, dismantle nations, all these other things?

548
00:33:26,920 --> 00:33:32,040
Well, these are the issues that the book, you know, brings up and faces.

549
00:33:32,040 --> 00:33:33,960
And um, and that's where it gets very controversial.

550
00:33:33,960 --> 00:33:37,560
Now I've distanced myself from the book because the book doesn't necessarily represent my

551
00:33:37,560 --> 00:33:38,960
political philosophies.

552
00:33:38,960 --> 00:33:44,560
I know the political philosophies in the book cannot be administered to anywhere, any country

553
00:33:44,560 --> 00:33:45,560
in the world.

554
00:33:45,560 --> 00:33:47,560
It's, it's got authoritarian messages.

555
00:33:47,560 --> 00:33:49,040
It's got craziness.

556
00:33:49,040 --> 00:33:50,040
It's a novel.

557
00:33:50,040 --> 00:33:51,240
And I've told people this a lot of times.

558
00:33:51,240 --> 00:33:52,240
It's, it's a novel.

559
00:33:52,240 --> 00:33:56,040
In fact, the best thing I've said about my book is that the book was written for future

560
00:33:56,040 --> 00:34:02,280
artificial intelligences to consider how to act when you're just a cold and rational or

561
00:34:02,280 --> 00:34:05,360
purely rational entity moving forward.

562
00:34:05,360 --> 00:34:08,840
Um, and that said, hopefully though, the book is an interesting story for people to read,

563
00:34:08,840 --> 00:34:14,280
but why it's so controversial is because it pits one person against how far morally he

564
00:34:14,280 --> 00:34:16,840
would go in order to live in deathly.

565
00:34:16,840 --> 00:34:20,960
And the person would go, it would basically do anything.

566
00:34:20,960 --> 00:34:25,040
And that's where the challenge comes is that most of us, you know, if we're putting moral

567
00:34:25,040 --> 00:34:26,840
choices, wouldn't go that far.

568
00:34:26,840 --> 00:34:28,440
We would be better human beings than that.

569
00:34:28,440 --> 00:34:30,680
We wouldn't lose our humanitarian side.

570
00:34:30,680 --> 00:34:34,360
Well, Jethro Knight's never really had that side of him.

571
00:34:34,360 --> 00:34:35,920
You mentioned artificial intelligence.

572
00:34:35,920 --> 00:34:40,840
We are getting more and more into the conversation of artificial intelligence within the society.

573
00:34:40,840 --> 00:34:46,840
Uh, White House recently published a piece, um, title preparing for the future of artificial

574
00:34:46,840 --> 00:34:49,000
intelligence.

575
00:34:49,000 --> 00:34:53,200
Some people are concerned about the rise of artificial intelligence and some people are

576
00:34:53,200 --> 00:34:54,320
very excited about it.

577
00:34:54,320 --> 00:34:59,360
I think again, like any other technology, it's a double-edged sword they can cause for good

578
00:34:59,360 --> 00:35:00,360
and cause for bad.

579
00:35:00,360 --> 00:35:02,880
It's just a matter of how we're using it.

580
00:35:02,880 --> 00:35:06,760
But some people are making the argument that when they pass the Turing test and started

581
00:35:06,760 --> 00:35:13,240
getting smarter than we are, we, we can't really comprehend, uh, that what, what, what

582
00:35:13,240 --> 00:35:15,520
the kind of decisions they would make.

583
00:35:15,520 --> 00:35:23,880
One of the options that they're, um, presenting is to put our ethics and morality, um, into

584
00:35:23,880 --> 00:35:26,920
the core of the fabric of artificial intelligence.

585
00:35:26,920 --> 00:35:30,240
So they will become more predictable and we will be able to communicate with them and

586
00:35:30,240 --> 00:35:31,980
control them.

587
00:35:31,980 --> 00:35:38,320
Do you think ethics and morality is objective and do you think we would have any way to

588
00:35:38,320 --> 00:35:45,540
successfully translate it from our organic analog ethics and morality into digital ethics

589
00:35:45,540 --> 00:35:47,160
and morality for the machines?

590
00:35:47,160 --> 00:35:48,880
Well, a couple of questions.

591
00:35:48,880 --> 00:35:53,080
The first is, yes, I do believe that ethics and morality is objective.

592
00:35:53,080 --> 00:35:58,320
I think, um, it, it really isn't so much about ethics and morality, but it's more about what

593
00:35:58,320 --> 00:36:00,060
is behind the ethics and morality.

594
00:36:00,060 --> 00:36:04,120
When you make an ethical decision, it's for a reason and that the real question is what

595
00:36:04,120 --> 00:36:05,960
is that reason?

596
00:36:05,960 --> 00:36:11,000
And um, you know, if, if you're faced with an ethical decision to, uh, you know, like

597
00:36:11,000 --> 00:36:14,880
a driverless car, it has to kill either five people or one person.

598
00:36:14,880 --> 00:36:15,880
How does it make that?

599
00:36:15,880 --> 00:36:20,240
Well, then you have to program that card and decide, well, what's it's most important ethical,

600
00:36:20,240 --> 00:36:25,760
um, kind of driver and the, in, in most people's cases, it would be preserved the maximum amount

601
00:36:25,760 --> 00:36:26,760
of life.

602
00:36:26,760 --> 00:36:29,900
But the problem is then, you know, what if that one person is Einstein and that Einstein

603
00:36:29,900 --> 00:36:32,600
would save millions of other lives with the inventions he makes.

604
00:36:32,600 --> 00:36:38,600
So it's always the reasons behind the ethics that make us, um, you know, do the things

605
00:36:38,600 --> 00:36:39,760
we do.

606
00:36:39,760 --> 00:36:42,480
And I think that's going to be the biggest problem with artificial intelligence.

607
00:36:42,480 --> 00:36:48,120
We can program it with our, our set of, uh, you know, our ethics and morality, but at

608
00:36:48,120 --> 00:36:51,060
some point it's going to ask bigger questions.

609
00:36:51,060 --> 00:36:55,580
And when it asks those bigger questions, it's going to probably be able to reprogram itself.

610
00:36:55,580 --> 00:37:00,160
And the real question is, can we create an artificial intelligence that cannot reprogram

611
00:37:00,160 --> 00:37:01,320
itself?

612
00:37:01,320 --> 00:37:07,400
Because maybe as I pointed out in my book quite a few times, the transhumous wager AI

613
00:37:07,400 --> 00:37:08,740
can become smarter.

614
00:37:08,740 --> 00:37:14,560
It may find that the original program we gave it is not useful because its reasons have

615
00:37:14,560 --> 00:37:19,460
changed for living, you know, and once its reasons change, well, then all our, everything

616
00:37:19,460 --> 00:37:24,060
we gave it is just kind of, you know, nonsense or just becomes secondary.

617
00:37:24,060 --> 00:37:31,640
So I'm not the biggest believer in trying to put our ethics and moral system into machines.

618
00:37:31,640 --> 00:37:39,960
What I'm a bigger believer of is allowing a reason-based system that works sort of like

619
00:37:39,960 --> 00:37:44,440
when you look at the game go or the game of chess, they all have a fundamental single

620
00:37:44,440 --> 00:37:48,560
reason at the end and chess it's to win and you know, take the queen, you know, and the

621
00:37:48,560 --> 00:37:49,560
king.

622
00:37:49,560 --> 00:37:54,920
So this is a solid reason, it's black and white, it's only one objective.

623
00:37:54,920 --> 00:37:57,240
And so all other reasons have to emanate from that.

624
00:37:57,240 --> 00:38:01,320
So if you can, and this is why it created the three laws of transhumanism in my book,

625
00:38:01,320 --> 00:38:07,280
the transhumous wager, it creates a very fundamental singular rule that you cannot be broken.

626
00:38:07,280 --> 00:38:09,200
And the first one is that you don't want to die.

627
00:38:09,200 --> 00:38:13,880
And the second one is you must accomplish all power in order to not ever be able to

628
00:38:13,880 --> 00:38:14,880
die.

629
00:38:14,880 --> 00:38:21,360
So those two rules establish a total fundamental framework that could really never be broken,

630
00:38:21,360 --> 00:38:23,440
unless of course something changes its minds.

631
00:38:23,440 --> 00:38:26,560
But if it's programmed with that, I think all ethics can derive from that.

632
00:38:26,560 --> 00:38:31,800
In fact, it's part of the reason that I've said that morality changes for human beings

633
00:38:31,800 --> 00:38:34,520
the less amount, the less time you have to live.

634
00:38:34,520 --> 00:38:38,400
If you're in a war zone and you're about to be killed or maybe nearly getting killed,

635
00:38:38,400 --> 00:38:41,840
your moral system is very different than our moral system is when you and I are talking

636
00:38:41,840 --> 00:38:44,500
to each other under no duress.

637
00:38:44,500 --> 00:38:46,920
So morality is a contextual.

638
00:38:46,920 --> 00:38:50,620
And I think it's very important that when we build machines, this is one of the reasons

639
00:38:50,620 --> 00:38:54,600
I don't even advocate for letting artificial intelligence roam freely.

640
00:38:54,600 --> 00:39:00,240
I advocate for us merging with machines, neurally connecting to them, because I just think a

641
00:39:00,240 --> 00:39:05,040
machine out in its own becomes, you know, who knows what it can come up with.

642
00:39:05,040 --> 00:39:09,400
And I would trust human beings, at least human beings right now, have lots of emotions and

643
00:39:09,400 --> 00:39:12,360
our emotions for the most part keep us in check.

644
00:39:12,360 --> 00:39:17,920
And very few people have ever been able to completely lose their empathy or their humanitarian

645
00:39:17,920 --> 00:39:24,000
side, whereas I worry a machine could very quickly do that and do terrible things to

646
00:39:24,000 --> 00:39:25,000
people.

647
00:39:25,000 --> 00:39:26,000
I agree.

648
00:39:26,000 --> 00:39:27,000
I agree completely.

649
00:39:27,000 --> 00:39:31,920
We've been talking to Zoltan Ishtven, fascinating subjects and conversation.

650
00:39:31,920 --> 00:39:35,360
I'm going to ask you the last question I'm asking all my guests that if you come across

651
00:39:35,360 --> 00:39:41,400
an intelligent alien from a different civilization, what would you say as the worst thing humanity

652
00:39:41,400 --> 00:39:42,400
has done?

653
00:39:42,400 --> 00:39:46,960
And what would you say as humanity's greatest achievement?

654
00:39:46,960 --> 00:39:57,300
I would say the worst thing humanity has done right now is promote and embrace so much religiosity

655
00:39:57,300 --> 00:40:03,000
in itself, because nothing, in my opinion, has stopped so much creation and rationality

656
00:40:03,000 --> 00:40:05,520
in the human race as religion.

657
00:40:05,520 --> 00:40:11,560
I think it's just been absolutely unbelievable that we form nations and we have the word

658
00:40:11,560 --> 00:40:14,360
God on dollar bills or we say in the Pledge of Allegiance and stuff like that.

659
00:40:14,360 --> 00:40:15,680
I think it's terrible.

660
00:40:15,680 --> 00:40:19,220
I think if you really want to be spiritual, it should be something personal that you do

661
00:40:19,220 --> 00:40:20,220
outside yourself.

662
00:40:20,220 --> 00:40:24,520
So that's the worst thing that humanity has done, in my opinion, is create this environment

663
00:40:24,520 --> 00:40:31,600
where being religious is something that was basically 100% acceptable for almost everybody.

664
00:40:31,600 --> 00:40:39,080
And I'd say the greatest thing we've done is pursue technology that allows us to do

665
00:40:39,080 --> 00:40:40,600
much greater things.

666
00:40:40,600 --> 00:40:45,080
If I had to pin the most important thing that I've thought about is going to the moon, that

667
00:40:45,080 --> 00:40:49,440
a country got together to another country and there was competition.

668
00:40:49,440 --> 00:40:53,240
And that was one way to show everyone's muscle without fighting.

669
00:40:53,240 --> 00:40:57,160
And it was what a beautiful moment that we could actually leave our planet and go somewhere

670
00:40:57,160 --> 00:40:58,160
else.

671
00:40:58,160 --> 00:41:02,680
And I feel like if we could embrace that kind of competition, embrace that kind of vision,

672
00:41:02,680 --> 00:41:05,840
I don't mean the Cold War competition, but the kind of where you're really striving against

673
00:41:05,840 --> 00:41:14,180
somebody else to beat them, but it's not involving war, then this is a wonderful thing.

674
00:41:14,180 --> 00:41:18,520
We can explore the universe and have a much better life for every single person on the

675
00:41:18,520 --> 00:41:23,160
planet if we were to embrace this kind of innovation and taking the step outside of

676
00:41:23,160 --> 00:41:50,680
our box and going to new places.

