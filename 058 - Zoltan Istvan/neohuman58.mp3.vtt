WEBVTT

00:00.000 --> 00:06.240
We need to win this. America needs to continue to own innovation across the world, because it's such

00:06.240 --> 00:11.360
a critical moment in time to not lose our leadership, to make sure that democracy actually

00:11.360 --> 00:17.120
survives. China is not a democracy. The voting system is completely different than how we have

00:17.120 --> 00:22.560
it here. So we need to make sure we win this game. Otherwise, it's going to be a very, very different

00:22.560 --> 00:37.520
world. Hello, and welcome to the 58th episode of Neohuman Podcasts. I'm Agabahari Adygologist

00:37.520 --> 00:41.120
on Twitter and Instagram, and you can follow the show on LiveInLimbo.com,

00:41.680 --> 00:47.440
iTunes, YouTube, and BitChute. And with me, I'm welcoming back for the third time on Neohuman

00:47.440 --> 00:53.040
Podcast, Zoltan Isman. Welcome back to Neohuman Podcast, Zoltan. Thank you for having me again.

00:53.040 --> 00:57.920
Yeah, absolutely, man. Always a pleasure. For those of our audience who are not familiar with

00:58.480 --> 01:01.920
your work and who you are and what you've done, why don't we start with your background,

01:01.920 --> 01:05.760
the work you've done and the lives you've lived, and what are you mainly focused on now these days?

01:06.720 --> 01:11.360
Sure. Well, you know, a lot of people know me as the transhumanist guy, the guy who wants to merge

01:11.360 --> 01:17.200
people with machines using science and technology. And just so your listeners know, transhumanism is

01:17.200 --> 01:20.960
a social movement of many millions of people around the world that want to use science and

01:20.960 --> 01:26.960
technology to upgrade the human being. However, my specialty in this field has really been running

01:26.960 --> 01:32.240
political campaigns where I emphasize science and technology. I ran in 2016 as a presidential

01:32.240 --> 01:38.240
candidate, in 2018 as a libertarian gubernatorial candidate in California, and now I'm running again

01:38.240 --> 01:44.640
as a Republican in the 2020 presidential race. What is so interesting about getting involved

01:44.640 --> 01:51.360
in United States politics now these days considering all the division and all the very unscientific

01:51.360 --> 01:56.560
and sometimes anti-tech kind of a narrative that is going on within the partisan politics

01:56.560 --> 02:03.760
here in the United States here? Well, you know, I mean, it just feels like some people really like

02:03.760 --> 02:09.280
radical science and tech, and some people don't. And, you know, if you like it, then you're very

02:09.280 --> 02:14.480
interested in it. But if you're, you know, against it for some reason, because maybe you're either

02:15.680 --> 02:20.800
super religious, or maybe you're super, just don't want to change, or you're really like

02:20.800 --> 02:25.520
an older person, a lot of older people just don't seem to really like transhumanism that much,

02:25.520 --> 02:30.160
then you might not be into it. But in terms of politics, like really nothing is changing

02:30.160 --> 02:34.560
our world, the American world more than artificial intelligence, genetic editing,

02:34.560 --> 02:39.280
brain implants. I mean, these are things that are going to become the huge next drivers of the

02:39.280 --> 02:45.520
economy, as well as kind of where the future is going in the next 10 to 20 years. So I think

02:45.520 --> 02:50.400
politics must play a very big role of it. And that's sort of where my policy and my campaigns

02:50.400 --> 02:55.120
come in, as I try to make a statement for those things that other candidates won't talk about.

02:55.120 --> 02:59.760
Yeah, that's exactly what I mean, that nobody's really talking about the AI, genetic engineering,

02:59.760 --> 03:05.040
and all the important things. But they're all fighting with each other over basically partisan

03:05.040 --> 03:11.200
bullshit. So my bigger point is that what is the point of trying to get anything done in such a

03:11.200 --> 03:17.200
broken system from within when a lot can be done from outside of a system like we see that big tech

03:17.200 --> 03:23.840
companies have far more impact than let's say, representatives in DC. Well, you know, so I've

03:23.840 --> 03:27.680
tried this before, just you know, when I ran for the Libertarians, which is of course, the third

03:27.680 --> 03:33.920
party, unless you have structure built into the system, either through the Democrats or the

03:33.920 --> 03:40.400
Republicans, it's very hard as an independent to get any kind of real traction, because all 50

03:40.400 --> 03:45.920
states have ballot requirements. And some of those ballot requirements are incredibly expensive

03:45.920 --> 03:51.680
millions of dollars to get on. So if you really want to kind of play in the big leagues, you kind

03:51.680 --> 03:57.840
of have to choose one or two, you know, one of the two parties. I don't like that. I wish we had a

03:57.840 --> 04:02.720
stronger third party in, you know, here in America and other independent candidates that can make a

04:02.720 --> 04:07.760
difference. But really, if you want to be in the game, you kind of have to follow those rules of

04:07.760 --> 04:12.720
one side or the other. And I chose the side just because I'm just really conservative. And that's

04:12.720 --> 04:16.560
why I'm running this time around, you know, but a large part of what I'm trying to do is also tell

04:16.560 --> 04:23.520
Republicans, look, if you're not going to be interested in transhumanism, then the left is

04:23.520 --> 04:30.320
going to take it away from you and turn it to another dominated social movement of the left.

04:30.320 --> 04:34.160
And I keep telling you, you know, one of the big premises I run on is it's not that I'm super

04:34.720 --> 04:40.160
huge fan of the Republicans or a super huge fan of the Democrats. I'm a kind of a technology person,

04:40.160 --> 04:45.280
more of a centrist. But I definitely know that socialism isn't good for transhumanism. I

04:45.280 --> 04:50.240
definitely know that socialism isn't good for science and technology. So the Republicans have

04:50.240 --> 04:55.440
to stand up and try to pull transhumanism, you know, in a way that they can have some ownership

04:55.440 --> 04:59.840
over rather than it just fall completely in the hands of the left. This is really what a lot of

04:59.840 --> 05:05.040
my presidential campaign is about is trying to make sure artificial intelligence isn't socially

05:05.040 --> 05:10.400
driven, trying to make sure that genetic editing isn't driven entirely by the far left. You know,

05:10.400 --> 05:14.960
the environmental movement is a very good example. It's an entirely left leaning movement. Do we want

05:14.960 --> 05:19.040
transhumanism to become like that? No. So we need some more balance. And I'm trying to bring that

05:19.040 --> 05:24.720
balance to the public's knowledge. And for people to know there are already factions within the

05:24.720 --> 05:29.760
transhumanist movement who are leaning far left. Would you agree with that? Oh, absolutely. I mean,

05:29.760 --> 05:35.360
transhumanism is overwhelmingly far left at this moment. It just happens to be that some of the

05:35.360 --> 05:41.120
major players in the movement, thankfully, are either libertarian or fiscally conservative.

05:41.120 --> 05:46.800
And because it began as a sort of libertarian fiscally conservative movement, but I can tell

05:46.800 --> 05:52.240
you, I mean, the great majority now have turned hard left, and they're youthful. And I'm really

05:52.240 --> 05:56.960
excited about the growth of the movement since we've talked, you know, it's growing all the time,

05:56.960 --> 06:02.240
but it is growing to the left. And I'm not sure how far that can happen without some, you know,

06:02.240 --> 06:06.960
without something bad happening. This, this technology doesn't come for free. It comes from

06:06.960 --> 06:13.680
hard work, innovation, free markets, entrepreneurial spirit. These are things not normally associated

06:13.680 --> 06:18.000
with the hard left. And so we mean that we need to make sure there's a better balance. And that's

06:18.000 --> 06:22.480
what I'm trying. I'm here to try to do with my campaign and say, look, transhumanism needs some

06:22.480 --> 06:28.160
fiscally conservative, responsible people to come out and say, it's also our movement. And also,

06:28.160 --> 06:33.760
it seems to me that what far left is really hell bent on doing is to creating a bigger, more

06:33.760 --> 06:40.720
centrally driven states, federal government that take based on the priorities that they determine,

06:40.720 --> 06:46.480
and then they distribute based on the priorities that they determine. But the tech based world and

06:46.480 --> 06:51.120
the digitization that you're experiencing will really only work from my perspective in a

06:51.680 --> 06:57.840
decentralized and secure by design kind of a system that is not relying on any kind of a

06:57.840 --> 07:00.480
centralized structure of authority in form of federal government.

07:00.480 --> 07:06.640
Yeah, well, I wouldn't agree with that. I mean, I think being decentralized is one of the huge

07:06.640 --> 07:11.680
pluses of being fiscally conservative, because everybody's competing against one another. And

07:11.680 --> 07:16.400
ultimately, what happens is you have people that that win and that win again, and then new companies

07:16.400 --> 07:21.600
come up and try to win. And that creates that decentralization that we're all sort of looking

07:21.600 --> 07:28.080
for. Of course, when you swallow it in like the socialist type situation, it's all under control

07:28.080 --> 07:34.160
of a central authority. And if that authority is wrong, then the entire movement is sabotaged.

07:34.160 --> 07:38.640
And again, this is why really, it needs a better balance. It needs to have I don't mind some

07:38.640 --> 07:44.560
left leaning people trying to infiltrate it, run it own it. Naturally, I kind of think a good balance

07:44.560 --> 07:48.560
is good. You know, it goes back and forth. That's how America became really strong, I think.

07:49.120 --> 07:54.880
Unfortunately, though, it's right now it's turning so hard left, that there's so few fiscally

07:54.880 --> 07:58.960
conservative people out there or libertarian people, or conservatives like myself out there

07:58.960 --> 08:04.400
trying to move it that I'm genuinely worried that transhumanism in Silicon Valley is going to fall

08:04.400 --> 08:10.240
to the hard left and never come up for air again. Right. There are very few people within at least

08:10.240 --> 08:15.520
the vocal ones within Silicon Valley who are talking against the far left. I know Peter Thiel

08:15.520 --> 08:20.640
moved out of Silicon Valley to Los Angeles because of the very same thing he has had enough of the

08:20.640 --> 08:25.840
culture of it. It's just very destructive. Whoever that you're talking to with a little bit of brain,

08:25.840 --> 08:31.760
they're sick and tired of it. A lot of us are sick and tired. And I think some of the left of some

08:31.760 --> 08:37.600
of the more normal left are sick and tired too. It's what's happened is that media, which is

08:37.600 --> 08:42.160
comprised a lot of very young journalists who are very left because of course, they don't have

08:42.160 --> 08:45.760
much money and a lot of them have don't have children. So they haven't really had to deal

08:45.760 --> 08:51.520
with life in a real kind of way. I'm a father of two kids. I can tell you that I was more

08:51.520 --> 08:56.080
left leaning and then I had kids. And then all of a sudden I said, wow, wait a sec, this is the

08:56.080 --> 09:01.920
24 hour seven responsibility and responsibility is sort of what makes people physically conservative.

09:01.920 --> 09:08.000
It's because you're like, wait a sec, this is real. I can't miss a day of work and not pay my,

09:08.000 --> 09:13.680
you know, my get my check and feed my kids. There are hard responsibilities, a equals a type of

09:13.680 --> 09:20.000
thing. And I think as media has painted this picture where it makes more sense for Apple and

09:20.000 --> 09:26.320
Google and some of these other tech companies to seemingly lean left in order to seem like they're

09:26.320 --> 09:33.040
really nice people. But deep down, I mean, Silicon Valley still has that driving hunger of capitalism.

09:33.040 --> 09:38.320
And I hope it'll kind of raise its head and not just be convinced because it must appease the media

09:38.320 --> 09:42.400
and especially the younger generation, which of course naturally leans left when they're younger.

09:42.400 --> 09:47.280
But, you know, I just worried because there's tipping points. And once you tip too far to the

09:47.280 --> 09:52.800
left, it's very hard to get any kind of balance back or even come back at all. Yeah, especially

09:52.800 --> 09:59.280
now that there is this ongoing competition between a closed system being China and some kind of a

09:59.280 --> 10:04.880
competitive system at its core being United States and the Chinese quite honestly, they have a lot of

10:04.880 --> 10:10.160
advantages over Americans because they don't care really about and I'm talking in the perspective

10:10.160 --> 10:16.880
from the perspective of technological advancement. They are not bound by religion. They are not bound

10:16.880 --> 10:23.040
by we shouldn't experiment with genetic engineering, for example, because we're going to upset God of

10:23.040 --> 10:29.840
some kind. And at the same time, they are very centrally focused on collecting as much data as

10:29.840 --> 10:34.560
they can to empower their artificial intelligence as strongly as they can because they got it. You

10:34.560 --> 10:40.160
know, they know what's going on. And yet we are here complaining about and arguing about whether

10:40.160 --> 10:46.400
or not Russia hired prostitutes to pee on Trump, whether or not that's the case. It seems like the

10:46.400 --> 10:52.560
education of people is lacking deeply. And at the same time, this uncertain kind of a time that we

10:52.560 --> 10:56.640
are experiencing, people are trying to hang on to whatever that makes sense to them already,

10:56.640 --> 11:00.400
rather than learning new things that are coming because this decade is going to be insane.

11:00.400 --> 11:05.840
Oh, well, I mean, you nailed on kind of the number one topic that I'm really,

11:06.400 --> 11:10.240
you know, pushing in my campaign, which is, you know, outside of, I guess, socialism and

11:10.240 --> 11:15.440
transhumanism is this idea that China is just whooping our butt. And there's just, you know,

11:15.440 --> 11:19.760
this is not something you can come back from because it would be one thing if we have the

11:19.760 --> 11:24.800
same population sort of like with, you know, Russia, our populations were pretty same. No,

11:24.800 --> 11:29.760
China has four times the amount of people and they have almost as many engineers as our entire

11:29.760 --> 11:35.440
workforce. We do not get a second chance with this game. Once China surpasses our economy,

11:35.440 --> 11:40.240
and it's pretty much a foregone conclusion, they will at this point, it's sort of game over in

11:40.240 --> 11:46.000
terms of America being great and America leading the world forward in terms of culture, you know,

11:46.000 --> 11:51.200
in terms of democracy, in terms of the things that mean a lot to us. And when you're talking

11:51.200 --> 11:57.280
with so many millions of engineers, and they have a culture of working hard, and they have a culture

11:57.280 --> 12:03.040
of just kind of like, oh, obedience, you know, we may not appreciate that. But from an economic

12:03.040 --> 12:06.560
point of view, when they talk about artificial intelligence, genetic engineering, of course,

12:06.560 --> 12:11.360
you nailed on the big one, their secular, it's really our conservatism that often gets in the

12:11.360 --> 12:16.320
way of us developing innovation, we don't want to do any genetic editing, we don't want to augment

12:16.320 --> 12:20.560
our intelligence, because we're too religious, and that would be changing the body of God or

12:20.560 --> 12:25.440
something like that. People don't really get it that well, whether Americans do it or not,

12:25.440 --> 12:30.720
China is going to do it. And if they upgrade and augment an entire generation of Chinese babies,

12:30.720 --> 12:34.720
with higher IQs than us, through their new types of, you know, genetic engineering,

12:35.280 --> 12:40.080
we're dead in the water. So whether we like it or not, America has to step up to the plate.

12:40.080 --> 12:44.640
And that requires both the left and the right together to say, wait a sec, we have a common

12:44.640 --> 12:50.560
adversary, and we don't want that that nation China to become that much stronger than us.

12:50.560 --> 12:55.120
And unfortunately, look, I don't know, I'm not saying it's game over. But we're in the fourth

12:55.120 --> 12:59.600
inning. And we're starting to throw Hail Mary passes, because that's we need to just take

12:59.600 --> 13:04.000
a huge chunk of money and a huge amount of incentives, put them into genetic engineering,

13:04.000 --> 13:07.760
put them into AI, put them into brain implants, put them into all the different radical

13:07.760 --> 13:12.720
technologies out there that can transform our economy and make it so that we can be

13:12.720 --> 13:18.000
leading the world forward. There's a reason that Apple and Google and Microsoft and Amazon are the

13:18.000 --> 13:23.040
largest companies in the world right now. It's all tech companies. But right now, China is leading

13:23.040 --> 13:27.680
us in AI, they're leading us in genetic editing, they have the first genetically edited babies alive

13:27.680 --> 13:33.280
right now. If we don't catch up, we're dead in the water. Not only they're leading us, they're also

13:33.280 --> 13:38.640
setting the narrative in the United States, like we saw with NBA and Disney using their market size.

13:38.640 --> 13:44.240
So the like PC culture is a very problematic one that you cannot question certain,

13:45.440 --> 13:50.160
certain kind of concepts and subjects. And it seems like China has recognized that as

13:50.160 --> 13:53.280
as a weakness of the West, and they keep, you know, poking at it.

13:54.400 --> 14:01.520
Of course they are, because it is a weakness. And also just speaking of war, you know, Trump,

14:01.520 --> 14:05.360
I think you had spoken to Jimmy, President Jimmy Carter, and, you know, he said, look,

14:05.360 --> 14:10.080
China isn't spending any money on wars. And look at what we're doing. At some point,

14:10.080 --> 14:14.400
building too many bombs, unless we're going to actually use them, and I highly doubt we're

14:14.400 --> 14:20.560
going to use them against China. It just works against us. We need to innovate, we need to beat

14:20.560 --> 14:25.600
China where it counts. And that means AI, that means genetic editing, that means in the science

14:25.600 --> 14:29.680
and tech industries, which very quickly, when the stock market, you look at the stock market

14:29.680 --> 14:35.440
of the last two decades, it's stacking those tech companies up front, we need four or five or six

14:35.440 --> 14:40.960
more times, you know, companies like Apple, five or six more companies like Google that size.

14:40.960 --> 14:45.200
Because when you look at the Chinese population, I mean, they're creating, like I heard some kind

14:45.200 --> 14:50.640
of crazy statistic. We created like three or four million jobs in the last few years. That's great.

14:50.640 --> 14:54.720
I'm happy about it. Trump's done good in the economy. No question about that. But China

14:54.720 --> 15:01.520
created 65 million jobs in the same timeframe. We can't compete against a nation that's four

15:01.520 --> 15:06.800
times our size. And beyond that comes India. India in the next decade will pass China's

15:06.800 --> 15:11.680
population. And they have the same situation going a very good work ethic, where all of a sudden,

15:11.680 --> 15:16.160
they're going to have, you know, 100 or 200 million engineers, and they're going to become

15:16.160 --> 15:20.720
number two or number one, and China is going to be America's gonna be number three, this all in

15:20.720 --> 15:25.680
10 years time before my children even go to college. And I'm very worried about part of why

15:25.680 --> 15:31.520
I'm running for president is to say, try to wake up people and say, listen, it doesn't win you votes

15:31.520 --> 15:35.600
to talk about artificial intelligence. It doesn't win you votes to talk about weird stuff like

15:35.600 --> 15:42.400
genetic editing. But it's the reality of winning the race of being the leading nation. If you want

15:42.400 --> 15:48.240
to lead the world forward, these topics must be addressed, innovation must occur here. Otherwise,

15:48.240 --> 15:53.200
it's really a lost cause. These are going to be not only trillion dollar companies regarding AI

15:53.200 --> 15:55.920
and genetic editing, but they're going to be multi trillion dollar companies.

15:55.920 --> 16:01.120
Yeah. And this is not sci fi and China already has had their first successfully.

16:01.120 --> 16:05.520
Can I say design designer babies early last year?

16:05.520 --> 16:11.360
Yeah. No, it's not America. It's China that had it. And that's, you know, that's what's scary

16:11.360 --> 16:15.600
about is, wait a second, I thought we were leading the world and the stuff. No, no, we're not. You

16:15.600 --> 16:19.840
know, we may be able to have some of that technology to do it, but our government won't allow us to do

16:19.840 --> 16:24.640
it. And this is really where I come in saying, look, I'm a new type of Republican, somebody that

16:24.640 --> 16:30.160
wants to say, look, it's okay to be fiscally conservative, I am, it's okay to have some

16:30.160 --> 16:35.840
traditional values. That's fine. But we can't lose the economic race or the innovation race when it

16:35.840 --> 16:40.960
comes to other countries. It means we have to expand our minds. We have to open ourselves a

16:40.960 --> 16:46.240
little bit. The Republican party can't always be so closed minded. It's okay to embrace genetic

16:46.240 --> 16:50.880
editing, fit it within your religious framework, fit it within your traditional values. You can

16:50.880 --> 16:55.520
do so, but whatever happens. And I would say most importantly, don't let China lead it because we're

16:55.520 --> 17:00.960
never going to catch up. Yeah, absolutely. You have a new book out called Upgrading America,

17:00.960 --> 17:07.280
the political writings of Zoltan Isfan. We've been talking about what we're talking about now

17:07.280 --> 17:12.880
since the first time I had you on the show, which was June of 2016. And then I came down

17:12.880 --> 17:19.200
to Philadelphia to campaign with you outside of DNC. And you've been consistent. That's the thing.

17:19.200 --> 17:25.920
And you've been very active in the media. So would you say that this book Upgrading America is a

17:25.920 --> 17:31.440
conclusion of all of your activity and experiences for this political campaign? And basically,

17:31.440 --> 17:36.560
the kind of roadmap that you're laying down that this is how America should be governed,

17:36.560 --> 17:44.240
whether or not you will be the president or not? Well, I would definitely say it's, you know,

17:44.240 --> 17:50.160
it comprises all my writings together. There are three or four essays in there that are not policy

17:50.160 --> 17:57.280
in 2020 because they're so controversial. However, I don't want to see myself as somebody who

17:57.280 --> 18:01.920
only adheres to policies. And for the next 20 years, that's what I'm going to believe in.

18:01.920 --> 18:05.200
I'd like to see myself as somebody who can grow, somebody who might be able to say, you know what,

18:05.200 --> 18:09.760
I made a mistake. I'm able to reach outside of myself or I'm able to hear a new theory.

18:09.760 --> 18:15.520
And the book comprises everything that I, the best that I could put forth. It doesn't mean

18:15.520 --> 18:21.040
that I'm correct in all of it, but I do believe that 80% of it is plenty enough to lead the nation

18:21.040 --> 18:26.160
forward into the future. And in order to beat China and India, as we come across the kind of

18:26.160 --> 18:31.760
the new decade and things like that, it's just tough because some of my writing, I write as

18:32.480 --> 18:36.960
a philosopher and it's almost as an artist. I provoke people to say, what can we think?

18:36.960 --> 18:41.920
How far can we take this? And then there's some that are just clear standard policies.

18:41.920 --> 18:46.800
Like we need to do better. We need to fix inequality. We need to fix education. We need

18:46.800 --> 18:51.040
to fix the prison system. There are some things that are just like so blatantly obvious. They'll

18:51.040 --> 18:55.760
remain policy forever, but some of it's a little bit more controversial. And, uh, you know, I hope

18:55.760 --> 19:00.720
when people look at the book, they'll say, they'll try to see the difference between the philosopher

19:00.720 --> 19:04.880
and the person who's running for office saying, this is what really is my policy. You know, my

19:04.880 --> 19:11.680
website, Zoltan2020.com has the actual 20 point plan, but literally it's 95% of those essays in

19:11.680 --> 19:17.120
there. And just your audience knows it's essays from the New York Times. It's essays from vice

19:17.120 --> 19:22.160
essays from Huffpost, essays from Newsweek, essays from some different types of publications that

19:22.160 --> 19:27.680
are more academic or scholarly. It's, it's a good six years of the best opinion essays that I could

19:27.680 --> 19:32.240
write on the topics of politics and on where I think the country is going and where it should be

19:32.240 --> 19:36.800
going and where it should be going. How has the response by Republicans and conservatives have

19:36.800 --> 19:44.400
been, um, with respect to what you're talking about? It's not as good as I wanted to be. Donations

19:44.400 --> 19:49.200
haven't been as strong as I would have hoped. I originally saw myself as sort of a Trojan horse

19:49.200 --> 19:53.120
in the Republican party thinking, okay, I'm going to come in and all of a sudden it's going to

19:53.120 --> 19:57.520
explode and we're going to see a brand new Republican party. All the younger Republicans

19:57.520 --> 20:03.440
are going to go for me and say, this is the future. But you know, Trump is such a dominating

20:03.440 --> 20:07.360
personality and he's frankly doing pretty good with the economy. And for a lot of people, that's

20:07.360 --> 20:11.760
all that really matters that it's very hard to compete against him. And the media doesn't really

20:11.760 --> 20:16.320
want to give attention because honestly the media works off ads and frankly, who could be better

20:16.320 --> 20:22.320
for ads and Trump? You know, I mean, he, he creates controversy all the time. And so I don't think the

20:22.320 --> 20:27.760
Republican party has heard my message. I honestly don't think 2020 is the year for transhumanism.

20:27.760 --> 20:34.240
I'm not even sure after my reception, if 2024 will be the year, but I think it's coming.

20:34.240 --> 20:40.000
And I hope that the Republicans in deep in their minds say, wait a sec. It's important to remember

20:40.000 --> 20:44.960
that transhumanism is on the radar now. And we need to keep it in mind for the future,

20:44.960 --> 20:49.920
because if it is the future, we want to own that future rather than, like I said, from the original

20:49.920 --> 20:54.560
things we're talking about, we have the far left owning that. And so I hope I've made a difference.

20:54.560 --> 20:58.480
And again, that's all I tried to do. I didn't come into this race thinking that I was going to be

20:58.480 --> 21:04.720
Trump. That was never, you know, I'm, I'm realistic enough. Will my time come in 2028 or 2032?

21:04.720 --> 21:09.680
That now is a different conversation. Maybe if I keep at this, eventually the, the publicity

21:09.680 --> 21:13.920
and the media coverage will grow big enough where I can make a real campaign that actually

21:13.920 --> 21:18.240
can dent the system. But in the meantime, what I'm really trying to do is get the Republican party

21:18.240 --> 21:23.520
to say, wait a sec, China is embracing transhumanism. If America doesn't embrace it,

21:23.520 --> 21:28.480
we're going to be, you know, in a very sorry state. So how can we get fiscally conservative

21:28.480 --> 21:33.280
people more on board with some of these radical technologies, even if they seem a little bit

21:33.280 --> 21:39.600
controversial? Well, one thing about when you were saying in 2024, 2028, or even further than that,

21:39.600 --> 21:44.320
there will be a opportunity for a transhumanist president. The question is whether or not there

21:44.320 --> 21:49.360
will be any need for a human president at that point. Now that we're starting the decade of

21:50.240 --> 21:55.040
really mainstream big data, internet of things, machine learning and artificial intelligence,

21:55.040 --> 22:00.400
why not having an AI president? One of the things that I always think about Trump is that Trump has

22:00.400 --> 22:05.440
the opportunity to be the last human and the first AI president of the United States considering the

22:06.160 --> 22:11.680
size and depth of the databases that has been created about him, you know, both public and

22:11.680 --> 22:17.360
private. Well, it is possible if he wins a second term that he could be the last one,

22:17.360 --> 22:22.320
it would require a stretch of our imagination, because I don't think general artificial

22:22.320 --> 22:28.240
intelligence will be here by then. But it's very possible that an AI strong enough to govern by

22:28.240 --> 22:33.600
what we might call the, you know, governing by the greatest good for the greatest amount of people

22:33.600 --> 22:40.880
could already start happening by 2024. Whether humanity and Americans will be ready for that is

22:40.880 --> 22:47.520
a whole nother idea. But you know, I originally in 2016 had reached out to IBM to try to debate

22:47.520 --> 22:52.000
Watson. Watson was for a while thinking about running for president. And I thought that was a

22:52.000 --> 22:57.200
very interesting thing. And I think I think there's no question by the end of this decade,

22:57.200 --> 23:03.040
we're going to have some serious contenders for in a political way that are AI based,

23:03.040 --> 23:07.280
and they may have human companions at first kind of an AI with a human running together.

23:07.280 --> 23:10.640
And that might be the very best way to govern. But there's no question probably by 2030s,

23:11.360 --> 23:16.800
it'll be just best to leave it up to a machine. Because in the end of the day, we can monitor we

23:16.800 --> 23:20.800
can, you know, all the databases can tell people what's best when what's best for the economy,

23:20.800 --> 23:26.000
how do we squeeze every single dollar out of the economy. And if we can have a machine tell us how

23:26.000 --> 23:30.560
to do that without all the fighting and the divisiveness and everything else that's happening,

23:30.560 --> 23:35.840
I you know, it might make sense to do it. Again, that's a very challenging perspective,

23:35.840 --> 23:40.400
challenging perspective, because at the same time that AI comes is the time, you know,

23:40.400 --> 23:44.960
the different companies like Elon Musk and other people working on Neuralink and Brian Johnson with

23:44.960 --> 23:50.000
Colonel, his company, you know, will we be able to connect to that AI with our brain and machine

23:50.000 --> 23:54.640
interface? And then all of a sudden, is it us? Or is it the AI? Or are we just one in the same?

23:54.640 --> 23:58.560
And I think that's where the world is going eventually. So the economy can kind of keep up

23:58.560 --> 24:02.800
and we can kind of stave off innovation and things like that. But, you know, it's good,

24:02.800 --> 24:07.040
no matter what happens, the next 10 years are gonna be so crazy, so wild, so brilliant,

24:07.600 --> 24:11.200
you know, that it's gonna just like, I think every morning, we're going to turn on the news

24:11.200 --> 24:16.080
and be like, Oh, I can't believe this happened. This is so bizarre. But again, you know, from a

24:16.080 --> 24:23.200
political perspective, if America doesn't own it, someone else does. And if a Chinese company or

24:23.200 --> 24:28.320
Chinese government owns it, and that's the AI that they're sending to us to run our country,

24:28.320 --> 24:33.600
we're in for it. Which is exactly why I would just tell your listeners, listen, we need to win this,

24:33.600 --> 24:39.360
America needs to continue to own innovation across the world, because it's such a critical

24:39.360 --> 24:44.640
moment in time to not lose our leadership to make sure that democracy actually survives.

24:44.640 --> 24:50.080
China is not a democracy. The voting system is completely different than how we have it here.

24:50.640 --> 24:54.800
So we need to make sure we win this game. Otherwise, it's going to be a very, very

24:54.800 --> 24:59.680
different world. It just seems like the two biggest thing is first of all, get rid of central

24:59.680 --> 25:04.400
structures of authorities to have control over our data, whether they're corporations or military

25:04.400 --> 25:10.000
or any kind of a state. And then the second is to educate the society because any technology works

25:10.000 --> 25:14.720
as well as a society that adapts it. You know, I keep bringing this up, the Japanese are doing a

25:14.720 --> 25:21.840
far better job than Americans adopting into new technologies. Well, yeah, I think the Japanese

25:21.840 --> 25:26.160
have that kind of Buddhist perspective. You know, people think, oh, it has nothing to do with

25:26.160 --> 25:31.600
religion. But honestly, I think a lot of it does. If you your religious outlook is oftentimes your

25:31.600 --> 25:37.120
cultural outlook. And Japan, if you've been there, it's it's very Buddhist. And Buddhist means sort

25:37.120 --> 25:42.640
of anything goes as long as you try to be nice. And it can be gods or it can be no God or it can

25:42.640 --> 25:48.560
be the void. But the point of the story is all technology is neutral. Therefore, you can accept

25:48.560 --> 25:53.680
it if it's acceptable to your society. Whereas in America, nobody says technology is neutral.

25:53.680 --> 25:59.120
People say, oh, technology is terrible. Or they'll say, technology is very great. And I think

25:59.120 --> 26:05.680
America has to get over that kind of, you know, yin yang stuff and say, wait a sec, technology is

26:05.680 --> 26:11.200
just something that's just whatever we make of it. And we should embrace the most advanced technology

26:11.200 --> 26:16.240
we can have as long as we find it being functional for our lives. And we shouldn't put it in the

26:16.240 --> 26:21.440
context of religion, or the context of culture, the context of other things. It's really just a

26:21.440 --> 26:26.000
context of is it functional or not. If Americans would do that, then all of a sudden, I think

26:26.000 --> 26:30.560
Congress would pass tons of bills, we'd start spending a huge amount of money on all these

26:30.560 --> 26:36.080
crazy innovations, and we'd outdo the Chinese. But as it is, as long as we're conservative,

26:36.080 --> 26:42.480
it seems like Trump and Mike Pence and other people are sort of, you know, a shy of technology

26:42.480 --> 26:49.040
or wanting to stay away from it without realizing that, you know, without innovating in that area,

26:49.040 --> 26:53.680
we're going to lose to, you know, India and China at some point in the future. That that's,

26:53.680 --> 26:58.880
that day is coming that we can't allow that. I agree. Zoltan's book is called Upgrading America,

26:58.880 --> 27:03.120
the political writings of Zoltan Isfan. Always a pleasure talking to you. I know the time is

27:03.120 --> 27:07.920
limited. So let me ask you the last question I ask all my guests, that if you come across an

27:07.920 --> 27:13.440
intelligent alien from a different civilization, what would you say is the worst thing humanity

27:13.440 --> 27:23.280
has done? And what would you say is our greatest achievement? Well, the worst thing that's such an

27:23.280 --> 27:29.520
interesting question. Let me let me give it a sec. Look, in my opinion, the worst thing that we've

27:29.520 --> 27:38.240
done is convince ourselves of a politically correct nature, that that's an okay statement.

27:38.240 --> 27:42.000
What I'm worried about most when I see Americans is that people are saying,

27:43.120 --> 27:48.640
we must be soft, we must be snowflake, you know, we must be like, not hurt, not stomp on anyone's

27:48.640 --> 27:55.680
feelings. And honestly, this is killing innovation. The most courageous part of us is to break out.

27:55.680 --> 28:01.040
And sometimes we break out, it's terrible. And sometimes we break out, it's ugly. And

28:01.040 --> 28:06.000
sometimes we break out, it's totally non functional. But sometimes we break out,

28:06.000 --> 28:12.000
that's how the universe and the whole species moves forward. But we have such a tightening

28:12.000 --> 28:16.480
politically correct culture in America, that it seems like you can't say anything, you can't

28:16.480 --> 28:20.320
innovate anything, you can't even do anything. This is why Silicon Valley is turning left.

28:20.320 --> 28:24.720
The media has made it so that they don't want you to say anything that's against the grain.

28:24.720 --> 28:29.840
And I'm the guy who just goes out there to provoke people to say, what can we think? I'm not right

28:29.840 --> 28:35.600
all the time. But it's okay that we think of out of the box. So the worst thing that's happening

28:35.600 --> 28:41.680
to me right now, at least to the Western, you know, Western part of human beings, is that we're

28:41.680 --> 28:47.040
becoming politically politically correct. The best thing is that people are fighting against that.

28:47.040 --> 28:51.520
People want to break out steel and people still want to say, look, I want to cut off my arm,

28:51.520 --> 28:56.480
put on a robotic arm, because I want to throw a football two miles long, or I want to, you know,

28:56.480 --> 29:01.840
do whatever I want with my crazy new cyborg body. And even though that's totally against the grain,

29:01.840 --> 29:05.440
we're going to look back at 100 years and say, thankfully, people stood up and said,

29:05.440 --> 29:10.320
I'm not going to listen to what's politically correct, what's right, what fits within moral

29:10.320 --> 29:16.560
boundaries, what fits within religious, you know, context, I went my own direction, I, you know,

29:16.560 --> 29:20.640
I walked to a different drum beat. And I found something that I really love. And as long as

29:20.640 --> 29:23.680
we have people doing that, then that's the greatest thing that people can do.

