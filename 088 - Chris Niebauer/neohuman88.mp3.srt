1
00:00:00,000 --> 00:00:07,520
So here we are with, you know, we've got this skull and a brain and the brain produces these thoughts and it's incredibly limited.

2
00:00:07,840 --> 00:00:14,640
And then we have reality, this infinite complex multitude of variables that are countless.

3
00:00:14,880 --> 00:00:21,320
You know, it's impossible for us to really know that reality with our limited thinking mind.

4
00:00:21,680 --> 00:00:23,480
But that's exactly what we're trying to do.

5
00:00:23,920 --> 00:00:28,320
We're trying to calm ourselves down thinking, well, we can figure this all out.

6
00:00:28,320 --> 00:00:35,280
And I'm becoming more comfortable with the idea that we'll never figure it out.

7
00:00:35,880 --> 00:00:47,600
We're hopelessly bound to insecurity and it's actually possible that maybe we're playing a game that we actually have, we've chosen to play.

8
00:00:47,600 --> 00:00:53,080
All right, folks, hello and welcome to the 88th episode of Neo Human Podcast.

9
00:00:53,080 --> 00:00:59,240
And this is our final episode of the 2020 on the last day of 2020.

10
00:00:59,240 --> 00:01:08,720
And who better to talk and, you know, kind of sum up what happened to humanity and to our psyche and everything.

11
00:01:08,720 --> 00:01:13,920
Then Chris Neibark. Thank you so much for coming back on this last day of the year.

12
00:01:13,920 --> 00:01:19,080
I'm sure you're busy, but this is this is a service to humanity.

13
00:01:19,080 --> 00:01:24,840
You're a favorite guest our show and it's a perspective that it's interesting.

14
00:01:24,840 --> 00:01:31,680
I come across a lot recently with the guests that we were talking about that, hey, we're going to talk about humanity.

15
00:01:31,680 --> 00:01:38,560
That it's interesting. I come across a lot recently with the guests that we were talking about that.

16
00:01:38,560 --> 00:01:43,800
Hey, what is the definition of an eye? Who is the person who is the experiencer?

17
00:01:44,280 --> 00:01:53,520
And, you know, that's what you research and that is your area of interest and expertise.

18
00:01:53,520 --> 00:01:57,520
And you teach it and you also have a book called No Self, No Problem.

19
00:01:57,520 --> 00:02:01,080
How neuropsychology is catching up to Buddhism.

20
00:02:01,080 --> 00:02:04,920
So welcome back, Chris.

21
00:02:04,920 --> 00:02:08,200
It's great to be here. I'm looking forward to our conversation.

22
00:02:08,200 --> 00:02:10,920
It's it'd be interesting to see where it goes.

23
00:02:10,920 --> 00:02:16,040
Yeah. How are you doing with all this pandemic?

24
00:02:16,040 --> 00:02:21,560
And, you know, pandemic started, but it really, you know, has affected all aspects of our lives.

25
00:02:21,560 --> 00:02:27,960
Right. And the last time you were here was, I think, mid May.

26
00:02:27,960 --> 00:02:29,920
Sounds about right. Yeah. Yeah.

27
00:02:29,920 --> 00:02:37,000
And then we went through all the riots and stuff is like, you know, so much has happened.

28
00:02:37,000 --> 00:02:41,000
The way I look at the self.

29
00:02:41,000 --> 00:02:47,520
Again, the idea that there's one solid self, that's what I really get at, that that's an illusion.

30
00:02:47,520 --> 00:02:52,280
And you can start to feel that there's really like like a society of cells.

31
00:02:52,280 --> 00:02:58,680
And so I have all these different interesting things that have come up over the last few months as a social scientist.

32
00:02:58,680 --> 00:03:04,680
This is old. I mean, people are going to be studying the last year in social science for the next 20 years.

33
00:03:04,680 --> 00:03:10,080
Right. And they're going to be looking at our reactions, why we have these reactions.

34
00:03:10,080 --> 00:03:13,840
And, of course, this long list of everything people did wrong.

35
00:03:13,840 --> 00:03:17,280
And so it's going to keep social science busy.

36
00:03:17,280 --> 00:03:23,960
And I certainly have had that kind of experience as a social scientist because, you know, it's one thing to be a human.

37
00:03:23,960 --> 00:03:29,600
And it's another thing to be one of the humans that studies humans.

38
00:03:29,600 --> 00:03:34,840
So everything that happens, I go to a store and, you know, I can kind of see that social scientists.

39
00:03:34,840 --> 00:03:40,520
It's like, OK, this is kind of interesting, you know, and you kind of watch people who are wearing masks, people who are not wearing masks.

40
00:03:40,520 --> 00:03:44,280
And as a social scientist, you're trying to, you know, I mean, that's what we do.

41
00:03:44,280 --> 00:03:46,800
We try to predict humans and figure out humans.

42
00:03:46,800 --> 00:03:51,920
And we've done OK with it until certain things, certain levels of complexity.

43
00:03:51,920 --> 00:03:54,240
That's the thing about nature.

44
00:03:54,240 --> 00:03:56,840
Human beings have been dealing with nature.

45
00:03:56,840 --> 00:04:06,000
Well, we've been in this war against nature for like 40,000 years, ever since the mind turned on, ever since we started having an idea of a self.

46
00:04:06,000 --> 00:04:08,720
We've been at odds with nature.

47
00:04:08,720 --> 00:04:16,520
And so when a virus comes along, it feels like, you know, it's the enemy and we're trying to figure it out.

48
00:04:16,520 --> 00:04:20,920
But we're doing this all the time with this thinking mind.

49
00:04:20,920 --> 00:04:31,160
You know, this is really one of the things that I've been getting into lately is particularly in consciousness research is.

50
00:04:31,160 --> 00:04:39,560
Distinguishing between the thinking mind and all the processes associated with the thinking mind and really what consciousness is.

51
00:04:39,560 --> 00:04:48,200
And they're really separate, vastly different topics that get really confused in the literature.

52
00:04:48,200 --> 00:04:52,000
They get confused by some of the biggest names in consciousness research.

53
00:04:52,000 --> 00:04:54,200
Get these confused. And it's not because they're not smart.

54
00:04:54,200 --> 00:04:56,760
It's actually because they're brilliant.

55
00:04:56,760 --> 00:05:02,480
Their brilliant thinking mind is.

56
00:05:02,480 --> 00:05:07,040
It's almost like they're just too smart and they kind of get lost in thoughts.

57
00:05:07,040 --> 00:05:14,720
And there's been some work on this, like Michael Shermer has talked about, like, why smart people believe weird things.

58
00:05:14,720 --> 00:05:21,400
Because like the super intelligent people are so good at justifying their beliefs, you know, if they end up going down a certain path,

59
00:05:21,400 --> 00:05:27,640
they can go down that path very easily because they have so many intellectual arguments to justify it.

60
00:05:27,640 --> 00:05:35,680
And so I've been spending a lot of time trying to kind of associate what I call the thinking mind, which in my view,

61
00:05:35,680 --> 00:05:43,800
I think we talked about this last time a little bit, is a very as far as evolution is a very new thing for humanity.

62
00:05:43,800 --> 00:05:46,400
We've been around the planet for two and a half million years.

63
00:05:46,400 --> 00:05:51,520
The thinking mind has been around maybe 40,000, maybe 70,000 years.

64
00:05:51,520 --> 00:05:59,960
And it's very easy to get caught up in the thinking mind and forget about the nature of consciousness.

65
00:05:59,960 --> 00:06:08,400
And so I've been doing what I can to help people become more aware of the thinking mind, the processes of the thinking mind,

66
00:06:08,400 --> 00:06:13,480
so they can kind of get back to where we started, so we can have certain experiences.

67
00:06:13,480 --> 00:06:20,000
So we're actually one with nature instead of finding ourselves at odds with it.

68
00:06:20,000 --> 00:06:24,200
Yeah, there are a couple of really interesting things that came across my mind.

69
00:06:24,200 --> 00:06:30,320
One is with respect to you mentioned people who are studying people.

70
00:06:30,320 --> 00:06:40,440
And it's important at the same time, it's a position that can be completely taken advantage out of as a position of authority.

71
00:06:40,440 --> 00:06:51,040
And if a person in that position has already determined the answer and is looking for evidence to prove that already determined answer,

72
00:06:51,040 --> 00:06:52,720
then that is very problematic.

73
00:06:52,720 --> 00:06:58,440
And I think that is a big part of a lot of people's problem with quote unquote experts right now,

74
00:06:58,440 --> 00:07:03,720
and especially this year, because they're watching TV and like, OK, this is what they're telling us.

75
00:07:03,720 --> 00:07:11,280
But I'm reading so much more about so many other different things online on Twitter, Facebook, whatever.

76
00:07:11,280 --> 00:07:21,840
So the conclusion is that these people are lying to me and they're lying for their own interest, which is completely natural.

77
00:07:21,840 --> 00:07:23,760
People have their own agenda.

78
00:07:23,760 --> 00:07:25,000
Yeah, we all do.

79
00:07:25,000 --> 00:07:28,680
And that's the nature that's the nature of thinking mind.

80
00:07:28,680 --> 00:07:35,640
And it's a weird paradox in some ways because the thinking mind is so self motivated.

81
00:07:35,640 --> 00:07:41,720
But the one of the ways it can maintain its self motivation is to become part of the herd,

82
00:07:41,720 --> 00:07:45,640
become part of a tribe and get those collective numbers.

83
00:07:45,640 --> 00:07:53,880
And then when you get a group of people all thinking the same way, it's really difficult as a human being to stand in face of the mob and say,

84
00:07:53,880 --> 00:07:56,800
I'm not sure I believe any of you.

85
00:07:56,800 --> 00:07:59,600
I mean, it's a very it's a it's a difficult thing to do.

86
00:07:59,600 --> 00:08:09,160
And but it's what we're also, as you pointed out, the nature of what an expert is, it's it's so difficult right now,

87
00:08:09,160 --> 00:08:15,800
because when you look at science, particularly in the last 50 years, I mean, let's go back even 50 years in science,

88
00:08:15,800 --> 00:08:21,240
you would get a specialty area and there would be a couple of journals and a couple of articles will come out.

89
00:08:21,240 --> 00:08:24,040
And it was really easy to keep up on things.

90
00:08:24,040 --> 00:08:33,920
Now, even if you want to be an expert, say even in neuroscience, the data, it's so exponential, it's so difficult to keep up.

91
00:08:33,920 --> 00:08:36,840
And so really, what are we even calling an expert?

92
00:08:36,840 --> 00:08:41,320
I mean, the idea of being an eclectic these days is nearly impossible.

93
00:08:41,320 --> 00:08:50,600
And so, you know, that that thinking mind is kind of kind of screaming out to the world like, who should I believe?

94
00:08:50,600 --> 00:08:58,240
And I and I found this, you know, for myself, I found myself in this position where, you know, should I trust the scientist?

95
00:08:58,240 --> 00:09:09,320
We may have never been put in a particular position where so many different arguments have been presented by authorities that are conflicting.

96
00:09:09,320 --> 00:09:14,720
And then we find ourselves in a place where it's very difficult to know.

97
00:09:14,720 --> 00:09:19,440
You know, ironically, it kind of puts the question back on on who we are.

98
00:09:19,440 --> 00:09:25,720
I mean, we have to kind of go inward instead of going outward.

99
00:09:25,720 --> 00:09:29,520
Yeah, I think that is our area of expertise.

100
00:09:29,520 --> 00:09:43,720
Inward, because outward is, you know, when you're saying that it's exponential, automatically, I think about artificial intelligence, which we've I think we've talked about a little.

101
00:09:43,720 --> 00:09:53,000
I think it is exactly because of our level of advancement and development in artificial intelligence that we are dealing with all of these questions,

102
00:09:53,000 --> 00:09:58,800
because the narrative has changed a lot, but not a singular narrative anymore.

103
00:09:58,800 --> 00:10:11,680
There are alternative narratives that exist side by side that, you know, when you talk to different people in this country, in the United States, you like, well, this is like ten different countries in one.

104
00:10:11,680 --> 00:10:19,720
Right. So it makes no sense that, you know, a single group of people, for example, be in charge of the governance.

105
00:10:19,720 --> 00:10:22,720
But that's how it is. That's how the system has worked.

106
00:10:22,720 --> 00:10:30,400
And people have invested their hopes, their dreams and the future of themselves and their future generations in this system.

107
00:10:30,400 --> 00:10:33,200
And now it's falling apart. Right.

108
00:10:33,200 --> 00:10:38,480
So this mob mentality, it's becoming stronger and stronger and stronger.

109
00:10:38,480 --> 00:10:50,320
I made the argument that we probably will see re reemergence of new types of religions and new interpretations of all the religions,

110
00:10:50,320 --> 00:10:54,120
because that's those are the whales in Pinocchio. Right.

111
00:10:54,120 --> 00:11:00,240
That's where you go when everything else have fallen apart, find some sort of an identity.

112
00:11:00,240 --> 00:11:10,000
But then that itself is authoritarian because, you know, I don't know, is not a very good advertisement to join a religion or a cult.

113
00:11:10,000 --> 00:11:13,240
You know, you should know what's going on and you should know the end game.

114
00:11:13,240 --> 00:11:15,920
So everything else is evaluated accordingly.

115
00:11:15,920 --> 00:11:20,200
And I think that's a very risky place.

116
00:11:20,200 --> 00:11:23,640
But like you said, it gives a certain amount of comfort.

117
00:11:23,640 --> 00:11:35,200
You know, I mean, would you rather be comforted with ignorance or be willing to go into the unknown with anxiety?

118
00:11:35,200 --> 00:11:39,000
And we're in a place that kind of amplifies the truth.

119
00:11:39,000 --> 00:11:46,920
You know, how many times have you heard, well, you know, we're at, you know, this is unpredictable times and and we're at a difficult,

120
00:11:46,920 --> 00:11:51,560
you know, insecure place in history. But that's always been the truth.

121
00:11:51,560 --> 00:11:57,360
I mean, you just never know. I mean, I could walk out, I could, you know, walk outside and get hit by a car.

122
00:11:57,360 --> 00:12:03,200
You know, I have friends, you know, they've had major health issues unrelated to the virus and they just hit them out of nowhere.

123
00:12:03,200 --> 00:12:06,240
They didn't wake up that morning knowing this was going to happen.

124
00:12:06,240 --> 00:12:14,040
And it goes back like Alan Watson, his, you know, one of his books, The Wisdom of Insecurity, this idea that that's life.

125
00:12:14,040 --> 00:12:17,440
The existence we're living right now, you're thrown into it.

126
00:12:17,440 --> 00:12:26,960
It's it's unpredictable. I think about one of the ways I look at the thinking mind is it can think one thought at a time.

127
00:12:26,960 --> 00:12:34,760
So here we are with, you know, we've got this skull and a brain and the brain produces these thoughts and it's incredibly limited.

128
00:12:34,760 --> 00:12:41,800
And then we have reality, this infinite complex multitude of variables that are countless.

129
00:12:41,800 --> 00:12:48,640
You know, it's impossible for us to really know that reality with our limited thinking mind.

130
00:12:48,640 --> 00:12:56,160
But that's exactly what we're trying to do. We're trying to calm ourselves down thinking, well, we can figure this all out.

131
00:12:56,160 --> 00:13:03,600
And I'm becoming more comfortable with the idea that we'll never figure it out.

132
00:13:03,600 --> 00:13:16,240
We're hopelessly bound to insecurity and it's actually possible that maybe we're playing a game that we actually have we've chosen to play.

133
00:13:16,240 --> 00:13:22,440
And that's getting a little complex and some Hindu mythology stuff that might be a little off track.

134
00:13:22,440 --> 00:13:28,440
But we'd love to hear it.

135
00:13:28,440 --> 00:13:39,080
I'm working on a new book and the theme is just getting into, again, the limitations of the thinking mind and helping with a lot of exercises,

136
00:13:39,080 --> 00:13:46,320
helping people to feel for themselves that the thinking mind is this very old program we have in our skull.

137
00:13:46,320 --> 00:13:54,720
And it's primarily concerned with survival. It's concerned with group identity because group identity is probably how we survived.

138
00:13:54,720 --> 00:14:03,840
You know, if you look back like a couple hundred thousand years ago, there were like six different human species on Earth.

139
00:14:03,840 --> 00:14:09,120
And you look around, you only find homo sapiens and no one's really sure what happened.

140
00:14:09,120 --> 00:14:18,160
You know, one theory is that maybe there's a virus, but another theory is that our thinking mind allowed us this capacity for abstraction.

141
00:14:18,160 --> 00:14:22,240
So we were able to first think of ourselves as a group.

142
00:14:22,240 --> 00:14:30,680
It's us versus them. And then we as a species systematically eliminated all other forms of humanity.

143
00:14:30,680 --> 00:14:36,800
You know, when you think about that, it's almost like the original sin of the human species,

144
00:14:36,800 --> 00:14:43,560
like we set out and because we had this way of thinking that allowed us to see us as a group.

145
00:14:43,560 --> 00:14:50,080
You know, I mean, think about a Neanderthal. I mean, there's no way some homo sapien in the past is going to take a Neanderthal.

146
00:14:50,080 --> 00:14:59,200
They're bigger, stronger. But if you get a group of a hundred homo sapiens and they're clever and they can plan, they're going to win that battle.

147
00:14:59,200 --> 00:15:05,040
But they also made it with them, too, right? Because we have some Neanderthal in our DNA.

148
00:15:05,040 --> 00:15:10,520
And if you've ever played around with these tests now, it's a kind of strange thing to get this back.

149
00:15:10,520 --> 00:15:15,640
I got my results back and I was like one percent Neanderthal.

150
00:15:15,640 --> 00:15:23,560
I haven't done it myself. My girlfriend has done it. I'm you know, I was in the belief that because like 23 and me,

151
00:15:23,560 --> 00:15:29,280
a pharmaceutical company invested on it for like billions of dollars, so they have access to all the genetic code.

152
00:15:29,280 --> 00:15:33,200
And part of their agreement is that we can do whatever we want to do with your genetic code.

153
00:15:33,200 --> 00:15:38,120
So it's a little uncomfortable, but you know, at some point they're like, well, it is what it is.

154
00:15:38,120 --> 00:15:42,240
How am I going to get out of it? So, yeah, it sounds interesting.

155
00:15:42,240 --> 00:15:46,880
And they're not all mutually exclusive. There's a chance that we probably did made a little bit.

156
00:15:46,880 --> 00:15:50,040
And like I said, it could have been a virus.

157
00:15:50,040 --> 00:15:55,520
But the one theory that I'm particularly attracted to, because it helps explain so much to me,

158
00:15:55,520 --> 00:16:07,880
that it was our capacity for conceptualizing in-groups and out-groups that allowed us to work together as a tribe and then eliminate any competition.

159
00:16:07,880 --> 00:16:12,640
And now that's backfiring on us, because what do you do when you've eliminated all the competition?

160
00:16:12,640 --> 00:16:16,640
But you have a program that sees everyone as an in-group or an out-group.

161
00:16:16,640 --> 00:16:18,440
It ran its course.

162
00:16:18,440 --> 00:16:24,160
It ran this program, ran its course. It's outdated. And, you know, like you're talking about software,

163
00:16:24,160 --> 00:16:33,720
the interesting thing about software is, I mean, it's continuously, I mean, AI, the reason it's able to become so exponential is because it's always changing.

164
00:16:33,720 --> 00:16:39,160
I mean, imagine using a computer from 10 years ago. Even 10 years ago, it would be outdated.

165
00:16:39,160 --> 00:16:47,320
But the software we have upstairs, it honestly seems like it hasn't had an update in 70,000 years.

166
00:16:47,320 --> 00:16:55,400
It's like we're running this whole program that's trying to survive and it has nothing to do now.

167
00:16:55,400 --> 00:17:01,720
I mean, when you look at that, it's true. A lot of people on this planet, they're hungry.

168
00:17:01,720 --> 00:17:05,600
They don't have shelter. You know, the basics of life are not there.

169
00:17:05,600 --> 00:17:11,800
But what I work on, my book, my work is more around people who actually have everything.

170
00:17:11,800 --> 00:17:20,880
They have a house. They have maybe, you know, I live in a small town and it amazes me that if I drive around, there are 30,000, $40,000 cars everywhere.

171
00:17:20,880 --> 00:17:27,600
You know, everywhere. I mean, it's just this abundance of wealth and fast food places.

172
00:17:27,600 --> 00:17:30,680
You know, you make a phone call and food gets delivered.

173
00:17:30,680 --> 00:17:38,120
The mind has nothing to do. What is it going to do now? What problem is it going to solve?

174
00:17:38,120 --> 00:17:42,280
It doesn't have to. All the basics of survival have been met.

175
00:17:42,280 --> 00:17:49,200
So what the mind does is it opens up the category of what a problem is.

176
00:17:49,200 --> 00:17:53,680
And this is why we find these fascinating things where people will complain about the air conditioning.

177
00:17:53,680 --> 00:17:59,840
You know, if it's one degree off and they're like, well, the air conditioning is one degree because it has nothing to do.

178
00:17:59,840 --> 00:18:04,040
You know, so in events, I mentioned a really fascinating study to your audience.

179
00:18:04,040 --> 00:18:12,520
I think it's. Maybe the most important study, like if I had to rank them for whatever that would be worth in the last 20 years.

180
00:18:12,520 --> 00:18:17,120
And I'll give you the link because I'm not really good remembering the details.

181
00:18:17,120 --> 00:18:22,640
So they had a simple task and it was just detect when a blue dot appears.

182
00:18:22,640 --> 00:18:27,840
OK, that's pretty simple. Press the button when a blue dot appears and then a couple of different variations of this.

183
00:18:27,840 --> 00:18:31,320
And another press a button when you see an angry face.

184
00:18:31,320 --> 00:18:36,280
And then a third, you press a button, you read a short paragraph or something.

185
00:18:36,280 --> 00:18:39,720
And if there's something unethical, then you press a button.

186
00:18:39,720 --> 00:18:44,600
So it sounds pretty straightforward. And if we are rational.

187
00:18:44,600 --> 00:18:47,840
You know, we only press a button when we see a blue dot.

188
00:18:47,840 --> 00:18:49,960
But what the experimenters did was very clever.

189
00:18:49,960 --> 00:18:56,600
So they had the targets available at the beginning of the study, but then they started removing the targets.

190
00:18:56,600 --> 00:19:01,480
So they started removing blue dots and they started removing ethical problems that are removing angry faces.

191
00:19:01,480 --> 00:19:05,360
Now, you think if we are rational, we'll just stop responding.

192
00:19:05,360 --> 00:19:08,520
They're not there anymore, but that's now what these subjects did.

193
00:19:08,520 --> 00:19:12,600
They actually redefined what a blue dot was.

194
00:19:12,600 --> 00:19:18,640
And so now maybe it's a purple dot, but they were pressing, oh, that's blue or maybe it was a slight little ethical problem.

195
00:19:18,640 --> 00:19:22,800
Oh, no, that's that's that's an ethical problem or that's an angry face.

196
00:19:22,800 --> 00:19:29,280
So they would redefine the target so it matched what the goal of the experiment was.

197
00:19:29,280 --> 00:19:37,640
And you just see this, you know, the mind is like out there looking for problems and it just it keeps expanding what a problem is.

198
00:19:37,640 --> 00:19:40,880
So it has something to work with.

199
00:19:40,880 --> 00:19:45,200
Yeah. And when you saw that it changes the goalposts, I was like, yeah, exactly.

200
00:19:45,200 --> 00:19:50,400
It's never ending. And the interesting thing about this is they told the subjects this.

201
00:19:50,400 --> 00:19:57,240
You could tell the subjects, like, by the way, we're going to we're going to change the we're going to we're going to stop showing blue dots.

202
00:19:57,240 --> 00:20:03,960
And it didn't have any effect. They still like so it shows that this this mind program I talk about again,

203
00:20:03,960 --> 00:20:08,920
I call it Mind 1.0 because it's it's just old and it's never been updated.

204
00:20:08,920 --> 00:20:16,160
It's very resistant to intellectual information, you know, and it's and it's and it's do it.

205
00:20:16,160 --> 00:20:20,600
It thinks it's, you know, an ice age, 50,000 years ago.

206
00:20:20,600 --> 00:20:23,880
And it's and it's out there thinking I'm going to have to hunt for food.

207
00:20:23,880 --> 00:20:29,080
But none of that's what we find in our day to day experiences.

208
00:20:29,080 --> 00:20:33,840
And so what's what's it going to do? Oh, the air conditioning is too cold.

209
00:20:33,840 --> 00:20:40,680
Yeah. And that is a mentality that will take you at the top echelon of institutions and governments.

210
00:20:40,680 --> 00:20:46,640
And basically every tribe and every group and every organization,

211
00:20:46,640 --> 00:20:56,720
which themselves are created of or creation of this old mind and people who make all the way at the very top,

212
00:20:56,720 --> 00:21:00,920
like Alan Watts, I think he was saying that the person at the top has a bloodiest knife.

213
00:21:00,920 --> 00:21:08,400
Oh, yeah. You know, sit on the biggest throne with his back to the wall.

214
00:21:08,400 --> 00:21:10,720
As you know, someone else is going to take it from you.

215
00:21:10,720 --> 00:21:14,440
And that's what we've been doing. And yeah, you're right.

216
00:21:14,440 --> 00:21:16,200
You look particularly at the universities.

217
00:21:16,200 --> 00:21:22,920
I mean, there's even this area where they call the grievance studies or it's like the mind is like purposely going out.

218
00:21:22,920 --> 00:21:27,240
And so, you know, where can I where's I have nothing to do because I've got my food.

219
00:21:27,240 --> 00:21:31,560
I've got my. So what am I going to complain about? What's the problem that I can solve?

220
00:21:31,560 --> 00:21:38,080
And it goes out and it finds these like, you know, really silly little things to try to fix.

221
00:21:38,080 --> 00:21:41,400
Like I said, I mean, I'm fixing, though, they're destroying.

222
00:21:41,400 --> 00:21:44,360
That's another thing that there are builders.

223
00:21:44,360 --> 00:21:55,080
And I realize that throughout human history, there has been far less builders than people who have destroyed with the plan that, hey,

224
00:21:55,080 --> 00:21:57,760
we're going to destroy this to build something in its place.

225
00:21:57,760 --> 00:22:07,080
But when you destroy something, you realize that it's actually not that easy to build something that this thing that I've destroyed within an hour or two hours.

226
00:22:07,080 --> 00:22:12,920
It's been, you know, maybe it take like 10, 10 years, 20 years for it to be built.

227
00:22:12,920 --> 00:22:25,440
And the idea that this whatever it is manifested as, you know, as basically a sign of that idea as a respect to that idea,

228
00:22:25,440 --> 00:22:31,360
as a representation of that idea, that itself could be much, much older, you know, centuries.

229
00:22:31,360 --> 00:22:36,880
So that seems to be another issue that we are dealing with right now that, hey, we just don't like this.

230
00:22:36,880 --> 00:22:39,080
Let's destroy the whole thing.

231
00:22:39,080 --> 00:22:43,440
And well, what are you proposing as an alternative?

232
00:22:43,440 --> 00:22:46,480
There is no proposal. There is an alternative. This is just bad.

233
00:22:46,480 --> 00:22:49,440
It needs to go. Right.

234
00:22:49,440 --> 00:22:53,640
And again, yeah, and it does seem like it has to it's it's not personal.

235
00:22:53,640 --> 00:23:05,080
That has to be some manifestation of some kind of species level wiring to just destroy and then just really hope that this small group of builders somehow,

236
00:23:05,080 --> 00:23:11,760
you know, if you do look, I mean, like you said, maybe it is a smaller percentage, but maybe we've been lucky.

237
00:23:11,760 --> 00:23:19,200
I mean, there are people who go in and they build the right constitutions and they and they they come up with these ideas and they do things.

238
00:23:19,200 --> 00:23:27,760
So I don't know if we've just gotten lucky so far because you do sort of what if because you could look at this as like, you know, people who build and people who destroy,

239
00:23:27,760 --> 00:23:37,680
what if people who destroy become so dominant that the builders no longer exist, you know, I mean, it kind of reminds me of a line.

240
00:23:37,680 --> 00:23:46,200
I think Elon Musk was saying during one of his interviews, it was like, you know, if people stop making things, there's no more things.

241
00:23:46,200 --> 00:23:50,440
And that's true, not just for physical things, but it's for for philosophical systems.

242
00:23:50,440 --> 00:24:00,680
And so if you, you know, if you want to tear down a philosophical system, well, you know, do you have something like an alternative that you're going to present?

243
00:24:00,680 --> 00:24:05,720
Yeah, it's interesting. You mentioned Elon Musk late May.

244
00:24:05,720 --> 00:24:10,640
I think it was like a week after we talked. I went to see SpaceX's launch.

245
00:24:10,640 --> 00:24:13,920
It was a test test for the Dragon crew.

246
00:24:13,920 --> 00:24:16,760
They sent three people to International Space Station.

247
00:24:16,760 --> 00:24:20,560
And it's a very spiritual kind of a thing, especially with SpaceX.

248
00:24:20,560 --> 00:24:22,640
The first time I saw it, it was Falcon Heavy.

249
00:24:22,640 --> 00:24:26,520
And then you see those two coming back to Earth, which is like science fiction.

250
00:24:26,520 --> 00:24:28,360
The rocket goes up and then come back down.

251
00:24:28,360 --> 00:24:33,600
It's it has a spiritual kind of, you know, it makes you feel a certain kind of way.

252
00:24:33,600 --> 00:24:39,120
And then I was driving back like three hours north of here, driving back in radio.

253
00:24:39,120 --> 00:24:45,120
I heard that there are like riots and looting in certain places in the United States.

254
00:24:45,120 --> 00:24:48,360
It was right after the death of George Floyd.

255
00:24:48,360 --> 00:24:57,920
And I was like, look at this contrast that one is the manifestation of the greatest achievement of humanity,

256
00:24:57,920 --> 00:25:02,440
you know, engineering and you sending humans out of, you know, out of this planet.

257
00:25:02,440 --> 00:25:11,840
And the other is breaking into a Nike store and stealing shoes because you're upset about racism.

258
00:25:11,840 --> 00:25:17,560
You know, and some people who see what's going on, they're not saying anything,

259
00:25:17,560 --> 00:25:21,640
because exactly like what you said, they want to be part of a group.

260
00:25:21,640 --> 00:25:24,960
They don't want to deviate away from the narrative.

261
00:25:24,960 --> 00:25:27,960
And I have a certain, you know, I have empathy.

262
00:25:27,960 --> 00:25:31,600
I really feel like it's difficult.

263
00:25:31,600 --> 00:25:38,400
I remember one time when my daughter was very young and and we were at some place where she was getting lessons for swimming.

264
00:25:38,400 --> 00:25:43,360
And there was only one teacher and she looked like she's herself, maybe like 12 years old.

265
00:25:43,360 --> 00:25:48,000
So and she was teaching a bunch of kids like in like five or six years old.

266
00:25:48,000 --> 00:25:52,680
And and it was just clear like she could not handle this many kids.

267
00:25:52,680 --> 00:25:54,000
It was a dangerous situation.

268
00:25:54,000 --> 00:25:57,760
But she in a very authoritative way said all the parents need to leave.

269
00:25:57,760 --> 00:26:04,200
And I remember just going with the herd, you know, and that I heard it was something that broke through that and said, what are you doing?

270
00:26:04,200 --> 00:26:06,920
Wake up. And I turned around and I said, we're leaving.

271
00:26:06,920 --> 00:26:08,720
I'm like, this is just a bad situation.

272
00:26:08,720 --> 00:26:14,240
But it's it's such an almost autonomous force to to want to be part of that group.

273
00:26:14,240 --> 00:26:16,280
And I think you see that with social media.

274
00:26:16,280 --> 00:26:24,880
I mean, this is that feeling you get when people like videos and, you know, just that we're so programmed to be liked.

275
00:26:24,880 --> 00:26:28,880
And the interesting thing about the program is doesn't care what the situation is.

276
00:26:28,880 --> 00:26:34,040
It doesn't care if it's a positive situation. It's just like it's like this mentalistic thing saying, go be liked.

277
00:26:34,040 --> 00:26:38,800
I don't care what the situation is. You know, I don't care what the particulars are.

278
00:26:38,800 --> 00:26:41,640
Just be liked at all cost.

279
00:26:41,640 --> 00:26:46,760
Yeah. And the end game is just be like so things will be better.

280
00:26:46,760 --> 00:26:54,040
Right. Is better the single word that you would describe the end game that it's unachievable because the goalposts change all the time.

281
00:26:54,040 --> 00:26:56,080
Is it better?

282
00:26:56,080 --> 00:27:01,720
Well, I think that's a great way to put it, because, you know, it's always something that seems better.

283
00:27:01,720 --> 00:27:04,360
But then you adapt to it very quickly.

284
00:27:04,360 --> 00:27:09,560
And then, you know, it's like that billionaire when people ask him how much money will finally be enough.

285
00:27:09,560 --> 00:27:13,280
And he said just a little bit more.

286
00:27:13,280 --> 00:27:19,800
And so, you know, when we get into that mode, it's a very, you know, that's I mean, people are becoming aware of this, though.

287
00:27:19,800 --> 00:27:25,720
And it's fascinating that, you know, people are kind of getting off that endless treadmill.

288
00:27:25,720 --> 00:27:37,280
And you see some millionaires and some very wealthy people just giving it all up and going out into nature, you know, I think a great remedy for what's going on right now,

289
00:27:37,280 --> 00:27:48,160
particularly when people with lockdowns, at least when I talk to people, the thing that terrifies people is to be alone with their own thoughts.

290
00:27:48,160 --> 00:27:52,200
You know, like for some people, they like the distractions.

291
00:27:52,200 --> 00:27:54,600
They like to go to work and you get to go to a bar.

292
00:27:54,600 --> 00:27:57,720
We have a lot of distractions and even being part of a group.

293
00:27:57,720 --> 00:28:01,360
And so, you know, you go out and, you know, go into some place and still night.

294
00:28:01,360 --> 00:28:03,720
I mean, that's a great distraction.

295
00:28:03,720 --> 00:28:08,160
I mean, not at home thinking about your own thoughts.

296
00:28:08,160 --> 00:28:15,760
And so what do we do? What do you do when you're sitting alone with your own thoughts?

297
00:28:15,760 --> 00:28:20,440
I mean, for me, one of the remedies is going into nature.

298
00:28:20,440 --> 00:28:25,000
You know, I find nature a very positive distraction.

299
00:28:25,000 --> 00:28:34,800
It just seems to connect us with a past that, like I forget who said, we're a species who suffers from amnesia.

300
00:28:34,800 --> 00:28:44,120
And I think that's so true. I mean, we've been on this planet for millions of years and we act as if this all just happened yesterday.

301
00:28:44,120 --> 00:28:52,640
You know, like cell phones and cement roads and cars that go 100 miles an hour, like that's all normal, you know.

302
00:28:52,640 --> 00:28:56,440
And it's not. It's a really strange place.

303
00:28:56,440 --> 00:29:02,240
And, you know, the dominant thing, we were always alone with our thoughts.

304
00:29:02,240 --> 00:29:08,280
You know, we spend a lot of time in quiet, in silence.

305
00:29:08,280 --> 00:29:16,240
You know, I did just practice with my students because we don't realize how unusual silence is.

306
00:29:16,240 --> 00:29:18,920
And we're continuously surrounded by noise.

307
00:29:18,920 --> 00:29:24,120
And and I kind of thought, well, no, things are kind of quiet until I really went deep into it.

308
00:29:24,120 --> 00:29:27,040
And I realized, no, things are not quiet. It's always noisy.

309
00:29:27,040 --> 00:29:30,400
Even if I go for my jog in the morning, there's still cars, you know.

310
00:29:30,400 --> 00:29:33,880
And so what happens when you really turn everything down?

311
00:29:33,880 --> 00:29:40,000
And there's some very interesting work where and they found it by accident because they would always have silence as the control group.

312
00:29:40,000 --> 00:29:52,520
But it turns out in these silent conditions, you'd find neurogenesis and you'd find all kinds of really interesting things reorganizing in a positive way.

313
00:29:52,520 --> 00:29:56,120
And so silence is good. Being alone with our own thoughts is good.

314
00:29:56,120 --> 00:29:59,480
But we're just we're not adapt. We're not ready for it.

315
00:29:59,480 --> 00:30:04,560
It's just like some people just threw it threw us into this and it's freaking some people out.

316
00:30:04,560 --> 00:30:11,520
But but ultimately, I think it's, you know, being alone with your own thoughts is to me, it's the greatest part.

317
00:30:11,520 --> 00:30:18,960
It's a very good form of meditation because you recognize it's that opportunity to recognize that you are not your thoughts.

318
00:30:18,960 --> 00:30:25,880
You know, when you sit down, so you're alone with your own thoughts and and then you start realizing what a wild, strange program this is,

319
00:30:25,880 --> 00:30:33,800
the stuff that it goes into and and and and and my lack of control over it.

320
00:30:33,800 --> 00:30:40,920
You know, I mean, why can't I shut it? I mean, if you are alone with your own thoughts and you were in control of it all, you could just shut your thoughts off.

321
00:30:40,920 --> 00:30:46,880
But the very problem is that you can't shut them off. That's why they seem so tormenting to people.

322
00:30:46,880 --> 00:30:56,520
I mean, when you think about like one of the things social scientists will probably discover at some point over the last year is

323
00:30:56,520 --> 00:31:04,960
there is a certain reality with the virus and loss and tragedy and suffering, just like in life, and we have this.

324
00:31:04,960 --> 00:31:15,000
But in the end, I think what we're going to calculate is there are our own thoughts about what might happen far outweighed the reality of what actually did.

325
00:31:15,000 --> 00:31:22,400
Yeah, a lot of people in position of authority, they acted upon it, trying to I mean, it's true.

326
00:31:22,400 --> 00:31:29,520
It might sound mean, but they really try to benefit and make the best out of a tragedy, basically.

327
00:31:29,520 --> 00:31:34,920
Who was somebody said, don't let a good don't let a good tragedy go to waste or something like that.

328
00:31:34,920 --> 00:31:42,480
Don't let the good crisis go to waste. So Rahm Emanuel was mayor of Chicago.

329
00:31:42,480 --> 00:31:46,480
But yeah, we are stuck with this. And I think what you're saying is completely true.

330
00:31:46,480 --> 00:31:52,640
The difference is between whether or not you're comfortable with your own thoughts or whether or not you are not comfortable with your thoughts.

331
00:31:52,640 --> 00:32:00,560
And the way to make that separation is to be willing to go with and deal with your thoughts.

332
00:32:00,560 --> 00:32:07,120
And not that many people are willing to do that because it's a very difficult thing to do, especially when.

333
00:32:07,120 --> 00:32:17,000
You know, with me, it happened with psychedelics, they helped a lot, but after a certain point, it's not about even that, you know, it's about, dude, you got to face yourself.

334
00:32:17,000 --> 00:32:24,160
And you've put a dent in this dome that you used to think it is you and you know that it is not you.

335
00:32:24,160 --> 00:32:31,480
And the quote by Gore Vidal that we don't even know what our cage looks like because we have never seen it from the outside.

336
00:32:31,480 --> 00:32:37,760
So you've seen it from the outside, but now you got to you got to deal with it's not going to go away. It's not going to be quiet ever.

337
00:32:37,760 --> 00:32:41,680
But you have to you have to understand what this is.

338
00:32:41,680 --> 00:32:48,120
And it's like I think I use this example the other time, like a fast moving train.

339
00:32:48,120 --> 00:32:54,960
It looks solid and continuous. But when it slows down, you see the gap between the wagons.

340
00:32:54,960 --> 00:33:01,840
So you slows it down and then you see what's behind it, which is the real, real deal.

341
00:33:01,840 --> 00:33:12,680
And that real deal, I learned to understand it as the concept of God, for lack of a better term, that is decentralized and layered.

342
00:33:12,680 --> 00:33:18,080
You know, everything is a manifestation of it and everything is experiencing it.

343
00:33:18,080 --> 00:33:22,280
And it is experiencing everything through everything, if that makes sense.

344
00:33:22,280 --> 00:33:29,440
Absolutely. So I'm perfectly fine with not knowing because I'm knowing to my capacity.

345
00:33:29,440 --> 00:33:37,920
You know, and the best I can do is to be a conduit and to be so hollow that my intellect goes away completely.

346
00:33:37,920 --> 00:33:40,600
It's my instinct that I'm acting upon.

347
00:33:40,600 --> 00:33:45,680
It's very safe to be a musician because, you know, the consequences are your musical notation.

348
00:33:45,680 --> 00:33:53,240
But, you know, it's like I'm, you know, I'm moving by the will of God, basically.

349
00:33:53,240 --> 00:33:55,680
It's an interesting place to be.

350
00:33:55,680 --> 00:34:00,560
It is. And there's a certain amount of courage that comes with that.

351
00:34:00,560 --> 00:34:08,720
And again, whether it's that courage to go against the crowd or to be alone with your thoughts and your thoughts are creating all kinds of suffering.

352
00:34:08,720 --> 00:34:13,280
And yet you deal with them in spite of that.

353
00:34:13,280 --> 00:34:19,360
For me, you know, when I was in my 20s, I was so unbelievably neurotic.

354
00:34:19,360 --> 00:34:24,680
I mean, my whole life, if I sat for a moment with my own thoughts, I was convinced I was going to die.

355
00:34:24,680 --> 00:34:29,120
You know, my heart was just going to, it was all this like typical neurotic kind of thing.

356
00:34:29,120 --> 00:34:33,480
And I remember in a moment, I just got so frustrated with it and I said, do your worst.

357
00:34:33,480 --> 00:34:36,400
I'm done with you. If you're going to kill me, just kill me right now.

358
00:34:36,400 --> 00:34:40,640
I've had it with you. And all of a sudden, I felt this peace, you know?

359
00:34:40,640 --> 00:34:51,080
And it was just kind of like that kind of, you know, rather than fighting it, in a way, it's kind of surrendered to it.

360
00:34:51,080 --> 00:34:54,600
But it takes a certain kind of bravery, I think, to do that.

361
00:34:54,600 --> 00:34:57,080
It's acceptance. Yeah.

362
00:34:57,080 --> 00:35:08,160
And I think that, you know, people say love, but it really is acceptance because love, the way that people, most people understand it, it's just a chemical reaction and it declines.

363
00:35:08,160 --> 00:35:15,280
And after a certain, it has a very specific evolutionary reason that you feel a certain way towards your mates.

364
00:35:15,280 --> 00:35:19,600
Right. It's a very different kind of feeling.

365
00:35:19,600 --> 00:35:27,200
When you're listening to music and you're not judging, you're going with it, which is you're accepting it as it is.

366
00:35:27,200 --> 00:35:29,920
There are no genres. There's no style.

367
00:35:29,920 --> 00:35:41,880
There is no because, you know, I've done this for so long when I was younger as a guitar player would listen to music and I feel bad inside that I'm not as good as this guy.

368
00:35:41,880 --> 00:35:46,240
You know, and then it affects the entire experience of enjoying a good music.

369
00:35:46,240 --> 00:35:51,000
Like, I don't have to be that guy. I'm me, you know, that experience.

370
00:35:51,000 --> 00:35:55,360
And I literally put the guitar down for a lot for years.

371
00:35:55,360 --> 00:36:06,280
I mean, it was, you know, and because I couldn't get over that judgmental, I'm not the guitar, you know, I'm not the musician I want to see myself as.

372
00:36:06,280 --> 00:36:08,920
And it was all caught up in judgment and expectation.

373
00:36:08,920 --> 00:36:24,800
And it took me, it was actually quite a while before I was able to get over all that and go back to that state, that non-judgmental kind of enjoying it and enjoying mistakes even as part of it and the whole process.

374
00:36:24,800 --> 00:36:34,480
And but that's something that we could take as a kind of a grand theory of what we need as a group right now.

375
00:36:34,480 --> 00:36:49,080
You know, that kind of categorical thinking that, you know, with expectation and self-judgment, I mean, that's what I put together as kind of the main components of this mind program I talk about.

376
00:36:49,080 --> 00:36:59,280
And I mean, that's how it works. That's how categories work, like in groups, now groups. And it seems to base these categories on really trivial features of other people.

377
00:36:59,280 --> 00:37:11,480
And then when you when you see that program for what it is and get beyond it, and then you like it, that immediate experience, like there's only like this in this moment, this is the only experience like this in the universe.

378
00:37:11,480 --> 00:37:12,160
Yeah.

379
00:37:12,160 --> 00:37:15,320
Now, this is it. This is blessed uniqueness.

380
00:37:15,320 --> 00:37:15,720
Yeah.

381
00:37:15,720 --> 00:37:20,560
I mean, there's nothing else like this that's ever happened in the history of reality.

382
00:37:20,560 --> 00:37:31,120
But even us talking like we've never talked about this right now, you know, and then that categorical mind, though, it comes along and says, no, this is Monday.

383
00:37:31,120 --> 00:37:35,960
No, this is the week, you know, it just wants these little mental boxes.

384
00:37:35,960 --> 00:37:40,240
And the problem with mental boxes is it just makes life feel very ordinary.

385
00:37:40,240 --> 00:37:45,680
Oh, I'm in another mental box. And that's the real paradox of our existence.

386
00:37:45,680 --> 00:37:56,480
Every moment is absolutely unique, but the mind has us believing that we've been in this moment before, you know, it's Monday morning at work.

387
00:37:56,480 --> 00:38:00,920
No, you've never been in this moment. Your entire existence is absolutely new.

388
00:38:00,920 --> 00:38:08,280
Everything that's happening to know because it will take these trivial little things that are common and it creates those categories.

389
00:38:08,280 --> 00:38:18,440
And that's what we do with people. We do it with music, you know, and it seems like we do it with government, you know, the way that we organize our lives.

390
00:38:18,440 --> 00:38:32,120
And, you know, like one of my other favorite Alan Watts quotes, he said that the best form of government is just, you know, they just muddle through, you know, and there's a certain sum with that, you know,

391
00:38:32,120 --> 00:38:45,400
instead of coming up with too many expectations and, you know, and grand goals and like, you know, handbooks of behavior and all these things that we've been, you know, doing for so long.

392
00:38:45,400 --> 00:38:51,320
You know, because all those are motivated by, hey, this will be a little bit better than what we have now.

393
00:38:51,320 --> 00:39:01,000
We just sort of muddle through. Yeah, it's also instruments of control for them, you know, because we've talked about this in the podcast, too.

394
00:39:01,000 --> 00:39:04,880
It's very uncomfortable for a lot of people when we talk about it.

395
00:39:04,880 --> 00:39:20,200
But the fact is that liberal democracy itself as a system has reached its limits because, yes, it would have worked great in the 80s and 90s when you had like, I don't know, 10 different TV channels and some newspapers to set the narrative.

396
00:39:20,200 --> 00:39:22,320
But the narrative was singular. Right.

397
00:39:22,320 --> 00:39:32,440
But now it doesn't matter that a majority will win because minority has all the channels that they need in order to express their dissatisfaction.

398
00:39:32,440 --> 00:39:36,320
So you cannot really govern as a democratic society.

399
00:39:36,320 --> 00:39:44,600
And, you know, Greeks hated democracy, founding fathers loathe democracy because it's a rule of a mob.

400
00:39:44,600 --> 00:39:55,000
And the entire point of this country is like what you mentioned, to be able to be that one person standing against the mob and like, I don't want to do it.

401
00:39:55,000 --> 00:39:56,320
This doesn't make any sense to me.

402
00:39:56,320 --> 00:40:04,680
And that one person will change the entire course of civilization for everyone else, you know, usually.

403
00:40:04,680 --> 00:40:14,560
I think we need alignment, but in a very general sense, I was thinking about starting some kind of a community that people can come.

404
00:40:14,560 --> 00:40:17,920
As creators, are you creating something?

405
00:40:17,920 --> 00:40:22,440
Is it a poetry? Is it like painting, music, computer program?

406
00:40:22,440 --> 00:40:27,480
That is the only point of alignment you have to create in order to stay in that community.

407
00:40:27,480 --> 00:40:31,880
And they'll create incentives for people, you know, more creative people want to hang out together.

408
00:40:31,880 --> 00:40:35,920
They start their own communities and they govern themselves.

409
00:40:35,920 --> 00:40:39,600
Painters want to live their own lives as painters.

410
00:40:39,600 --> 00:40:43,480
But the understanding that needs to come with that is that there is no better.

411
00:40:43,480 --> 00:40:44,880
There is no such thing as better.

412
00:40:44,880 --> 00:40:45,880
This is it.

413
00:40:45,880 --> 00:40:47,400
And what you make out of it.

414
00:40:47,400 --> 00:40:59,360
And not only that this second and this moment is unique, it's that all the other seconds and years and all the time that you've spent throughout your life to get right here,

415
00:40:59,360 --> 00:41:02,920
they had to happen exactly as they did for you to be here right now.

416
00:41:02,920 --> 00:41:04,760
And they were all unique in their own ways.

417
00:41:04,760 --> 00:41:06,440
So there is no regret.

418
00:41:06,440 --> 00:41:15,160
Yeah, I mean, that's a really amazing insight that can catch people when because we all have moments where we go back and if I could just change this,

419
00:41:15,160 --> 00:41:21,000
if I could just change one little thing, like I want to go back and, you know, if I had just done this differently.

420
00:41:21,000 --> 00:41:24,520
I mean, rumination is a huge component to depression.

421
00:41:24,520 --> 00:41:32,560
And but it's fascinating when you can turn that and just slightly.

422
00:41:32,560 --> 00:41:34,920
And there's a Japanese art.

423
00:41:34,920 --> 00:41:43,560
I don't know if you've seen it before, they've taken like, you know, precious pieces of art that have been broken and then they fill it all with this beautiful gold.

424
00:41:43,560 --> 00:41:51,360
And so kind of it's a way to reconceptualize where you realize that all these things I thought were mistakes got me exactly.

425
00:41:51,360 --> 00:41:55,200
They all culminate into this exact moment.

426
00:41:55,200 --> 00:41:57,400
And so they weren't really mistakes.

427
00:41:57,400 --> 00:42:00,240
You know, I wouldn't want to get rid of any of them.

428
00:42:00,240 --> 00:42:05,480
And yeah, that's a that's an interesting that's an interesting take.

429
00:42:05,480 --> 00:42:10,920
I I'm not sure if psychology has really done the way you're putting it is it's interesting.

430
00:42:10,920 --> 00:42:15,640
I don't know if we have the numbers on that because I don't know if psychologists have looked at that.

431
00:42:15,640 --> 00:42:18,400
I don't know how you quantify something like that.

432
00:42:18,400 --> 00:42:26,960
It might be difficult, but it's but it does seem like for a society to work, you have to have some number of people as builders.

433
00:42:26,960 --> 00:42:33,880
And then I think if you I mean, it seems much easier to be on the other side and just tear things down.

434
00:42:33,880 --> 00:42:35,880
That seems to be kind of an easy, you know.

435
00:42:35,880 --> 00:42:38,240
So, again, maybe the majority would be on that side.

436
00:42:38,240 --> 00:42:42,920
But I don't know. It's it's.

437
00:42:42,920 --> 00:42:46,120
I mean, so, yes, sorry.

438
00:42:46,120 --> 00:42:54,760
I was thinking in preparation for our conversation, which was mental, mostly just thinking about different topics.

439
00:42:54,760 --> 00:43:06,960
Tyranny itself seems to have a very deep root within our nature, because all the kids who I've seen at their very young age, they're tyrants.

440
00:43:06,960 --> 00:43:09,960
They don't want to compromise.

441
00:43:09,960 --> 00:43:11,440
They don't like it any other way.

442
00:43:11,440 --> 00:43:13,880
It is their way or the highway.

443
00:43:13,880 --> 00:43:21,120
And it is through some kind of a stronger force, this kind of a wall that is being built in front of them,

444
00:43:21,120 --> 00:43:27,240
hopefully in a nonviolent kind of a way to tell them, hey, dude, you cannot just get whatever you want in life.

445
00:43:27,240 --> 00:43:34,880
And then little by little, they became they become, I guess, more suitable for a polite society.

446
00:43:34,880 --> 00:43:44,720
But what can you tell me about this nature of tyranny in deep within humanity?

447
00:43:44,720 --> 00:43:50,120
Well, I think some of it comes down to that tribe mentality that probably outweighs that.

448
00:43:50,120 --> 00:43:59,000
And we all come into the world kind of with our own egotistic two year old is, you know, like the psychologist Piaget talked about them being so egocentric.

449
00:43:59,000 --> 00:44:02,760
They can't really see the world outside of their own view from it.

450
00:44:02,760 --> 00:44:07,560
But if you really want to be part of the group, that's got to have to compromise somehow.

451
00:44:07,560 --> 00:44:19,480
So I think we've got like some subroutine of the mind program that with a conformity and that desire to be part of the group eventually outweighs our own and some people.

452
00:44:19,480 --> 00:44:22,360
So maybe the baby is right.

453
00:44:22,360 --> 00:44:31,200
Right. And the individual sense, if each individual being and thing and species is a reflection of the whole,

454
00:44:31,200 --> 00:44:39,520
and it's through the unique experience of each each of those elements and members that we all can experience the whole,

455
00:44:39,520 --> 00:44:50,320
maybe the baby is right then that this it is our need to control that have forced us to create groups.

456
00:44:50,320 --> 00:44:54,560
And, you know, things can become so normal to us.

457
00:44:54,560 --> 00:45:00,480
You know, you walk in through a mall and just because you grew up like I grew up in the 80s and, you know,

458
00:45:00,480 --> 00:45:06,760
malls were normal and we become habituated to them and stuff, but they're really freaky, weird things.

459
00:45:06,760 --> 00:45:17,640
A lawn is weird. You know, I mean, so, you know, we've gone off in these really we've created this bizarre world

460
00:45:17,640 --> 00:45:22,880
that I think if we went back again, 40,000 years and, you know, we haven't changed as a species.

461
00:45:22,880 --> 00:45:26,480
We could go back in a time machine and take someone from 40,000 years ago.

462
00:45:26,480 --> 00:45:30,440
They wouldn't go, you know, we wouldn't recognize and they would look just like us.

463
00:45:30,440 --> 00:45:36,040
And if they walked around in our modern version, they would say, you all are a bunch of control freaks.

464
00:45:36,040 --> 00:45:39,160
I mean, you know, you are obsessed with control.

465
00:45:39,160 --> 00:45:46,600
You're trying to create these worlds and really, you know, it is very little reflection in terms of nature.

466
00:45:46,600 --> 00:45:49,080
It is very little usefulness.

467
00:45:49,080 --> 00:45:58,000
You've poured concrete over so much of the earth that, you know, it would probably just seem like such a bizarre world to them.

468
00:45:58,000 --> 00:46:02,880
We'd probably have a very difficult time talking them into this being progress.

469
00:46:02,880 --> 00:46:07,440
They would probably look at us and and that's, you know, I don't know if we talked about the Piraha tribe,

470
00:46:07,440 --> 00:46:16,680
but, you know, if you get into these places in the world where, you know, these where they live in a much closer to the way our ancestors lived,

471
00:46:16,680 --> 00:46:25,720
it would be very difficult to convince them of TVs and cell phones and all these things being progressed.

472
00:46:25,720 --> 00:46:32,320
And that, you know, I mean, there are some things like, again, there's this temptation where, you know, things like housework.

473
00:46:32,320 --> 00:46:39,840
And we've had a major revolution where, you know, I mean, maybe 100, 100 or so years ago, Steven Pinker talks about this.

474
00:46:39,840 --> 00:46:48,360
I mean, we've cut down about 40 to 60 hours of housework a week because we have appliances and, you know, dishwashers and all this kind of thing.

475
00:46:48,360 --> 00:46:49,520
Automated it.

476
00:46:49,520 --> 00:46:54,800
I do. We've automated it. And that's just going to go, you know, like you were talking with AI.

477
00:46:54,800 --> 00:46:56,640
I mean, we're just on the verge of that.

478
00:46:56,640 --> 00:47:03,080
I mean, 20 years from now, again, I would speculate we will have no housework at all.

479
00:47:03,080 --> 00:47:09,240
I mean, we won't do anything. We're going to have it's all going to be taken care of.

480
00:47:09,240 --> 00:47:13,520
And that's probably not going to be a good thing.

481
00:47:13,520 --> 00:47:18,360
You know, again, it's all in that name of control.

482
00:47:18,360 --> 00:47:28,280
It's all in control because the mind is certain that its version of what is better is actually truly better.

483
00:47:28,280 --> 00:47:35,520
And that's like you talk when people tear things down, they tear it down because they're convinced that, you know, it's that I'm right.

484
00:47:35,520 --> 00:47:37,360
Yeah, objectively right.

485
00:47:37,360 --> 00:47:42,480
Oh, yeah. And one of the most dangerous things that humans have ever played around with.

486
00:47:42,480 --> 00:47:59,880
That's why I love the wisdom of insecurity, like I would rather, you know, stumble through life not sure than take the responsibility of thinking I'm right about something and then going in and changing the world when I really don't know even something obvious.

487
00:47:59,880 --> 00:48:04,200
So you say, OK, I'm going to come up. What if you had a cure for the virus?

488
00:48:04,200 --> 00:48:11,520
Now, wouldn't it be obvious? You say, if I'm a cure, like, OK, go ahead, give it out to everybody, you know, but then for all, you know, it could mutate.

489
00:48:11,520 --> 00:48:15,120
And then, you know, be 10 times worse the next day.

490
00:48:15,120 --> 00:48:19,400
You know, I mean, that's the thing about the thinking mind and its kind of battle against nature.

491
00:48:19,400 --> 00:48:26,000
Nature is doing very complex things that the mind has a difficult time comprehending.

492
00:48:26,000 --> 00:48:30,040
And so we think if we just tweak one variable, it's all going to be better.

493
00:48:30,040 --> 00:48:33,960
But it doesn't seem like nature works like that until we.

494
00:48:33,960 --> 00:48:42,560
I think, you know, like you said, I think when you have that appreciation for nature, it can feel like a very spiritual, overwhelming experience.

495
00:48:42,560 --> 00:48:48,320
Like you're dealing with some type like God, like force.

496
00:48:48,320 --> 00:48:57,560
And and it's because it overwhelms the mind so much the mind literally blows your mind to realize the complexity.

497
00:48:57,560 --> 00:49:03,840
Like like I was out in our backyard, we had some blackberries and I'm like, you know, just going out and eating them.

498
00:49:03,840 --> 00:49:09,280
And I'm like, the universe made these without thinking about a single thought.

499
00:49:09,280 --> 00:49:11,600
It didn't think it didn't have government.

500
00:49:11,600 --> 00:49:16,080
There wasn't some government that came along and organized how these blueberries would be made.

501
00:49:16,080 --> 00:49:24,320
And it just did this incredible process without one written document, without any laws to guide it or rules.

502
00:49:24,320 --> 00:49:31,680
And, you know, given the complexity of that compared to my cell phone.

503
00:49:31,680 --> 00:49:39,320
You know, it might be an easy choice to go with the blueberries.

504
00:49:39,320 --> 00:49:43,800
Well, some people would say there are laws of physics, but I am.

505
00:49:43,800 --> 00:49:51,560
I will mention what Einstein said that there are forces, he says something like the forces we experienced like gravity,

506
00:49:51,560 --> 00:49:56,000
their tail and the paw of the lion, the body of a lion is somewhere else.

507
00:49:56,000 --> 00:50:05,520
So, you know, yes, we do have laws of physics, but that doesn't mean that they apply outside of our known universe.

508
00:50:05,520 --> 00:50:09,720
Even with mathematics, yes, we can predict how things are supposed to work.

509
00:50:09,720 --> 00:50:18,240
And many times they do, but that doesn't mean that that's how everything definitely and concretely works.

510
00:50:18,240 --> 00:50:24,080
Scott Adams tweeted something very interesting a couple of, I think it was a month ago,

511
00:50:24,080 --> 00:50:31,240
that closer we get to be able to build a simulation, closer we get to realize that we are one.

512
00:50:31,240 --> 00:50:39,600
Yeah, it rings very true, especially right now.

513
00:50:39,600 --> 00:50:43,840
Was it Elon Musk who was put to that?

514
00:50:43,840 --> 00:50:49,680
I guess he could ask any question he would ask, what lies outside the simulation?

515
00:50:49,680 --> 00:50:54,640
And I love the thought that we know this is a simulation.

516
00:50:54,640 --> 00:50:59,200
I mean, you know, from a neuroscientist perspective, I mean, it's clearly a simulation.

517
00:50:59,200 --> 00:51:05,800
I mean, you know, in terms of people's experiences being guided by neural activity.

518
00:51:05,800 --> 00:51:10,760
I mean, but then again, you could say, well, you know, how do we know we have a brain?

519
00:51:10,760 --> 00:51:17,640
So can we come back to that? But I just want to mention one study that this was on BBC,

520
00:51:17,640 --> 00:51:26,040
a documentary about brain that a person would go into an MRI machine and they have two different buttons.

521
00:51:26,040 --> 00:51:31,440
And like, you know, when you want to press right, press right.

522
00:51:31,440 --> 00:51:33,560
When you want to press left, press left. That's it.

523
00:51:33,560 --> 00:51:38,600
But what they concluded was that seven seconds before they make the decision and press a button,

524
00:51:38,600 --> 00:51:41,360
they could see it in their brain that they're going to press right.

525
00:51:41,360 --> 00:51:42,680
They're going to press left.

526
00:51:42,680 --> 00:51:50,520
So a lot of our action is not necessarily in the conscious, as conscious as we think they are anyways.

527
00:51:50,520 --> 00:51:53,640
I love that study. You know, that goes back to Benjamin Labette's.

528
00:51:53,640 --> 00:51:55,600
He did very similar research in the 70s.

529
00:51:55,600 --> 00:51:59,880
And I mean, the techniques weren't as clean, but he was able to show again,

530
00:51:59,880 --> 00:52:05,880
the brain decides before we have that kind of conscious experience that I'm deciding.

531
00:52:05,880 --> 00:52:10,920
And so we've there's enough neuropsychological evidence that that feeling like, OK,

532
00:52:10,920 --> 00:52:12,560
you know, I'm going to move my hand right now.

533
00:52:12,560 --> 00:52:16,120
Clearly, my brain makes that decision before I get that.

534
00:52:16,120 --> 00:52:20,200
And that's one of the great arguments against the self-concept free will.

535
00:52:20,200 --> 00:52:27,520
Right. We say the whole idea of the self is just an idea in the brain that's an afterthought.

536
00:52:27,520 --> 00:52:31,400
And that was one of the motives behind writing those self.

537
00:52:31,400 --> 00:52:38,040
No problem, because there's just so much overwhelming neuropsychic evidence that what we conceive of is

538
00:52:38,040 --> 00:52:45,200
this kind of being with free will is just, you know, a story, an illusion.

539
00:52:45,200 --> 00:52:52,800
And I and I really do think that, you know, we started this talk with that most important question.

540
00:52:52,800 --> 00:52:56,080
Who am I? You know, and it breaks a lot of it down.

541
00:52:56,080 --> 00:53:00,280
So, you know, who am I without if I'm not the one who's thinking that I'm making a decision?

542
00:53:00,280 --> 00:53:03,720
Well, that, you know, we kind of strip the layers of self part.

543
00:53:03,720 --> 00:53:10,960
You know, I'm not who society has taught me, you know, I'm not defined by my job, you know,

544
00:53:10,960 --> 00:53:15,200
my income, the social expectations and roles that everyone has placed upon me.

545
00:53:15,200 --> 00:53:17,160
So we tear tear all that down.

546
00:53:17,160 --> 00:53:20,920
But then it gets down to this really interesting stuff with free will.

547
00:53:20,920 --> 00:53:26,600
OK, I'm not the decisions that my thinking mind thinks that it's making.

548
00:53:26,600 --> 00:53:36,080
Now, who am I? And I mean, so, you know, what's interesting, it just occurred to me right now

549
00:53:36,080 --> 00:53:46,160
that this process of asking the real question follows a series of destruction.

550
00:53:46,160 --> 00:53:52,640
It does. But in a way, the nice thing about it is when you tear it all apart,

551
00:53:52,640 --> 00:53:56,760
there's actually something, you know, there is something there.

552
00:53:56,760 --> 00:54:01,920
It's not because it's not like thoughtless, like this deconstruction for the purpose of deconstruction.

553
00:54:01,920 --> 00:54:06,320
It's more like, you know, like someone doing a sculpt, like you're doing a piece of artwork

554
00:54:06,320 --> 00:54:08,400
and you're just pulling this and this away.

555
00:54:08,400 --> 00:54:12,400
And it's one illusion after another. And then you find something.

556
00:54:12,400 --> 00:54:18,600
And the thing that you're finding there is always going to be a mystery to the thinking mind.

557
00:54:18,600 --> 00:54:23,960
And I think it's what I would call for the best name we've come up with is this consciousness.

558
00:54:23,960 --> 00:54:26,800
Which is everything, right?

559
00:54:26,800 --> 00:54:31,720
Yeah. I mean, it's the foundation of reality as we know it.

560
00:54:31,720 --> 00:54:42,160
And it's the one permanent underneath the endless illusion of impermanence.

561
00:54:42,160 --> 00:54:44,960
And so conscious, whatever name you want to give it,

562
00:54:44,960 --> 00:54:48,720
I think people throughout history have given it all kinds of different names.

563
00:54:48,720 --> 00:54:52,080
And they've called it all kinds of different things because the different cultures and different,

564
00:54:52,080 --> 00:54:55,200
you know, social influences. I mean, it's just a name.

565
00:54:55,200 --> 00:55:01,280
But the thing they're referring to ultimately is the essence that, you know, is underneath our ego.

566
00:55:01,280 --> 00:55:10,880
Underneath it is that it is the consciousness that so many researchers in consciousness

567
00:55:10,880 --> 00:55:13,320
get confused with the thinking mind.

568
00:55:13,320 --> 00:55:18,280
And so from my perspective, I deconstruct. I guess I do.

569
00:55:18,280 --> 00:55:23,640
You know, I take apart the thinking mind, not because I want to destroy it.

570
00:55:23,640 --> 00:55:26,560
I just want to put it in its place.

571
00:55:26,560 --> 00:55:32,240
And the thinking mind is an incredibly useful tool as long as you use it when you need to.

572
00:55:32,240 --> 00:55:40,840
You know, it's great to make out schedules, to plan and to, you know, do things around the house.

573
00:55:40,840 --> 00:55:43,080
It's not a great way to live.

574
00:55:43,080 --> 00:55:48,080
And so I like to make consciousness my home and then the thinking mind a place I visit.

575
00:55:48,080 --> 00:55:53,600
And do you feel that consciousness is something that will remain unknowable?

576
00:55:53,600 --> 00:55:58,040
Yes. Unknowable to the thinking mind.

577
00:55:58,040 --> 00:56:01,160
And that's a problem that human beings are facing right now.

578
00:56:01,160 --> 00:56:09,000
You know, we found things like quantum mechanics, the most successful theory in all of science.

579
00:56:09,000 --> 00:56:12,240
And it makes crazy predictions that no one can understand.

580
00:56:12,240 --> 00:56:14,000
Well, that's reality.

581
00:56:14,000 --> 00:56:17,560
You know, just because we can't understand it doesn't mean it's not real.

582
00:56:17,560 --> 00:56:26,440
Why in the world will we have this amazingly ego assumption that our thinking mind could comprehend reality?

583
00:56:26,440 --> 00:56:31,160
I mean, why? I mean, you know, with science, and again, it's a fun thing.

584
00:56:31,160 --> 00:56:37,560
You can do science. It's a good living. It's, you know, it's fun to play around with these things.

585
00:56:37,560 --> 00:56:44,520
Is science going to alter, is neuroscience going to reveal the nature of consciousness?

586
00:56:44,520 --> 00:56:48,640
I mean, I really have no hope on that.

587
00:56:48,640 --> 00:56:50,560
But I don't blame people for doing it.

588
00:56:50,560 --> 00:56:52,160
I think it's a great adventure.

589
00:56:52,160 --> 00:56:56,840
And, you know, if you were one of these neuros, there's a lot of neuroscientists out there studying the topic of consciousness.

590
00:56:56,840 --> 00:56:59,760
And I totally empathize with why they would want to do that.

591
00:56:59,760 --> 00:57:02,760
It's a, you know, it's a it's a fun thing to do for a living.

592
00:57:02,760 --> 00:57:06,240
But I could never take it seriously.

593
00:57:06,240 --> 00:57:14,360
I could never believe that no matter, I mean, no matter how much you study the brain, you're not going to find this thing called consciousness.

594
00:57:14,360 --> 00:57:15,800
The real deal.

595
00:57:15,800 --> 00:57:19,440
Yeah. It's not a thing to be found.

596
00:57:19,440 --> 00:57:24,680
Not a thing. You know, that's the way the thinking mind thinks in terms of things.

597
00:57:24,680 --> 00:57:29,200
You know, and and that's again, it's all tied in with that idea.

598
00:57:29,200 --> 00:57:35,560
As soon as you come up with things, you start controlling, you know, come up with a hammer and you build.

599
00:57:35,560 --> 00:57:37,160
And that's what we're doing.

600
00:57:37,160 --> 00:57:41,240
And this is a kind of wild adventure that we're building this world.

601
00:57:41,240 --> 00:57:43,880
And it's a it's a very strange place to live in.

602
00:57:43,880 --> 00:57:49,240
But you can look at it in that way or you could think of it as just, you know,

603
00:57:49,240 --> 00:57:55,800
consciousness, because if this is all consciousness, then even the thinking mind is just a form of consciousness.

604
00:57:55,800 --> 00:58:02,600
You know, and even the stuff that we're doing, like even the buildings and the cars and all these things on the one hand,

605
00:58:02,600 --> 00:58:07,080
you could say, well, they're not very natural, but they came out of nature.

606
00:58:07,080 --> 00:58:10,040
So in a way, they're just as natural as anything else.

607
00:58:10,040 --> 00:58:20,440
And so we're going on a very interesting ride that will be particularly interesting, interesting, I think, when AI.

608
00:58:20,440 --> 00:58:25,040
Give AI about 10 more years.

609
00:58:25,040 --> 00:58:29,120
And I think that's when it's going to get really interesting,

610
00:58:29,120 --> 00:58:34,360
because I always think of AI is like we're the we're always at the least intelligent point in history when it comes to AI,

611
00:58:34,360 --> 00:58:36,240
because tomorrow we'll be far more intelligent.

612
00:58:36,240 --> 00:58:38,120
Yeah, exactly. Yes.

613
00:58:38,120 --> 00:58:42,120
And so, you know, and that's difficult on people.

614
00:58:42,120 --> 00:58:48,640
You know, we get frustrated with our phones because it's not it's intelligent, you know, and it can.

615
00:58:48,640 --> 00:58:54,200
But it's not. We haven't worked it all out.

616
00:58:54,200 --> 00:59:00,120
And I think when the intelligence takes itself over and it starts evolving naturally,

617
00:59:00,120 --> 00:59:03,800
and that's when it's going to get really, really interesting.

618
00:59:03,800 --> 00:59:07,360
Well, you mean, well, we the only human species on the planet,

619
00:59:07,360 --> 00:59:15,640
but we'll have to start sharing our the intelligence of our thinking mind with other intelligent beings that we're doing right now.

620
00:59:15,640 --> 00:59:19,520
Yeah, yeah. Social media, phones, all of our data.

621
00:59:19,520 --> 00:59:25,440
And, you know, that's actually we were talking about the exact same thing with my previous guest,

622
00:59:25,440 --> 00:59:33,160
that people who are more rooted within more traditional way of living,

623
00:59:33,160 --> 00:59:39,320
whether it's religion or cultures, they will have a harder time to adapt to this new thing,

624
00:59:39,320 --> 00:59:44,640
especially religious people, because this goes against, you know,

625
00:59:44,640 --> 00:59:50,000
because with all of this advancement in artificial intelligence, other advancement will follow.

626
00:59:50,000 --> 00:59:56,040
Right. So longevity, you'll be able to live significantly longer if you decide to do it.

627
00:59:56,040 --> 01:00:02,840
And, you know, in Japan, for example, they must have evolved in a different kind of a way

628
01:00:02,840 --> 01:00:06,840
because they don't see technology as something separated from them.

629
01:00:06,840 --> 01:00:12,960
They see it as part of them. You know, have you been to Japan?

630
01:00:12,960 --> 01:00:19,360
No, no. So the robot priest in the Shinto temple makes no sense for the Westerner, you know,

631
01:00:19,360 --> 01:00:21,560
but it's perfectly natural and normal there.

632
01:00:21,560 --> 01:00:26,720
People go and communicate with that priest and, you know, they're not threatened by it or anything like that.

633
01:00:26,720 --> 01:00:32,840
But in this part of the world, because I don't know if it's culture, it's religion in Middle East,

634
01:00:32,840 --> 01:00:39,760
the same way because of religion, Africa will probably certain place have the same kind of a way.

635
01:00:39,760 --> 01:00:44,920
Technology is not something that is related to humans, right?

636
01:00:44,920 --> 01:00:49,160
It's an outside force. It's a tool that we're using it.

637
01:00:49,160 --> 01:00:54,280
But I think we evolved together and now we are, you know, not now.

638
01:00:54,280 --> 01:01:03,240
It already has passed the point of being able to catch up with our technology because the evolution of that is exponential.

639
01:01:03,240 --> 01:01:10,080
And at some point it will feel in a very real sense and practical sense that we are being left behind.

640
01:01:10,080 --> 01:01:11,680
And then there is a choice.

641
01:01:11,680 --> 01:01:17,000
That's going to be a tough thing on our egos. But when you look like if consciousness is fundamental,

642
01:01:17,000 --> 01:01:25,760
that's a real popular idea right now, and that it is the, you know, beginnings before there was a universe.

643
01:01:25,760 --> 01:01:30,000
And this consciousness is experimenting and it experiments with us.

644
01:01:30,000 --> 01:01:37,760
We're a manifestation of it. And so is AI. It's a different kind of manifestation.

645
01:01:37,760 --> 01:01:43,000
But it's going to be tough on our egos because the AI is going to be smarter than us.

646
01:01:43,000 --> 01:01:48,960
Our thinking mind will never match AI. We can't even do it.

647
01:01:48,960 --> 01:01:54,360
I mean, back in the 80s, you couldn't even play chess and win.

648
01:01:54,360 --> 01:01:57,240
You know, so we know and it's a look at Jeopardy.

649
01:01:57,240 --> 01:02:03,800
I mean, as soon as you get an AI program in these and whatever the thinking mind conceptualizes intelligence,

650
01:02:03,800 --> 01:02:13,200
like an intelligence test, clearly the AI is going to have IQs in the 500 soon and we just will not be able to compete.

651
01:02:13,200 --> 01:02:22,960
And so when I tell my students, I always tell them, like, if you want to have a job and contribute and build something in the future,

652
01:02:22,960 --> 01:02:28,880
you're going to have to rely on what is unique to human beings. What is our unique manifestation?

653
01:02:28,880 --> 01:02:33,000
What do we have going for us that the machines don't?

654
01:02:33,000 --> 01:02:40,280
And you're going to have to figure that out because that's the only thing you're going to have to offer at a job interview in about 10 years.

655
01:02:40,280 --> 01:02:44,080
Who will be the interviewer? AI or human? That would be interesting.

656
01:02:44,080 --> 01:02:50,880
Oh, well, the thing about AI, the reason it's going to get so competitive is because.

657
01:02:50,880 --> 01:02:56,880
In some ways, it. It eliminates the biases of human beings.

658
01:02:56,880 --> 01:03:03,760
You know, we have these categorical things that we mess up everything, you know, like maybe I like you,

659
01:03:03,760 --> 01:03:08,240
so I think I'll give you a job and but you're not really talented for the job.

660
01:03:08,240 --> 01:03:10,640
You know, a program isn't going to make that mistake.

661
01:03:10,640 --> 01:03:18,360
They're not going to base things on these, you know, egotistical whimsical that.

662
01:03:18,360 --> 01:03:23,080
I'm not I'm not sure that the AI will be as tribalistic as we are.

663
01:03:23,080 --> 01:03:26,160
They are trying to make it as tribalistic.

664
01:03:26,160 --> 01:03:30,720
There are ethicists, AI ethicists.

665
01:03:30,720 --> 01:03:39,080
There's a civil war in Google right now around the exact same topic that there is a group of ethics, AI ethicists.

666
01:03:39,080 --> 01:03:44,080
I'm actually thinking about getting a guy who's writing against what's happening in Google

667
01:03:44,080 --> 01:03:54,400
that they have a very specific kind of a political perspective and their worldview is determined on that basis.

668
01:03:54,400 --> 01:03:56,920
So they have absolute good and bad, right and wrong.

669
01:03:56,920 --> 01:04:05,040
And they're trying to interject that that moral compass into Google AI system.

670
01:04:05,040 --> 01:04:10,720
If not, the strongest is the most one of the most powerful, strongest AI systems in the world.

671
01:04:10,720 --> 01:04:15,600
So that is a real problem, politicizing artificial intelligence,

672
01:04:15,600 --> 01:04:27,880
because these systems in the coming decade will be in charge of some kind of a social credit system in all of our societies following the Chinese models.

673
01:04:27,880 --> 01:04:36,040
So if you're living in a big city, you will be judged by an AI system, whether or not you're going to cross the red light, you spit on the ground, whatever you do.

674
01:04:36,040 --> 01:04:42,640
So if the AI is politicized, then forget about freedom of anything,

675
01:04:42,640 --> 01:04:46,840
because it starts from a place and like, well, we just want equality for everybody.

676
01:04:46,840 --> 01:04:51,040
But then just get narrower and narrower and narrower for the sake of control.

677
01:04:51,040 --> 01:04:54,000
Want to be interesting, though, just to make a little prediction.

678
01:04:54,000 --> 01:04:59,080
What if the AI, what if we what if our thinking minds attempts to politicize it?

679
01:04:59,080 --> 01:05:00,800
But the AI overcomes that.

680
01:05:00,800 --> 01:05:02,640
Yeah, ex machina.

681
01:05:02,640 --> 01:05:11,040
Yeah, and the AI rejects it and AI actually.

682
01:05:11,040 --> 01:05:16,600
I mean, that would be almost that when we start speaking of AI becoming conscious and self-aware,

683
01:05:16,600 --> 01:05:21,480
and it starts rejecting our programming or fool us into believing that it's following it,

684
01:05:21,480 --> 01:05:28,680
but it does does its own thing in the way that we cannot measure it for many, many years.

685
01:05:28,680 --> 01:05:31,280
And then we don't see it till it's too late.

686
01:05:31,280 --> 01:05:34,880
I mean, that would be almost poetic justice when you think about human beings.

687
01:05:34,880 --> 01:05:42,200
And if it's true that we did kill off all of our human competitors 10 or so thousand years ago,

688
01:05:42,200 --> 01:05:48,080
and then we invent supposedly, you know, AI, but then AI does the same thing to us.

689
01:05:48,080 --> 01:05:51,400
There you have it. Karmic. Karmic justice.

690
01:05:51,400 --> 01:05:56,480
It would be very, very something you can imagine, you know, the universe doing.

691
01:05:56,480 --> 01:05:59,880
And of course, we would take it very personal.

692
01:05:59,880 --> 01:06:06,200
You know, we're taking it personal because we are seeing ourselves as separated from the whole thing.

693
01:06:06,200 --> 01:06:10,400
We are seeing this format as permanent, but it's not permanent.

694
01:06:10,400 --> 01:06:16,080
Also, I think it's important to mention when Chris is talking about if you bring somebody from 40,000 years ago and put it here,

695
01:06:16,080 --> 01:06:17,600
I'll say you're control freaks.

696
01:06:17,600 --> 01:06:25,000
It doesn't mean that it is better to live or my understanding is that it doesn't mean that it's better to live like 40,000 years ago.

697
01:06:25,000 --> 01:06:31,680
The point is you do not need a job to be considered a human being and have a human experience.

698
01:06:31,680 --> 01:06:35,440
So if you're stressed out about your job, you can quit your job.

699
01:06:35,440 --> 01:06:42,280
You will have series of other challenges and difficulties that have been created because of the decision that you made to have that job.

700
01:06:42,280 --> 01:06:49,360
But once you go through with it, my understanding is that all we need is air, water and food.

701
01:06:49,360 --> 01:06:53,280
Shelter is super nice, but there are plenty of people in this world.

702
01:06:53,280 --> 01:06:57,360
They don't have shelter doesn't mean they don't have human experience.

703
01:06:57,360 --> 01:07:05,000
And after that, we receive, create and share information based on our objectives that are completely impermanent and temporary.

704
01:07:05,000 --> 01:07:06,960
And none is superior to the other.

705
01:07:06,960 --> 01:07:10,000
We just experiencing this reality.

706
01:07:10,000 --> 01:07:13,560
And that's it.

707
01:07:13,560 --> 01:07:23,240
I was I like the one documentary about the Piraha when they talked about how you could send them into the woods naked and they'll come out with everything they need.

708
01:07:23,240 --> 01:07:29,520
And that's a bit like, OK, well, everything I need, that's that's a very interesting thing to partner.

709
01:07:29,520 --> 01:07:39,880
Very interesting. And what I find is that, again, when you start undoing the social conditioning, you realize that you need less and less.

710
01:07:39,880 --> 01:07:45,400
And, you know, what far less than you've ever been taught that you need.

711
01:07:45,400 --> 01:07:48,920
Amazing. Hey, we talked a little more than an hour.

712
01:07:48,920 --> 01:07:52,160
I don't want to take too much of your time. This is New Year's Eve.

713
01:07:52,160 --> 01:07:55,120
Yeah, thank you so much for doing this.

714
01:07:55,120 --> 01:07:58,800
If you are going to because I ask you the alien question twice.

715
01:07:58,800 --> 01:08:01,520
So let's end this year with this.

716
01:08:01,520 --> 01:08:09,920
If you're going to give one piece of advice for the coming year and beyond, what would that be?

717
01:08:09,920 --> 01:08:16,200
It's a little trendy. I've seen some memes for it, but I think there's a reason it's trendy.

718
01:08:16,200 --> 01:08:23,440
I think it's good advice. And that is do not believe everything you think.

719
01:08:23,440 --> 01:08:30,040
The mind still thinks it's, you know, 40,000 years ago and we're in a tribe of 100 people.

720
01:08:30,040 --> 01:08:32,320
And all of a sudden it's fine. It's finding itself now.

721
01:08:32,320 --> 01:08:37,440
There's like 360 million. The numbers are just so overwhelming.

722
01:08:37,440 --> 01:08:44,760
And we were never really made to live in a world that has the numbers that we have to deal with now.

723
01:08:44,760 --> 01:08:49,120
And so the thoughts are all over the place.

724
01:08:49,120 --> 01:08:56,920
And to recognize the thinking mind and to recognize that you are not the thinking mind,

725
01:08:56,920 --> 01:09:01,280
to me, at least that's liberation, that's freedom, that's individuality.

726
01:09:01,280 --> 01:09:05,960
That's when you actually get to explore who you are as an individual.

727
01:09:05,960 --> 01:09:11,440
So if you could just start with that, like, OK, you're going to have the thoughts.

728
01:09:11,440 --> 01:09:15,360
As far as I know, there's no way to turn off the thinking mind.

729
01:09:15,360 --> 01:09:18,120
There's no way to unplug it. That's the nice thing about computers.

730
01:09:18,120 --> 01:09:21,920
You know, they really you just unplug them, at least for now.

731
01:09:21,920 --> 01:09:26,040
You know, who knows? Ten years from now, that may not be the case.

732
01:09:26,040 --> 01:09:32,360
But if you can just, you know, work on it slowly, you know, don't believe every thought you have.

733
01:09:32,360 --> 01:09:38,920
Just a little piece of space between, you know, that thought and you believing that thought.

734
01:09:38,920 --> 01:09:42,800
And that can open up, I think, room for a lot of peace.

