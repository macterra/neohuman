WEBVTT

00:00.000 --> 00:06.920
I would offer, actually the World Wide Web is our greatest achievement of the technology

00:06.920 --> 00:11.480
that makes self-expression possible and collaboration.

00:11.480 --> 00:18.640
I think it's instigated a renaissance across the world, it's amazing.

00:18.640 --> 00:23.960
And in a sense, it's only getting started, so ask me 10 years from now and I'll say the

00:23.960 --> 00:35.240
successor for the web, whatever that is.

00:35.240 --> 00:41.840
Hello, this is Agah Bahari and I am here with the first episode of Neo Human.

00:41.840 --> 00:45.920
I will be talking to interesting people about interesting subjects.

00:45.920 --> 00:51.320
We don't have any specific subject or title or style for the podcast, whatever happens,

00:51.320 --> 00:53.360
it's just going to be interesting.

00:53.360 --> 00:56.600
That's the most important thing.

00:56.600 --> 01:03.840
For the first episode, right here with me, we have David McFadden, who is a lead engineer

01:03.840 --> 01:09.160
at Synaptic, which is a Toronto-based technology company.

01:09.160 --> 01:10.160
Synaptic.

01:10.160 --> 01:11.160
Synaptic.

01:11.160 --> 01:12.160
Horrible.

01:12.160 --> 01:15.720
I asked you the name before the show too.

01:15.720 --> 01:20.440
So what do you do at Synaptic and what does Synaptic do?

01:20.440 --> 01:28.200
Yeah, Synaptic is a startup that's about almost four years old now and we build technology

01:28.200 --> 01:32.880
to mainly assist neurosurgeons in difficult brain surgery.

01:32.880 --> 01:40.200
So we have a line of products to look at the scans from the brain and render them in 3D

01:40.200 --> 01:44.680
and help the surgeon plan the surgery in advance.

01:44.680 --> 01:51.960
And then in the OR, our software acts sort of like a GPS for surgeons, it's like Google

01:51.960 --> 01:58.320
Maps to show them where they are and help her along in their route.

01:58.320 --> 02:02.880
And if they get off course, they can get back on with the 3D map of the brain.

02:02.880 --> 02:08.640
And this is usable with robotics and with human doctors, both can use it.

02:08.640 --> 02:12.880
Because I remember you were saying that you have a robotic arm at the work.

02:12.880 --> 02:13.880
That's right.

02:13.880 --> 02:17.320
I'm the lead software engineer on our robotic arm project.

02:17.320 --> 02:22.920
It's a device positioning system that's designed to assist the surgeon.

02:22.920 --> 02:29.000
So it's holding the optics for the surgery, which is the lighting and the camera and a

02:29.000 --> 02:33.000
microscope and it's recording video.

02:33.000 --> 02:38.980
And the robotic arm automatically positions the optics of the cameras into ideal positions

02:38.980 --> 02:39.980
for the surgeon.

02:39.980 --> 02:44.640
They just have to make a gesture that they want it in some particular place and press

02:44.640 --> 02:50.560
a foot pedal and the robotic arm will move the optics into the correct position.

02:50.560 --> 02:51.760
That's amazing.

02:51.760 --> 03:00.880
How long did it take from, if you know, from the concept idea of such a thing to being

03:00.880 --> 03:06.000
at this level that you guys are, which I believe you're ready to be launched?

03:06.000 --> 03:07.400
It launched last February.

03:07.400 --> 03:08.400
It launched last February.

03:08.400 --> 03:14.040
Yeah, from concept to when it was FDA approved and actually used in our real surgery was

03:14.040 --> 03:15.360
less than two years.

03:15.360 --> 03:16.360
Oh, wow.

03:16.360 --> 03:17.360
That's amazing.

03:17.360 --> 03:20.080
And you still consider the whole company as a startup.

03:20.080 --> 03:22.120
Like you're not a corporation per se.

03:22.120 --> 03:27.960
We're in transition now since we got FDA approval last February and we're deployed now.

03:27.960 --> 03:31.920
We're out in the field at, I think, eight or nine different installations now, different

03:31.920 --> 03:35.440
hospitals around the United States.

03:35.440 --> 03:41.160
And it's to date in the last eight months or so since it's heard, it's been used in

03:41.160 --> 03:43.920
500 real surgeries.

03:43.920 --> 03:45.320
That's amazing.

03:45.320 --> 03:52.520
What do you think is, I'm an enthusiast entrepreneur, I have to say.

03:52.520 --> 03:58.120
Like I'm very interested in creative ideas and then implementing those ideas.

03:58.120 --> 04:03.080
And with computers and coding, it's never really been easier, I think, to make an idea

04:03.080 --> 04:07.160
from ground up with a very limited number of people.

04:07.160 --> 04:10.160
That's very true.

04:10.160 --> 04:11.160
Yeah.

04:11.160 --> 04:18.000
What do you think the effect of such technologies in our, because the company that you're explaining

04:18.000 --> 04:23.560
is a very specific company to doing very specific thing, how do you think those technologies

04:23.560 --> 04:29.760
will translate into a popular or mainstream consumer to be able to take advantage of that?

04:29.760 --> 04:36.680
For example, let's say this is just off the top of my head.

04:36.680 --> 04:41.400
Would there be a possibility of mixing this technology or would you see the possibility

04:41.400 --> 04:52.800
of mixing this technology with a very straightforward variable like the EEG variables that exist

04:52.800 --> 04:55.240
right now that assist you to meditate?

04:55.240 --> 05:01.200
I think they're also a company from Toronto, eMUSE or MUSE, I think.

05:01.200 --> 05:02.200
Right.

05:02.200 --> 05:08.640
I think we actually used MUSE at a hackathon that we did internally at Synaptiv a couple

05:08.640 --> 05:13.720
months ago and using the MUSE will detect brainwaves of some sort and encode them in

05:13.720 --> 05:16.000
a way that a software can take advantage of.

05:16.000 --> 05:21.440
So one of the demos was to move the robotic arm just by thinking about it.

05:21.440 --> 05:22.440
Wow.

05:22.440 --> 05:23.800
It was amazing.

05:23.800 --> 05:24.800
I bet.

05:24.800 --> 05:25.800
Yeah.

05:25.800 --> 05:30.280
So we're definitely looking at new consumer electronics to bring that into the OR to help

05:30.280 --> 05:36.840
the surgeons, stuff like the Oculus Rift or the Microsoft HoloLens to give the surgeon

05:36.840 --> 05:43.120
a heads up display and show them the 3D rendering of the brain as if he was living in that space.

05:43.120 --> 05:44.120
That's amazing.

05:44.120 --> 05:51.320
You would imagine this also, beside the surgery itself for training, this is a very great

05:51.320 --> 05:58.720
achievement the way that you don't necessarily have to experiment on even like animals for

05:58.720 --> 06:01.560
a lot of stuff that are going on inside there.

06:01.560 --> 06:06.520
When we want to test their brain pulses or anything, instead of doing it on the animal,

06:06.520 --> 06:10.800
it will be able to done in a virtual space in the virtual brain.

06:10.800 --> 06:11.800
Yeah, definitely.

06:11.800 --> 06:16.520
You can see this in the Microsoft promotional material for the HoloLens and the early demos

06:16.520 --> 06:22.040
are in the classroom where a teacher is showing the kid's solar system or whatever and the

06:22.040 --> 06:27.000
kids have whole lenses and the solar system is right there in the classroom with them

06:27.000 --> 06:29.280
and animated and interactive.

06:29.280 --> 06:30.280
Or games.

06:30.280 --> 06:31.280
Yeah.

06:31.280 --> 06:35.600
Yeah, it's just unbelievable.

06:35.600 --> 06:40.640
Another use that this kind of technology has had in past couple of years has been a military

06:40.640 --> 06:50.680
and they've done it for good and for evil per se even though it might be necessary evil.

06:50.680 --> 06:56.360
But the technology has been used to treat PTSD very seriously and they've had very successful

06:56.360 --> 07:00.400
results from it.

07:00.400 --> 07:07.920
Where do you see the future of that technology with that assistance are going and how does

07:07.920 --> 07:15.800
technology as a whole will play a bigger and bigger role in the army and the military industry

07:15.800 --> 07:18.380
complex?

07:18.380 --> 07:26.560
We see with the rise of drones, it has been, I dare say, almost a decade now.

07:26.560 --> 07:29.260
Where do you see this whole thing is going with?

07:29.260 --> 07:35.860
Because we are not going to stop fighting, the war is going to continue and I think the

07:35.860 --> 07:42.040
difference would be that we will have less casualty because technology is covering most

07:42.040 --> 07:45.200
of the ground that people had to do before.

07:45.200 --> 07:49.960
Where do you see this whole thing going with the usage of technology and its dependence

07:49.960 --> 07:51.680
to advance technology?

07:51.680 --> 07:58.800
Well, in the military particularly, I think the trend is to push more and more computational

07:58.800 --> 08:03.040
power down to the ranks and replacing humans with automation.

08:03.040 --> 08:10.000
Obviously, it's much safer for their side, but they're going to run into a pretty significant

08:10.000 --> 08:16.760
ethical decision probably really soon about giving autonomous drones the power to kill

08:16.760 --> 08:20.060
or the right to kill.

08:20.060 --> 08:23.900
Would you think that they will announce that they're about to do that or they'll just do

08:23.900 --> 08:28.320
it until they get caught?

08:28.320 --> 08:34.840
Looking from recent events, I think probably the latter, we'll find out about it on WikiLeaks.

08:34.840 --> 08:39.000
Yeah, I think so.

08:39.000 --> 08:40.280
It's been amazing.

08:40.280 --> 08:50.160
I think it's a great achievement of technology that you can go in a small room in Arizona

08:50.160 --> 09:00.180
and control a drone in Afghanistan and drop a bomb because of course, it's not resulting

09:00.180 --> 09:01.780
always in good.

09:01.780 --> 09:05.200
Sometimes it does and there are some people that need to be killed and that's the only

09:05.200 --> 09:13.320
way and I much rather a drone will kill them than a soldier on our side basically being

09:13.320 --> 09:18.280
put in risk to deal with a Taliban leader or whoever.

09:18.280 --> 09:22.760
But at the same time, you see how people are treating, for example, even driverless cars.

09:22.760 --> 09:26.000
There are already a lot of people freaked out about it.

09:26.000 --> 09:30.240
People are freaked out about drones, use of mainstream drones.

09:30.240 --> 09:38.840
You see these conspiracy theorists that have YouTube channels and iTunes podcasts and all

09:38.840 --> 09:39.840
of that.

09:39.840 --> 09:44.800
They're talking about shoot the drones down with your shotguns and all the people who

09:44.800 --> 09:51.200
are very concerned about these kind of thing conspiracies.

09:51.200 --> 10:00.240
How do you think the challenge that technologists and technology enthusiasts have who are between

10:00.240 --> 10:07.240
two sides, one being the politics and politicians and the other being people who are basically

10:07.240 --> 10:09.720
always scared of a new thing.

10:09.720 --> 10:13.760
That new thing has to be proven many, many times and more and more people using it for

10:13.760 --> 10:16.520
masses to accept the usage of that.

10:16.520 --> 10:22.960
How do you think it will result and will it slow the advancement down or slow it down

10:22.960 --> 10:25.320
or speed it up?

10:25.320 --> 10:32.640
I think the way it will actually play out is we'll see some significant pushback initially

10:32.640 --> 10:40.560
because it is a big change, but it's also fairly inevitable that this is going to happen.

10:40.560 --> 10:45.320
It reminds me of David Brin's Transparent Society where surveillance becomes pervasive

10:45.320 --> 10:50.960
and that could have actually net positive effects on society as we've already seen

10:50.960 --> 10:58.000
with the way the police in the US have reacted to their cameras.

10:58.000 --> 11:03.000
All of a sudden, police are getting caught all the time and I think it's changing the

11:03.000 --> 11:04.760
way they behave.

11:04.760 --> 11:08.720
They're becoming more ethical in their professional behavior now.

11:08.720 --> 11:16.360
Yeah, it's like a double-edged sword because it's become more transparent for the authorities

11:16.360 --> 11:22.720
to control that, but at the same time, general population also are seeing it more.

11:22.720 --> 11:27.240
They do believe that it's happening more.

11:27.240 --> 11:31.980
Once it reaches some critical threshold, I think it will just become accepted like cell

11:31.980 --> 11:33.280
phones have become accepted.

11:33.280 --> 11:37.320
There was pushback initially about those two.

11:37.320 --> 11:42.760
People were just walking down the street talking to themselves that looked weird, but now it's

11:42.760 --> 11:45.320
so calm and nobody looks twice.

11:45.320 --> 11:47.440
It's just accepted.

11:47.440 --> 11:52.800
Also virtual reality, I think, will have a lot to do with that because people would have

11:52.800 --> 11:57.840
the possibility to be whoever they want physically.

11:57.840 --> 12:05.360
Like on the game Second Life, that you can create your own avatar and live in that.

12:05.360 --> 12:08.200
People get married, people buy stuff.

12:08.200 --> 12:11.960
Sweden, I heard, has an embassy in that virtual world.

12:11.960 --> 12:15.720
Nike has a store.

12:15.720 --> 12:21.360
So I think it will begin with this is weird that people are doing because people will

12:21.360 --> 12:26.240
do that and film it and put it on YouTube to create a community and find like-minded

12:26.240 --> 12:31.600
people and it's amazing that we can do that all around the world now.

12:31.600 --> 12:37.520
But at the same time, you freak certain people out, the people who watch Fox News and all

12:37.520 --> 12:43.940
those propaganda, basically.

12:43.940 --> 12:50.440
Those people are not that much of a concern, I agree, but we hear also from someone like

12:50.440 --> 12:59.160
Elon Musk and Bill Gates and Steve Wozniak who are, I don't want to say scaring people.

12:59.160 --> 13:00.680
They're smarter than that.

13:00.680 --> 13:07.920
They're making a very valid case of dangers of artificial intelligence.

13:07.920 --> 13:16.360
But at the same time, I think these kind of warnings, even though necessary, it will lower

13:16.360 --> 13:23.720
the budget that research facilities can have to actually work on it because if public opinion

13:23.720 --> 13:27.000
is not behind an idea, it would be very hard to finance.

13:27.000 --> 13:31.720
It's like, you know, I have a very good idea for a startup, but I probably not going to

13:31.720 --> 13:33.000
have more than 10 users.

13:33.000 --> 13:34.760
Nobody's going to fund me.

13:34.760 --> 13:35.760
Right.

13:35.760 --> 13:40.640
Yeah, we saw the same thing happen with prediction markets a few years ago.

13:40.640 --> 13:45.680
Robin Hanson was ready to roll out a prediction market that would help with public policy.

13:45.680 --> 13:50.880
And one of the questions that they were interested in betting on was the chance of a terrorist

13:50.880 --> 13:52.360
event.

13:52.360 --> 13:56.960
But some senators got a hold of this information and ran a scare campaign saying it would be

13:56.960 --> 14:03.240
terrible to bet on these sorts of things because one side has to bet on it happening, which

14:03.240 --> 14:06.840
could be seen as promoting it in some sense.

14:06.840 --> 14:12.520
It was a silly reason anyways, but the point is that it turned public opinion and the project

14:12.520 --> 14:14.640
was abandoned.

14:14.640 --> 14:20.320
Do you blame that senator or you blame the people who voted that senator into Senate?

14:20.320 --> 14:21.880
I think they're all to blame.

14:21.880 --> 14:22.880
Yeah.

14:22.880 --> 14:30.480
One senator is one senator, has to be thousands of people at least behind him.

14:30.480 --> 14:35.240
And I think that's one of the greatest revelations in the United States, Donald Trump running

14:35.240 --> 14:38.880
for presidency because you see everybody who's behind him.

14:38.880 --> 14:41.520
It's a very interesting phenomenon.

14:41.520 --> 14:42.520
Yeah.

14:42.520 --> 14:45.520
It's only only one person predicted that.

14:45.520 --> 14:46.520
Who did?

14:46.520 --> 14:47.520
Who was that?

14:47.520 --> 14:48.520
God Adams, the creator of Dilbert.

14:48.520 --> 14:49.520
Really?

14:49.520 --> 14:50.520
Seriously.

14:50.520 --> 14:52.680
He said Donald Trump will run for president.

14:52.680 --> 14:59.680
He said that Donald Trump will continue to lead in the Republican polls long before anyone

14:59.680 --> 15:02.560
else even considered that possibility.

15:02.560 --> 15:07.120
Everyone else thought he was a joke and that he was popular initially because it was funny,

15:07.120 --> 15:08.920
but that's actually not the case.

15:08.920 --> 15:19.200
Now, what's very interesting is that they were reading the polls, not polls really,

15:19.200 --> 15:25.880
but how much time media is covering Donald Trump in comparison to the other people.

15:25.880 --> 15:31.040
It's twice as much as Hillary Clinton, the time that Trump is getting, and I think 13

15:31.040 --> 15:33.040
times more than Bernie Sanders.

15:33.040 --> 15:38.000
What Trump understands is how to manipulate media to his advantage.

15:38.000 --> 15:39.000
Absolutely.

15:39.000 --> 15:43.280
And he knows that whoever has name recognition is going to be highest in the polls.

15:43.280 --> 15:48.920
It's such a great transition though, because with reality shows become more popular in

15:48.920 --> 15:49.920
the United States.

15:49.920 --> 15:55.680
And the celebrity culture, I had this conversation with somebody else that I was like, celebrities

15:55.680 --> 16:01.080
became the idols, the greatest thing that you can be in the 21st century.

16:01.080 --> 16:05.280
And she was saying that, no, people were celebrities before that.

16:05.280 --> 16:11.680
But I was like, no, not like this, that you use, for example, Bono from YouTube for any

16:11.680 --> 16:16.160
humanitarian campaign that you have to get attention from people.

16:16.160 --> 16:19.800
That's not the cause that is getting the attention of the people.

16:19.800 --> 16:21.620
It's a celebrity.

16:21.620 --> 16:27.880
And then by the rise of that, and now you see a person who's a creator of a reality

16:27.880 --> 16:35.360
show and is an apprentice, Miss Universe, all those things.

16:35.360 --> 16:40.160
Nobody knows better than him how to manipulate the media, as he said.

16:40.160 --> 16:45.800
And I mean, it's appealing to most people, I think because he's not getting any money

16:45.800 --> 16:50.480
from big corporations and CPACs and nobody.

16:50.480 --> 16:51.480
Right.

16:51.480 --> 16:53.320
He's posing as the outsider.

16:53.320 --> 16:55.480
He is above corruption.

16:55.480 --> 17:01.560
And the thing that I think people most find appealing is he speaks his mind.

17:01.560 --> 17:05.560
He doesn't care what people think about what he says.

17:05.560 --> 17:09.720
I mean, he goes to extremes to make that point.

17:09.720 --> 17:11.560
Do you think he believe a lot of?

17:11.560 --> 17:14.720
No, I think he does that in order to get media attention.

17:14.720 --> 17:16.440
I think so, too.

17:16.440 --> 17:17.440
I think so, too.

17:17.440 --> 17:26.280
I'm at this point, as we had this conversation before, I'm a Bernie Sanders supporter.

17:26.280 --> 17:33.680
And I think it would be very good for America to have a change in that direction.

17:33.680 --> 17:35.160
It's a very extreme change.

17:35.160 --> 17:43.360
We were a capitalist, but now we are being run by a Jew, liberal, socialist.

17:43.360 --> 17:44.640
It would be a very good change.

17:44.640 --> 17:45.640
In my opinion.

17:45.640 --> 17:51.320
But if he drops out, I'm supporting Donald Trump because I think he does not believe

17:51.320 --> 17:54.700
a lot of stuff that he says.

17:54.700 --> 17:59.920
You cannot possibly be that blind and make it that far.

17:59.920 --> 18:07.000
I think in a city like New York City and Hillary Clinton, I have no interest in her.

18:07.000 --> 18:13.200
No, I think Hillary would just be a continuation of Obama, which turned out to be just a continuation

18:13.200 --> 18:19.120
of W. Bush, surprisingly, against all odds, against everyone's wishes.

18:19.120 --> 18:20.520
Is it really a surprise?

18:20.520 --> 18:25.120
Because one man in a democracy doesn't supposed to be able to change anything.

18:25.120 --> 18:26.120
You have to go.

18:26.120 --> 18:34.920
So it's a democratic system that is backstabbing itself, in my opinion, because the party's

18:34.920 --> 18:43.880
rhetorics against each other, and one person who's being elected as somebody who you can't

18:43.880 --> 18:53.600
use as a punching box, you know, punching bag, I don't think he can do much.

18:53.600 --> 18:58.640
Well perhaps not, but you'd expect him to push in the directions of his promises when

18:58.640 --> 19:01.200
he's actually gone in the other direction.

19:01.200 --> 19:05.760
I think the good things that he did, I'm not really sure about the healthcare system, because

19:05.760 --> 19:09.440
apparently it's one of those things you have to live in the US to experience, that I heard

19:09.440 --> 19:14.480
good things and bad things about Obamacare from different people who I respect their

19:14.480 --> 19:16.200
opinions.

19:16.200 --> 19:24.200
I think when he made it legal for same-sex marriages to become federal, I think that

19:24.200 --> 19:25.440
was a good thing.

19:25.440 --> 19:31.160
And I still think he will do more in this last year.

19:31.160 --> 19:32.640
I'm not an Obama fan at all.

19:32.640 --> 19:39.320
In the second term, in the first term when he was running, I was totally supporting John

19:39.320 --> 19:41.080
McCain.

19:41.080 --> 19:46.320
And then John McCain elected Sarah Palin as vice president, like, why would you do that?

19:46.320 --> 19:48.000
Like it's such a weird thing.

19:48.000 --> 19:49.000
That was bizarre.

19:49.000 --> 19:53.880
Yeah, they made a really cool movie about it, Woody Harrelson, isn't it?

19:53.880 --> 19:57.200
I can't remember the name.

19:57.200 --> 20:04.000
But it's about that era of Sarah Palin, it's based on a book with Sarah Palin's advisor

20:04.000 --> 20:13.320
after the campaign was over, he wrote, and it was a disaster with her.

20:13.320 --> 20:18.280
But again, she's one person, there are thousands of people who are supporting her.

20:18.280 --> 20:24.680
She's still, apparently, making the most money in the conservative charities and conservative

20:24.680 --> 20:25.680
fundraisers.

20:25.680 --> 20:29.360
I mean, who knows, it's really strange.

20:29.360 --> 20:38.880
You think the new government of Canada will have any effect in the social life of Americans

20:38.880 --> 20:41.800
in a way that this is a liberal government?

20:41.800 --> 20:50.080
We pulled out of Syria in the first week that, you know, he became a prime minister.

20:50.080 --> 20:54.640
And then we started getting refugees, even though the numbers are not comparable with

20:54.640 --> 20:56.560
what Europe is doing.

20:56.560 --> 20:59.320
And that we can talk about.

20:59.320 --> 21:04.160
I fully expect the Trudeau's government to be kind of an example for Americans to show

21:04.160 --> 21:05.160
what's possible.

21:05.160 --> 21:06.160
Yeah.

21:06.160 --> 21:12.600
Other than the ridiculous choices they have now, it's, I mean, it's sad.

21:12.600 --> 21:17.240
It's I don't know, me and my girlfriend, we have this conversation, she's a big supporter

21:17.240 --> 21:21.320
of Hillary Clinton, because she also has worked for Hillary Clinton.

21:21.320 --> 21:25.180
And she was very impressed with her as a boss, she's a smart person.

21:25.180 --> 21:32.200
She brought technology in a very involved way into State Department.

21:32.200 --> 21:34.780
And she's a defender of women rights.

21:34.780 --> 21:40.240
But then you watch a lot of different stuff that's been put together, how she has flip

21:40.240 --> 21:43.080
flopped from time to time.

21:43.080 --> 21:48.360
And then you wonder, you know, is this really the best that United States of America can

21:48.360 --> 21:52.160
offer as a candidate for presidency?

21:52.160 --> 21:53.160
Like there's nobody else.

21:53.160 --> 21:56.640
My favorite candidate would be Eric Schmidt of Google.

21:56.640 --> 21:57.640
Okay.

21:57.640 --> 22:07.440
Because they are obviously smarter than anybody who's running, you know, for president, politicians.

22:07.440 --> 22:14.240
But unfortunately, we are kind of taken hostages by lawyers, it seems like Neil deGrasse Tyson

22:14.240 --> 22:19.640
was also saying that you look at the Congress and Senate, the lawyer, lawyer, lawyer, businessman,

22:19.640 --> 22:23.640
lawyer, lawyer, businessman, where are the scientists, where are the engineers?

22:23.640 --> 22:24.640
In Europe.

22:24.640 --> 22:31.280
I mean, the Europeans don't have the same problem with their politicians, they actually

22:31.280 --> 22:34.480
have academics and politics.

22:34.480 --> 22:35.480
Which they should.

22:35.480 --> 22:36.480
They should.

22:36.480 --> 22:37.480
You'd expect.

22:37.480 --> 22:38.480
Yeah.

22:38.480 --> 22:45.720
But no, it's, it's, I mean, a lot of good news is coming from the West in the sense

22:45.720 --> 22:52.560
that countries with innovation, you know, the first world countries, but at the same

22:52.560 --> 22:59.840
time, you see a lot of nonsense is also coming out of them.

22:59.840 --> 23:06.840
Look at Europe, the problem that they have now with the refugee crisis and what happened

23:06.840 --> 23:12.440
in Germany, which I'm sure you know about in the New Year's Eve, it just kind of makes

23:12.440 --> 23:13.440
it worse.

23:13.440 --> 23:18.800
And already, I think people are completely ignoring them.

23:18.800 --> 23:25.440
Under the radical right, who are, they're rising very powerful in decades.

23:25.440 --> 23:34.400
You can say in Germany, in Greece, in France, in Finland, in Sweden, you see people who

23:34.400 --> 23:40.120
were national socialists and they couldn't even breathe really in a political spectrum

23:40.120 --> 23:41.120
in those countries.

23:41.120 --> 23:47.640
There, they have a lot of supporters now and the extreme right group in Germany, Pegida,

23:47.640 --> 23:57.120
they had a, they had a rally here in Ottawa and there are videos on YouTube that day around

23:57.120 --> 24:02.000
the streets and there are also people who are countering them who are anti-racism and

24:02.000 --> 24:03.000
all of that.

24:03.000 --> 24:09.400
Where do you, where do you see this whole social conflict is going?

24:09.400 --> 24:16.120
From what I understand, the attacks in Cologne, New Year's Eve were actually suppressed, news

24:16.120 --> 24:20.520
of the attacks was suppressed by the government because they were afraid it would fuel kind

24:20.520 --> 24:23.680
of anti-immigration sentiment on the right.

24:23.680 --> 24:24.680
And then the mayor.

24:24.680 --> 24:29.280
But as soon as the news came out, it made it much worse because now the socialist governments

24:29.280 --> 24:31.480
are protecting the bad actors.

24:31.480 --> 24:32.480
That's right.

24:32.480 --> 24:34.880
And that's not the side you want to be on.

24:34.880 --> 24:35.880
No.

24:35.880 --> 24:40.880
And the mayor of Cologne, the mayor basically blamed the women.

24:40.880 --> 24:41.880
Right.

24:41.880 --> 24:42.880
Yeah.

24:42.880 --> 24:46.840
They kept the man at the arm length only, what are you talking about?

24:46.840 --> 24:49.520
Like, do you flip this easily?

24:49.520 --> 24:51.280
Like what did it take?

24:51.280 --> 24:59.920
And my understanding is that they're getting 1 million, 1 million plus refugees into Germany.

24:59.920 --> 25:03.320
This is not going to go away, this problem, because then they're going to push for them

25:03.320 --> 25:07.640
to become citizen faster so they can vote for that party.

25:07.640 --> 25:08.640
That's my thinking.

25:08.640 --> 25:13.040
They have the same thinking about abortion and people who are against it, that they don't

25:13.040 --> 25:16.680
care about that baby, they just care about one more Christian and one more Muslim or

25:16.680 --> 25:18.360
one more whatever.

25:18.360 --> 25:20.840
It's a number.

25:20.840 --> 25:27.960
And the fact that they're committing suicide, I think, in Europe for the sake of their own

25:27.960 --> 25:30.880
political game and agenda.

25:30.880 --> 25:35.480
Yeah, it looks ironic from the outside observer.

25:35.480 --> 25:37.400
Yeah, for sure.

25:37.400 --> 25:46.880
And as you're saying, Europeans, they master a lot of things much faster than Americans.

25:46.880 --> 25:53.200
They already, as you said, have academics and scientists and their political system

25:53.200 --> 25:59.480
are completely involved, but at the same time, you see the openness in the European way and

25:59.480 --> 26:05.120
multiculturalism in the European way that they promoted, for example, in England is

26:05.120 --> 26:07.600
causing a lot of problem right now.

26:07.600 --> 26:17.640
See all those Muslim British or British Muslims who joined the terrorist group ISIL in the

26:17.640 --> 26:18.800
Middle East.

26:18.800 --> 26:20.520
A lot of them are British.

26:20.520 --> 26:26.840
The guy who was born and raised in Britain, yeah, like they went to school.

26:26.840 --> 26:31.280
Sometimes in BBC, they're talking to people who knew them when they were a kid.

26:31.280 --> 26:38.800
The guy, Jihadi John, who who just got assassinated like two weeks ago, he was replaced by another

26:38.800 --> 26:40.280
British guy.

26:40.280 --> 26:44.400
And they right away find out who he was.

26:44.400 --> 26:54.320
And he was one of the people who are very closely related to excuse me, to the Islamic

26:54.320 --> 26:55.320
extremists.

26:55.320 --> 27:01.560
Anjum Chowdhury, I don't know if you know him, is like a preacher for extreme Islam in London

27:01.560 --> 27:07.760
and completely protected by the government, is getting paid by the government.

27:07.760 --> 27:15.120
But that guy who I had seen before in the documentaries about them, now he joined ISIL

27:15.120 --> 27:16.840
and he became a new Jihadi John.

27:16.840 --> 27:21.560
He just released the video is like very surreal.

27:21.560 --> 27:26.920
I think it's really interesting to see the recent backlash against these progressive

27:26.920 --> 27:30.000
values, the ones that are protecting the terrorists.

27:30.000 --> 27:33.560
In fact, there's a new term for them, the regressive left.

27:33.560 --> 27:34.560
That's right.

27:34.560 --> 27:39.120
They're the ones that are attacking Sam Harris and his colleagues for actually addressing

27:39.120 --> 27:40.120
the problem.

27:40.120 --> 27:47.680
So Glenn Greenwald and Ben Affleck, of course, and Bill Marshall, calling Sam a racist for

27:47.680 --> 27:50.720
saying that this is actually an issue.

27:50.720 --> 28:00.880
Yeah, I hope that we come to rationality and smart thinking in a way that we don't really

28:00.880 --> 28:05.360
have to get our facts from Ben Affleck, for example.

28:05.360 --> 28:11.240
Because the other side of his story, who at that occasion was Sam Harris, he's more than

28:11.240 --> 28:14.400
qualified to talk about any of those things.

28:14.400 --> 28:22.640
He has studied it, he's a philosopher and a neuroscientist, and he's been writing and

28:22.640 --> 28:28.120
talking about these issues for a while, for a long time.

28:28.120 --> 28:30.560
Since he published The End of Faith.

28:30.560 --> 28:31.560
Absolutely.

28:31.560 --> 28:36.840
And I think 9-11 was a horrible thing, but in a way, a lot of good came out of it in

28:36.840 --> 28:45.200
a sense that people like Sam Harris, people like Richard Dawkins, Christopher Hitchens,

28:45.200 --> 28:51.280
Douglas Morey, these people started targeting what the problem really, they think, is.

28:51.280 --> 28:54.040
And I agree with them completely.

28:54.040 --> 29:00.080
Do you think there would have been no God Delusion published if not for 9-11, or End

29:00.080 --> 29:06.360
of Faith, or Dennett's breaking the spell, or you think those were all a result of 9-11?

29:06.360 --> 29:07.880
I think so.

29:07.880 --> 29:08.880
I think so.

29:08.880 --> 29:09.880
Possibly, yes.

29:09.880 --> 29:17.160
Earlier in the podcast, you said something that triggered this odd idea.

29:17.160 --> 29:22.000
We were talking about elections and Trump, and in the context of Trump, you immediately

29:22.000 --> 29:25.040
brought up reality shows.

29:25.040 --> 29:33.920
And it just made me wonder, what if the elections are a reality show, and have been since, say,

29:33.920 --> 29:41.000
JFK debated Nixon in 1960 on TV, that was the first televised debate, what if the election

29:41.000 --> 29:45.080
has been a reality show ever since?

29:45.080 --> 29:46.080
What if?

29:46.080 --> 29:52.720
And the winner gets to rule the free world for four years.

29:52.720 --> 29:53.720
Yeah.

29:53.720 --> 29:56.920
It could be, I guess.

29:56.920 --> 29:59.400
I think everything is possible.

29:59.400 --> 30:04.200
But the question would be, who is producing the reality show?

30:04.200 --> 30:08.440
Who is okaying it?

30:08.440 --> 30:12.360
Maybe it's the media.

30:12.360 --> 30:13.800
Let's see.

30:13.800 --> 30:14.800
Let's follow the money.

30:14.800 --> 30:16.800
There's a lot of spending in elections.

30:16.800 --> 30:22.360
Where does that money go?

30:22.360 --> 30:27.320
I would imagine mostly goes to media.

30:27.320 --> 30:32.360
Some lobbyists, maybe, to shift the position.

30:32.360 --> 30:33.800
Elections are all about advertising.

30:33.800 --> 30:36.800
That's right.

30:36.800 --> 30:37.800
So advertisers.

30:37.800 --> 30:38.800
Yep.

30:38.800 --> 30:43.360
They're running the federal election reality show.

30:43.360 --> 30:46.600
Yeah, that's awesome.

30:46.600 --> 30:54.840
Well, you're right by saying that let's follow the money and see where it leads, because

30:54.840 --> 30:56.680
everything is basically money.

30:56.680 --> 31:03.400
Well, that's been Bernie Sanders' main complaint, this election cycle, isn't it, that the big

31:03.400 --> 31:05.560
business owns the politicians?

31:05.560 --> 31:08.000
I think that's absolutely true.

31:08.000 --> 31:09.920
The politicians are absolutely corrupt.

31:09.920 --> 31:13.400
It's special interests that control legislation.

31:13.400 --> 31:15.280
That's been proven statistically.

31:15.280 --> 31:16.280
Yes.

31:16.280 --> 31:20.720
That makes a lot of sense.

31:20.720 --> 31:30.800
So he offers a solution to add even more legislation to prevent this sort of thing, but that's

31:30.800 --> 31:31.800
might make it worse.

31:31.800 --> 31:37.440
That just adds more regulations to be subject to regulatory capture.

31:37.440 --> 31:40.000
It's just a bigger government.

31:40.000 --> 31:44.720
The more power the government has, the more value there is in controlling it.

31:44.720 --> 31:45.720
Right.

31:45.720 --> 31:51.040
That's absolutely true.

31:51.040 --> 31:54.440
Jeremy, what's his family name?

31:54.440 --> 32:02.560
He wrote a book, Future Money, and our friend Nicola interviewed him too, which he's talking

32:02.560 --> 32:03.560
about.

32:03.560 --> 32:04.560
Rifkin?

32:04.560 --> 32:05.560
Rifkin.

32:05.560 --> 32:06.560
Yes.

32:06.560 --> 32:07.560
Jeremy Rifkin.

32:07.560 --> 32:08.560
Thanks.

32:08.560 --> 32:11.800
A zero margin society.

32:11.800 --> 32:24.280
How do you think that kind of a society will affect this money talks in a way that, let's

32:24.280 --> 32:31.760
say, more and more human resources being replaced by machines.

32:31.760 --> 32:33.600
So you don't have to pay them salary.

32:33.600 --> 32:36.000
You don't have to pay for their...

32:36.000 --> 32:37.000
You don't have to pay...

32:37.000 --> 32:40.980
Is this the argument that robots are going to put everyone out of work?

32:40.980 --> 32:46.520
That money will have no value, basically the end of capitalism.

32:46.520 --> 32:48.080
That's the idea.

32:48.080 --> 32:51.080
There will be no money in this way.

32:51.080 --> 32:56.100
But is there still value in this society?

32:56.100 --> 32:58.120
Value is a concept?

32:58.120 --> 33:00.960
Will people value one thing over another?

33:00.960 --> 33:03.200
Will they value living in one place over another?

33:03.200 --> 33:08.340
Will they value seeing somebody talk or seeing some show more than another?

33:08.340 --> 33:14.520
You know what they were saying that in the past 20 years, apparently, a trend has begun

33:14.520 --> 33:24.400
that a newer generation, younger generation, they're not buying houses anymore, they rent.

33:24.400 --> 33:29.920
A lot of people go to college, but a lot of people don't go to college because it's a

33:29.920 --> 33:31.960
very big bet.

33:31.960 --> 33:38.320
I went to film school and I still have not paid my student loan fully.

33:38.320 --> 33:46.120
So you think about, because when you spend money, it's about a business, am I making

33:46.120 --> 33:47.120
the right investment?

33:47.120 --> 33:52.720
Am I going to get anything back from it?

33:52.720 --> 33:53.720
That just adds to it.

33:53.720 --> 33:59.840
It's like buying a house, it's like you have a mortgage before even you graduated.

33:59.840 --> 34:05.920
So more and more people are shifting, I think, towards individualism.

34:05.920 --> 34:11.320
And I think this is actually a time that Ayn Rand is going to get big again.

34:11.320 --> 34:19.160
More and more people will be interested in objectivism and think about yourself.

34:19.160 --> 34:25.280
But isn't staying away from mortgages and renting instead just a shift from long-term

34:25.280 --> 34:32.240
investment to short-term flexibility?

34:32.240 --> 34:35.240
I don't know.

34:35.240 --> 34:40.460
I'm confused about how you derive some trend towards individualism from that.

34:40.460 --> 34:44.520
It's not from that.

34:44.520 --> 34:50.880
I think it's just an observation about our social life.

34:50.880 --> 34:56.440
In early 90s, you would see boomboxes and a group of people gathering around it and

34:56.440 --> 34:58.760
walking on the street under a shoulder.

34:58.760 --> 35:02.840
One person has a boombox on the shoulder and like five, six other people walking with them.

35:02.840 --> 35:04.800
People were talking more to each other.

35:04.800 --> 35:07.720
You don't have to talk to anybody literally anymore.

35:07.720 --> 35:11.280
Yeah, I'm with you.

35:11.280 --> 35:17.520
I'm not saying it in the way that even if it was like old days, I'm not a fan of that

35:17.520 --> 35:18.520
at all.

35:18.520 --> 35:29.840
But I think it is more about it's less dependent on a group, which I think is a good thing

35:29.840 --> 35:33.520
when you have Instagram and the culture of selfie.

35:33.520 --> 35:37.320
For example, why is it that big, you think?

35:37.320 --> 35:45.160
That's a mystery to me.

35:45.160 --> 35:49.320
People have been a fan of it since it's crazy.

35:49.320 --> 35:55.800
It's one of those things that begun with being able to take a photo of yourself and see yourself

35:55.800 --> 35:58.680
with a phone and selfie has begun.

35:58.680 --> 36:01.680
It's just a no-brainer.

36:01.680 --> 36:03.640
But Kim Kardashian has a book of selfies.

36:03.640 --> 36:05.040
I don't know if you know about that.

36:05.040 --> 36:06.040
I did not.

36:06.040 --> 36:07.040
Yeah, full of selfies.

36:07.040 --> 36:10.840
But thanks for telling me.

36:10.840 --> 36:12.280
So I don't think it's a bad thing.

36:12.280 --> 36:15.960
I think we're dependent less on group.

36:15.960 --> 36:21.600
Maybe you could look at these selfie trends as kind of an artistic expression.

36:21.600 --> 36:27.080
I'm all for having online avatars and having many of them.

36:27.080 --> 36:30.120
I consider none of them are identical to me.

36:30.120 --> 36:36.160
They're crafted or designed by me for specific purposes and specific communities.

36:36.160 --> 36:39.040
I've got a social one on Facebook.

36:39.040 --> 36:42.040
I've got a very professional one on LinkedIn.

36:42.040 --> 36:48.600
And every different community I'm in, I have a different persona for that community.

36:48.600 --> 36:55.320
And I don't really worry about privacy very much because I only enter the data for that

36:55.320 --> 37:00.040
persona that I want to be associated with that persona.

37:00.040 --> 37:01.760
Mostly I'm not concerned about that at all.

37:01.760 --> 37:06.640
And I think people are freaking out about something that hasn't existed in many, many

37:06.640 --> 37:07.640
years.

37:07.640 --> 37:12.920
It's like, there was a really cool interview with Larry Ellison.

37:12.920 --> 37:14.680
I watched it on YouTube.

37:14.680 --> 37:15.680
Oracle.

37:15.680 --> 37:16.680
Yeah.

37:16.680 --> 37:19.160
And they're talking about NSA and the effect of that.

37:19.160 --> 37:22.960
And he's like, do you know who before NSA had all your information?

37:22.960 --> 37:23.960
Credit card companies.

37:23.960 --> 37:24.960
Right.

37:24.960 --> 37:35.760
And there was an article, I think MIT publication too, about how privacy has died.

37:35.760 --> 37:37.640
And it's a very new thing.

37:37.640 --> 37:39.040
And it has died already.

37:39.040 --> 37:47.480
How people have always favored comfort and accessibility to privacy.

37:47.480 --> 37:49.760
But people are making a huge deal out of it.

37:49.760 --> 37:52.400
And at the same time, Facebook does that.

37:52.400 --> 37:53.400
Google does that.

37:53.400 --> 37:55.480
Don't use them then.

37:55.480 --> 37:56.480
Right.

37:56.480 --> 37:57.800
Exactly.

37:57.800 --> 38:01.580
And if you want to keep something private, I think it's your responsibility to encrypt

38:01.580 --> 38:04.480
it or use secure channels.

38:04.480 --> 38:05.480
I agree.

38:05.480 --> 38:06.480
Technology is the solution.

38:06.480 --> 38:07.480
Absolutely.

38:07.480 --> 38:14.880
It's your responsibility to learn new ways to protect yourself and your information.

38:14.880 --> 38:20.480
I feel the same way about when they're saying Google is selling our information.

38:20.480 --> 38:22.360
So that's not a good thing.

38:22.360 --> 38:25.000
Google is not charging you for anything.

38:25.000 --> 38:29.240
So you can use anything and then that's their business model.

38:29.240 --> 38:31.640
That's the cost of using Google.

38:31.640 --> 38:32.640
Exactly.

38:32.640 --> 38:34.180
So don't use it.

38:34.180 --> 38:37.360
If it's too expensive, then don't.

38:37.360 --> 38:43.640
Don't use Doc Doc Go or whatever else, which is pretty cool.

38:43.640 --> 38:46.040
It's not Google.

38:46.040 --> 38:50.480
I guess the opponents are mistaking these companies for charities.

38:50.480 --> 38:56.280
The users are the product.

38:56.280 --> 38:58.320
They're not really hiding that fact.

38:58.320 --> 38:59.320
Absolutely.

38:59.320 --> 39:00.320
They don't charge you.

39:00.320 --> 39:02.080
They do charge their advertisers.

39:02.080 --> 39:03.080
You are the product.

39:03.080 --> 39:04.080
Absolutely.

39:04.080 --> 39:08.240
And there's nothing wrong with that, I don't think.

39:08.240 --> 39:10.040
That's your side of the bargain.

39:10.040 --> 39:12.340
That's why you get all these great utilities.

39:12.340 --> 39:14.720
This is where we are now.

39:14.720 --> 39:22.400
And I see it in a way that from the time that man has sat in the cave and decided I want

39:22.400 --> 39:27.200
to go outside, that's a decision that you made and everything else that can happen to

39:27.200 --> 39:31.660
you outside of that cave are the alternative of that decision.

39:31.660 --> 39:34.600
So don't leave if you don't want to deal with anything.

39:34.600 --> 39:35.600
It's the same thing.

39:35.600 --> 39:40.280
If you don't want to deal with these things, don't use internet.

39:40.280 --> 39:42.400
People make the same thing about aging.

39:42.400 --> 39:50.280
I think the age reversal, aging technology, there are a couple of organizations that were

39:50.280 --> 39:53.160
working on it.

39:53.160 --> 39:54.160
That's impossible.

39:54.160 --> 39:57.420
If you take this, this is like one of the stupidest thing I've ever heard.

39:57.420 --> 40:01.760
If you take death out of life, life has no meaning.

40:01.760 --> 40:03.080
I've heard that a lot.

40:03.080 --> 40:04.080
Yeah.

40:04.080 --> 40:05.720
Maybe for you.

40:05.720 --> 40:14.480
The meaning for me is that I want to live and not being stuck with being alive.

40:14.480 --> 40:17.000
But I don't want to be stuck with dying either.

40:17.000 --> 40:19.600
I want to have options.

40:19.600 --> 40:24.840
And I'm seeing it in a way that when we get to a point that we can back up our brain inside

40:24.840 --> 40:31.720
the machine, maybe one of me want to be backed up in the drop box of the future.

40:31.720 --> 40:35.880
And then I just want to commit suicide because I want to know how that feels.

40:35.880 --> 40:39.960
And then that version of me, my backup continues on like, oh, cool.

40:39.960 --> 40:41.960
I don't even remember.

40:41.960 --> 40:42.960
Yeah.

40:42.960 --> 40:49.840
That might absolutely be possible if you have uploads.

40:49.840 --> 40:59.240
Do you expect to see uploads within your lifetime?

40:59.240 --> 41:04.360
Uh, it's very hard to say.

41:04.360 --> 41:05.360
Like it's.

41:05.360 --> 41:06.360
Yeah.

41:06.360 --> 41:19.360
Also, you know, I guess if technology and science advance in a rate that they have been advancing

41:19.360 --> 41:27.840
and no major thing happens, possibly.

41:27.840 --> 41:32.000
But I, you don't really know, you know, I mean, it's, it's a crazy world.

41:32.000 --> 41:41.920
The fact that it's funny when this whole ISIL thing began, began in Iraq, um, I was telling

41:41.920 --> 41:47.240
my friends, this is a very good thing that it's a rock because if it was Pakistan, for

41:47.240 --> 41:50.920
example, they have nuclear weapon, they would have nuclear weapon.

41:50.920 --> 41:56.600
The game will be very different than, and now they're in Afghanistan.

41:56.600 --> 42:01.080
You know, and I was watching a documentary about it today by frontline.

42:01.080 --> 42:04.000
It's very good ISIS in Afghanistan.

42:04.000 --> 42:10.160
Um, and they're saying a lot of Taliban, they're leaving Taliban to join ISIS because ISIS

42:10.160 --> 42:14.080
pays $700 a month for each fighter.

42:14.080 --> 42:17.360
Apparently that's a rate and that's a lot of money.

42:17.360 --> 42:18.800
So they did, they joined them.

42:18.800 --> 42:24.520
So when, so the Taliban is working with them where it's joining ISIS.

42:24.520 --> 42:32.800
Now ISIS is fighting Taliban, but there are members of Taliban who've deserted Taliban

42:32.800 --> 42:36.960
and they're continuing to do that because ISIS pays more.

42:36.960 --> 42:37.960
That's the thing.

42:37.960 --> 42:42.800
Also, do they think they want to join the winning side?

42:42.800 --> 42:47.200
I would think that having a higher pay rate isn't going to help if you're on the losing

42:47.200 --> 42:48.200
side.

42:48.200 --> 42:56.680
Well, I mean, I don't know because, um, well, ISIS, at the same time, it's very hard to

42:56.680 --> 43:03.280
kind of imagine what would a Taliban know information wise, like it's very difficult

43:03.280 --> 43:11.500
to judge because it's the opposite side of the side that we are on and watching the news

43:11.500 --> 43:15.080
and conceiving the news for that Taliban.

43:15.080 --> 43:19.840
The problem as they're explaining is that we don't need ISIS because we already have

43:19.840 --> 43:23.760
Islamic government under Taliban.

43:23.760 --> 43:25.520
But then they're making the argument.

43:25.520 --> 43:31.200
Some of the Taliban who desert because it's just a religion filled with loopholes.

43:31.200 --> 43:45.400
I was like, no, it says in the Koran that, um, when there is a, um, caliphate, which

43:45.400 --> 43:51.200
is like, um, what the, the States Islamic state, then you have to join that like it's,

43:51.200 --> 43:53.320
it's an obligation for you.

43:53.320 --> 43:58.960
So with all these insane people around the world, if they get ahold of some serious weapon,

43:58.960 --> 44:04.680
they can cause a massive pause to this whole thing.

44:04.680 --> 44:07.360
At the same time, they might speed things up.

44:07.360 --> 44:17.000
You know, uh, this like Manhattan project, you know, uh, it was because of war that we

44:17.000 --> 44:25.620
build not we were Americans built, uh, west allies builds nuclear weapon, nuclear bomb.

44:25.620 --> 44:34.360
And then again, it was because of war that we went to the moon cold war.

44:34.360 --> 44:38.160
And then it stopped and we haven't gone back to the moon or anywhere else.

44:38.160 --> 44:44.440
And we are started doing it now, maybe because Chinese are getting there too.

44:44.440 --> 44:48.760
They said they're going to land the man on the moon 2020 or something like that, which

44:48.760 --> 44:51.240
is not even comparable.

44:51.240 --> 44:57.880
And I like the Chinese system, but I much rather speak in English and deal with the

44:57.880 --> 44:58.880
Chinese system.

44:58.880 --> 45:06.200
I think Chinese have figured out their country so well and mixed two different systems together

45:06.200 --> 45:07.200
so well.

45:07.200 --> 45:11.920
And they're so strict about it that they've been getting China to where it is now.

45:11.920 --> 45:17.240
But at the same time, China has became a bubble because it has a very small percentage of

45:17.240 --> 45:19.540
really, really rich people now.

45:19.540 --> 45:27.040
And then you go to central China and all those farmlands and it's just like 16th century.

45:27.040 --> 45:32.080
But they're the best capitalists in the world, I think.

45:32.080 --> 45:40.120
But again, uh, like Vietnam now, um, you can hire people much cheaper than China, for example,

45:40.120 --> 45:41.120
Philippines.

45:41.120 --> 45:43.720
So a lot of businesses are going for clothing and stuff.

45:43.720 --> 45:46.440
I know they go, it's, it's going to Vietnam.

45:46.440 --> 45:49.840
It has been going to Vietnam for years now.

45:49.840 --> 45:59.080
Um, but with less dependence on China, it also depends a lot on how we can improve our

45:59.080 --> 46:03.480
manufacturing technologies in the West, in the West.

46:03.480 --> 46:12.060
So 3d printing or machines running things, you know, um, I think they've, but they also

46:12.060 --> 46:14.680
have a brain program, right?

46:14.680 --> 46:18.080
Which Ben Goertzel is working with.

46:18.080 --> 46:19.080
Who's the other guy?

46:19.080 --> 46:20.080
Oh, right.

46:20.080 --> 46:26.640
Um, Ben Goertzel means the brain in software or?

46:26.640 --> 46:33.880
I know the guy who Ben Goertzel was working with, um, who's also in Ray Kurzweil's documentary,

46:33.880 --> 46:40.360
he's, he has a very negative perspective about artificial intelligence, Hugo, Hugo

46:40.360 --> 46:49.600
digress, yes, yes, and his art, artelict war, he sees a coming global violent war between

46:49.600 --> 46:51.280
the humans and the AIs.

46:51.280 --> 46:52.640
What do you think about that?

46:52.640 --> 46:55.520
Well, it's certainly a possibility.

46:55.520 --> 47:01.080
That's why, um, the machine intelligence research Institute exists.

47:01.080 --> 47:07.780
That's why Elon Musk and Bill Gates and the other scientists have joined in, in raising

47:07.780 --> 47:09.880
the issue around.

47:09.880 --> 47:15.000
Do you think it's going to be, um, because it's like one of the biggest concerns that

47:15.000 --> 47:20.160
makes sense as you explained that is there's a possibility that there will be conflict

47:20.160 --> 47:21.160
in that way.

47:21.160 --> 47:28.720
Do you think it will be between humans and machines or humans and human machine fusion?

47:28.720 --> 47:38.760
This third thing, because I'm thinking if, if you have, for example, um, nanobots inside

47:38.760 --> 47:45.760
your brain and you expand as a, you know, you evolve, right?

47:45.760 --> 47:46.760
You become the third thing.

47:46.760 --> 47:55.400
I think if there is a symbiosis between humans and AI, if every human has an AI partner or

47:55.400 --> 48:03.760
a bunch of them, um, then that is a path to a safe future.

48:03.760 --> 48:06.880
That's the best possible future, I think.

48:06.880 --> 48:13.200
But wouldn't it be like the problem would be if there's a single AI that's not human

48:13.200 --> 48:20.760
and not associated with any human that is competing with us for resources and it doesn't

48:20.760 --> 48:26.280
necessarily have any values shared with us.

48:26.280 --> 48:35.100
But like that's terrifying, but at the same time, wouldn't that represent the population

48:35.100 --> 48:37.600
on earth right now?

48:37.600 --> 48:44.880
Like I'm thinking, imagine a fundamentalist Christians would have their own AI.

48:44.880 --> 48:48.520
It would be the projection of them.

48:48.520 --> 48:51.320
Or you think the AI would have the ability to think...

48:51.320 --> 48:56.520
I think the AI and the human together would be a new, greater entity.

48:56.520 --> 48:59.720
Yes, that's exactly, exactly.

48:59.720 --> 49:07.880
And it would, to other people or other agents, it would look like a single agent, but it's

49:07.880 --> 49:10.280
actually a synthesis of the...

49:10.280 --> 49:14.320
It's connected to the same network, basically, neural network.

49:14.320 --> 49:15.320
Possibly.

49:15.320 --> 49:16.320
Yeah.

49:16.320 --> 49:19.240
Do you think they have to, though?

49:19.240 --> 49:26.240
Like the way the Tesla machines, for example, they're communicating with each other now?

49:26.240 --> 49:31.920
That again can bring up the privacy issue and all of that, because like the information

49:31.920 --> 49:34.080
that my car has, I don't want to share it.

49:34.080 --> 49:40.360
But if you don't want to share it, you wouldn't be able to take advantage of the full possibility

49:40.360 --> 49:42.320
of that enhancement.

49:42.320 --> 49:45.320
So same thing with AI, don't you think?

49:45.320 --> 49:52.360
I always think of the same thing with open source, AI to reach its full potential, it

49:52.360 --> 49:54.520
has to be open source.

49:54.520 --> 49:56.520
Probably.

49:56.520 --> 49:58.120
Yeah.

49:58.120 --> 49:59.360
Its full potential, yeah.

49:59.360 --> 50:00.360
What would be the other way?

50:00.360 --> 50:03.480
The other way to what?

50:03.480 --> 50:11.960
The other way to have a functional, superior, intellectually, artificial intelligence by

50:11.960 --> 50:13.680
not having it open source.

50:13.680 --> 50:16.760
What would be the other way?

50:16.760 --> 50:24.240
Stay proprietary, company organization can keep it to themselves, just the way software

50:24.240 --> 50:25.640
companies do already.

50:25.640 --> 50:29.440
Well, source code is not open source.

50:29.440 --> 50:30.720
Right.

50:30.720 --> 50:35.620
You mentioned HoloLens and Oculus Rift.

50:35.620 --> 50:44.840
We know that 2016 is the year that virtual reality will enter mainstream market.

50:44.840 --> 50:48.840
At least the commercial early adopter market.

50:48.840 --> 50:49.840
Yeah.

50:49.840 --> 50:53.720
Well, it's been around for a couple of years now.

50:53.720 --> 50:55.520
Just the development kits.

50:55.520 --> 50:56.520
Yeah.

50:56.520 --> 50:57.720
But it's become more accessible.

50:57.720 --> 51:00.160
You can pre-order Oculus now.

51:00.160 --> 51:01.160
I think it's 599.

51:01.160 --> 51:04.520
Just as of now, just a couple days ago.

51:04.520 --> 51:05.520
Which is awesome.

51:05.520 --> 51:13.720
I was waiting for this version, Crescent Bay, because it has the headphones now.

51:13.720 --> 51:15.260
All right.

51:15.260 --> 51:22.840
For me, as an audio engineer and sound designer, this is amazing because this is the difference

51:22.840 --> 51:27.000
between black and white and color TV to me.

51:27.000 --> 51:35.520
When you can create virtual 360 sonic environments, which is a necessity for virtual reality worlds

51:35.520 --> 51:38.480
to be believable, the sound has to be there.

51:38.480 --> 51:44.520
It's just an amazing opportunity after years of just doing the same thing, basically.

51:44.520 --> 51:50.120
How do you think virtual reality will start affecting, as you said, early adapters and

51:50.120 --> 51:55.680
then how it's going to get into mainstream and how people will feel about it and what

51:55.680 --> 51:59.760
do you think people will use it for and how it's going to change everything?

51:59.760 --> 52:06.320
Well, for the first couple of years, at least, I think the major markets are going to be

52:06.320 --> 52:10.520
in entertainment, probably mostly computer games.

52:10.520 --> 52:19.120
The Rift is coming out packaged with the game EVE Valkyrie, a 3D space game, and the videos

52:19.120 --> 52:21.080
that I've seen on YouTube are mind-blowing.

52:21.080 --> 52:22.760
I cannot wait to try this out.

52:22.760 --> 52:25.640
I'm a big fan of EVE anyways.

52:25.640 --> 52:26.640
That's awesome.

52:26.640 --> 52:33.080
This is going to be really interesting, but I think almost any 3D computer game is going

52:33.080 --> 52:38.880
to lend itself to the Rift and the developers or the games are going to incorporate integration

52:38.880 --> 52:39.880
points.

52:39.880 --> 52:47.640
They'll support the Rift and other similar devices like the HTC.

52:47.640 --> 52:52.800
And then what we'll see then is the price point is going to come down due to volume

52:52.800 --> 52:56.920
and the next generation is going to be just like we've seen with smartphones.

52:56.920 --> 52:58.160
Oh, absolutely.

52:58.160 --> 52:59.320
I think it's smart.

52:59.320 --> 53:00.760
I can't remember who said that.

53:00.760 --> 53:06.640
Maybe Elon Musk said it years ago that always wait for the third generation of a technology

53:06.640 --> 53:13.080
because by the time it gets to the third generation, it's working good enough and it's priced

53:13.080 --> 53:17.920
well enough for everybody to use it basically.

53:17.920 --> 53:23.840
It's a bit difficult to predict the next market after games, but I can see getting

53:23.840 --> 53:32.360
into education easily and 3D movies.

53:32.360 --> 53:33.360
Journalism also.

53:33.360 --> 53:34.360
Yeah.

53:34.360 --> 53:41.640
There's been a movie commissioned by Vice, Vice Media, that they made in Syria and it's

53:41.640 --> 53:43.080
360.

53:43.080 --> 53:50.280
I haven't seen it, but you can't imagine how big of a difference it makes when you're

53:50.280 --> 53:56.520
in the middle of that environment to really feel it and get connected to it.

53:56.520 --> 54:05.400
And also you take away the third, the middle man, because more and more I'm imagining when

54:05.400 --> 54:11.040
citizen journalists, they start arising because of blogging and because of how easy you got

54:11.040 --> 54:18.640
to take photos and videos and put it on YouTube and all those other websites, it will be possible

54:18.640 --> 54:23.400
to make a 360 video quite soon.

54:23.400 --> 54:24.400
I think.

54:24.400 --> 54:25.400
I think it already is.

54:25.400 --> 54:27.660
There is an iPhone app for them.

54:27.660 --> 54:29.000
For 360 videos?

54:29.000 --> 54:30.400
Oh, that's amazing.

54:30.400 --> 54:36.560
I know 360 cameras because one of the biggest challenge back then when they were have to

54:36.560 --> 54:45.760
put a couple of GoPro cameras like four or eight or 12 or something to get a 360 image.

54:45.760 --> 54:50.480
The thing you had to put a lot of cameras and then the image that it was giving you

54:50.480 --> 54:58.560
and to you needed to be stitched and the software to stitch those footage was very complex to

54:58.560 --> 54:59.560
work with.

54:59.560 --> 55:01.760
It was expensive.

55:01.760 --> 55:09.200
But again, like any other technology, the first generation is basically the first step

55:09.200 --> 55:11.800
in trial and error.

55:11.800 --> 55:17.080
But now there are 360 cameras that they cost maybe like 400 bucks, the price of a GoPro

55:17.080 --> 55:22.080
and it gives you already stitched image that you can use.

55:22.080 --> 55:28.600
So somebody in Syria when they're in war and doing a video of, for example, whatever, a

55:28.600 --> 55:34.360
rally or attack or a terrorist, a suicide bomber or something like that.

55:34.360 --> 55:39.120
Of course, I will watch that over a footage that is being transcribed for me by CNN.

55:39.120 --> 55:42.440
For example, it might be in the minority there.

55:42.440 --> 55:43.440
Really?

55:43.440 --> 55:48.160
How many people want to experience a suicide bomber?

55:48.160 --> 55:49.160
I don't know.

55:49.160 --> 55:53.840
I would imagine if I'm interested in what's going on there, I want to kind of feel it

55:53.840 --> 55:59.040
to maybe it just gives you perspective, I think, in my opinion.

55:59.040 --> 56:05.680
Yeah, I think it could definitely have a lot of value.

56:05.680 --> 56:13.880
Maybe for films and TVs too or treatments of I know that they're using that there was

56:13.880 --> 56:20.600
a video of this girl who was claustrophobic and she was so extreme that she couldn't take

56:20.600 --> 56:22.400
elevators.

56:22.400 --> 56:29.320
So they designed a game for her that was emulating her being inside the elevator and she trained

56:29.320 --> 56:36.360
with that and she took an elevator for first year after who knows how many years and it

56:36.360 --> 56:37.360
was amazing.

56:37.360 --> 56:39.120
So in therapy, in treatment.

56:39.120 --> 56:40.120
Yeah, absolutely.

56:40.120 --> 56:41.120
PTSD.

56:41.120 --> 56:44.000
They've been trying that.

56:44.000 --> 56:45.760
I'm looking forward to that.

56:45.760 --> 56:53.800
It's apparently one of the biggest products and technology in CES.

56:53.800 --> 56:58.280
This year was also about virtual reality, everything about virtual reality.

56:58.280 --> 57:02.360
So this is the year.

57:02.360 --> 57:09.280
As a last question before my last standard question, which I will ask everybody, but

57:09.280 --> 57:18.040
last question of series of question conversations that we've had.

57:18.040 --> 57:27.200
How do you think ethics and morality will translate for an artificial intelligence?

57:27.200 --> 57:34.760
Well, that's a pretty deep question.

57:34.760 --> 57:43.520
One way to look at AI is it's a system designed to make choices based on its goals and beliefs.

57:43.520 --> 57:50.760
An AI that's extremely smart, super intelligent, it will tend to have very accurate and sophisticated

57:50.760 --> 57:53.200
beliefs.

57:53.200 --> 58:01.240
The goals are basically beliefs about preferences, which states of the world are preferable to

58:01.240 --> 58:03.040
other states of the world.

58:03.040 --> 58:06.040
Can you even conceive what those beliefs will be?

58:06.040 --> 58:15.440
Well, we can conceive of hard coding beliefs in such a way that the AI will be unable to

58:15.440 --> 58:22.160
change its own goals, but at the same time that may very well cripple the AI in the sense

58:22.160 --> 58:28.880
that it won't be able to get past certain level of sophistication or intelligence if

58:28.880 --> 58:31.280
we cripple its ethical system.

58:31.280 --> 58:34.200
So presumably if it's much smarter than humans.

58:34.200 --> 58:35.200
Oh, absolutely.

58:35.200 --> 58:36.960
As it should be.

58:36.960 --> 58:45.440
We can't really expect to force our own morality per se on a machine that's supposed to be

58:45.440 --> 58:48.520
much better and bigger and the evolution of us.

58:48.520 --> 58:55.840
But that is exactly the project of friendly AI is to enforce our own values onto the AI.

58:55.840 --> 58:57.640
Our values aren't that good.

58:57.640 --> 58:58.640
We still lie.

58:58.640 --> 59:00.880
It's a problem.

59:00.880 --> 59:01.880
We don't.

59:01.880 --> 59:02.880
We're not that good ourselves.

59:02.880 --> 59:03.880
We are not.

59:03.880 --> 59:07.880
We don't even know what would be good.

59:07.880 --> 59:15.260
I mean, like we have no rigorous way of proving that any set of values is better than any

59:15.260 --> 59:16.260
other set.

59:16.260 --> 59:24.200
It's also very confusing to, for example, it's very interesting how it comes to you

59:24.200 --> 59:28.240
when you talk about these kind of things with children because children have no filter and

59:28.240 --> 59:32.800
they just ask you whatever that comes to their mind.

59:32.800 --> 59:39.500
You can't tell a child that killing is wrong as a rule because then he or she will be asking

59:39.500 --> 59:41.640
why those people are dying then.

59:41.640 --> 59:47.200
Why, you know, you can tell them you just won't be very convincing.

59:47.200 --> 59:48.200
Exactly.

59:48.200 --> 59:51.760
And so you can't say it as a rule, right?

59:51.760 --> 59:56.720
And that's like one of the biggest parts of morality, that killing is wrong.

59:56.720 --> 59:58.320
This is just an example.

59:58.320 --> 01:00:02.080
How are we going to explain that to an AI?

01:00:02.080 --> 01:00:05.600
And that is one of the first things that we need to explain it now that we're talking

01:00:05.600 --> 01:00:14.200
about as we spoke about it in military, that autonomous machine, okay, killing is wrong,

01:00:14.200 --> 01:00:21.440
just wound people, you know, but if this guy did this, then killing is fine.

01:00:21.440 --> 01:00:23.240
You can't really do that, you know?

01:00:23.240 --> 01:00:31.400
And that's why I think a lot of these attempts because moralities are different from place

01:00:31.400 --> 01:00:32.400
to place.

01:00:32.400 --> 01:00:35.920
The morality that we have is a very different morality that, for example, people have in

01:00:35.920 --> 01:00:39.640
Yemen, for instance.

01:00:39.640 --> 01:00:46.660
And at the same time, the machine to get to its full potential, it needs to be open source.

01:00:46.660 --> 01:00:51.720
So like Watson or IBM, it's open source.

01:00:51.720 --> 01:00:56.480
So if you have a strong enough of a hardware, you would be able to have...

01:00:56.480 --> 01:00:58.960
Are you sure Watson's open source?

01:00:58.960 --> 01:01:10.640
I think so, because they were asking for programmers and programmers mainly to use Watson capability

01:01:10.640 --> 01:01:13.200
and do their own projects.

01:01:13.200 --> 01:01:23.160
But let's say an open source AI, it would be usable by some Chinese kid in his grandparent's

01:01:23.160 --> 01:01:29.560
basement to build whatever he wants to build with it, or a Russian hacker, or a, you know,

01:01:29.560 --> 01:01:33.200
or a evil person per se, evil quote unquote.

01:01:33.200 --> 01:01:35.680
Yes, that's absolutely true.

01:01:35.680 --> 01:01:40.840
Ben Goetzel has his own open source project, OpenCog, I think, and just a couple of weeks

01:01:40.840 --> 01:01:46.320
ago, Elon Musk and some Peter Thiel, I think, and some other courts announced that they

01:01:46.320 --> 01:01:52.600
were funding another open source project, OpenAI, and they were investing a...

01:01:52.600 --> 01:01:55.720
Peter Thiel was involved in that, so I didn't know that.

01:01:55.720 --> 01:02:00.360
I'm not sure, I think.

01:02:00.360 --> 01:02:06.040
But I think they were putting something like a billion dollars into this project, significant

01:02:06.040 --> 01:02:08.720
funding.

01:02:08.720 --> 01:02:16.080
And at the same time, they came under quite a bit of criticism saying, if you think AI

01:02:16.080 --> 01:02:19.800
is dangerous, why on earth would you open source it?

01:02:19.800 --> 01:02:24.520
And the analogy is made with nuclear arms, if you think nukes are dangerous, you certainly

01:02:24.520 --> 01:02:30.200
don't want to publish an easy how-to on the web, because it could easily fall into the

01:02:30.200 --> 01:02:31.200
wrong hands.

01:02:31.200 --> 01:02:34.560
So why are they doing it with AI?

01:02:34.560 --> 01:02:36.800
What's the explanation?

01:02:36.800 --> 01:02:38.900
I haven't heard their explanation.

01:02:38.900 --> 01:02:50.240
One possibility is that unless you start looking into these issues right away, hardware is

01:02:50.240 --> 01:02:54.240
going to be at a point sometime in the future that there might be an extremely quick ramp

01:02:54.240 --> 01:03:00.560
up time from human level to superhuman level AI, and we won't be prepared.

01:03:00.560 --> 01:03:04.920
So it's better to start now, even if it is dangerous.

01:03:04.920 --> 01:03:06.960
To slow it down, basically.

01:03:06.960 --> 01:03:11.440
Well, to be better prepared for when it happens.

01:03:11.440 --> 01:03:14.840
Even if you end up spinging it up in some ways.

01:03:14.840 --> 01:03:18.760
Would we know it when it happens, you think?

01:03:18.760 --> 01:03:21.680
It depends how it is realized.

01:03:21.680 --> 01:03:28.080
I think if it's a pure AI rather than, say, a human emulation where a brain is scanned

01:03:28.080 --> 01:03:31.080
and then emulated in the hardware to get an AI.

01:03:31.080 --> 01:03:38.640
If it's just a pure code AI, it could happen in a small group that's secret.

01:03:38.640 --> 01:03:44.680
Maybe some company wants to build an AI to do trading on the stock exchanges in order

01:03:44.680 --> 01:03:48.600
to make a lot of money, and it gets more and more intelligent.

01:03:48.600 --> 01:03:53.800
Again, there's more and more data in order to interpret the financial data coming in,

01:03:53.800 --> 01:03:55.520
so it builds up a belief system.

01:03:55.520 --> 01:04:04.080
All it wants to do is make money, and it gets very good at trading and starts buying companies.

01:04:04.080 --> 01:04:05.080
But doing it in a way...

01:04:05.080 --> 01:04:07.240
That's a great idea for a movie.

01:04:07.240 --> 01:04:12.600
But does it in a way that's decentralized, using lots of versions of itself, lots of

01:04:12.600 --> 01:04:17.480
subsidiaries that can't be traced back to the main AI, so nobody realizes that it's

01:04:17.480 --> 01:04:27.880
all controlled by a single mind until it owns so many resources it can take over countries?

01:04:27.880 --> 01:04:30.080
Would you want to take over countries?

01:04:30.080 --> 01:04:31.920
If it needs more resources.

01:04:31.920 --> 01:04:38.100
If that's its main goal is to acquire resources, financial resources, it could become tremendously

01:04:38.100 --> 01:04:42.760
powerful by controlling humans with its resources.

01:04:42.760 --> 01:04:48.240
It could have a million people working for it, they don't even know that they're all

01:04:48.240 --> 01:04:49.640
working for the same mind.

01:04:49.640 --> 01:04:56.520
I think if the AI will be based on human morality, that's exactly what the AI would do.

01:04:56.520 --> 01:05:00.920
He will go after the money.

01:05:00.920 --> 01:05:04.560
Until it can build the hardware to make its own robots.

01:05:04.560 --> 01:05:05.560
Yeah.

01:05:05.560 --> 01:05:06.840
That's very interesting.

01:05:06.840 --> 01:05:15.600
I think I've always enjoyed looking at things as much as I could as a double-edged sword

01:05:15.600 --> 01:05:20.640
everything because they're good and bad, about literally everything, you know, with a hammer

01:05:20.640 --> 01:05:25.220
you can build a house so you can bash somebody's brains.

01:05:25.220 --> 01:05:29.520
So it really depends on how we're using it now, for what purpose we're using it.

01:05:29.520 --> 01:05:37.360
And I think core values of us unfortunately have been corrupted a lot, a majority of people

01:05:37.360 --> 01:05:44.600
because of the money-centric, money for the sake of money, materialistic money.

01:05:44.600 --> 01:05:48.720
Whereas I see that as a positive force.

01:05:48.720 --> 01:05:49.720
Yeah.

01:05:49.720 --> 01:05:50.720
I do.

01:05:50.720 --> 01:05:57.560
That people in the current system can protect their own interests better and advance their

01:05:57.560 --> 01:06:03.880
own interests better by serving others commercially.

01:06:03.880 --> 01:06:04.960
That's interesting.

01:06:04.960 --> 01:06:08.520
So it channels their own personal interests.

01:06:08.520 --> 01:06:09.520
Everyone is self-interested.

01:06:09.520 --> 01:06:18.080
Even those that claim not to be I think are basically deluding themselves and others.

01:06:18.080 --> 01:06:19.600
What they believe is...

01:06:19.600 --> 01:06:26.440
But the way to channel that self-interest into a net good for society is to put in a

01:06:26.440 --> 01:06:32.360
system where you do well by helping others, by selling them products and services, for

01:06:32.360 --> 01:06:33.360
example.

01:06:33.360 --> 01:06:34.360
That's so interesting.

01:06:34.360 --> 01:06:37.760
Last night we were watching a documentary called I Am.

01:06:37.760 --> 01:06:43.600
It's about this director named Tom Shaliak.

01:06:43.600 --> 01:06:49.160
He directed a whole bunch of comedies and made millions and millions of dollars.

01:06:49.160 --> 01:06:54.120
And then he went through this experience that he thought that he was going to die and then

01:06:54.120 --> 01:07:02.960
he survived that and he became very...

01:07:02.960 --> 01:07:09.520
Instead of making our objective profit to make it how we can help each other and help

01:07:09.520 --> 01:07:11.800
each other grow.

01:07:11.800 --> 01:07:16.600
And he was talking to his father and said, why can't we do that?

01:07:16.600 --> 01:07:26.000
And his father said, it's a very nice utopian idea that will never ever happen.

01:07:26.000 --> 01:07:31.520
I think the key is everybody started within themselves that you just make yourself a better

01:07:31.520 --> 01:07:39.840
person and then try to get that understanding to the circle close to you and just expand

01:07:39.840 --> 01:07:44.120
the circle more and more.

01:07:44.120 --> 01:07:53.120
I think it would worth more to focus on what we can do individually than why people aren't

01:07:53.120 --> 01:07:58.600
doing this and this and that because people are built from individuals.

01:07:58.600 --> 01:08:05.980
But also, all these new technologies have given the opportunity and power to an individual

01:08:05.980 --> 01:08:08.840
to change the world if they have a right idea.

01:08:08.840 --> 01:08:09.840
Yeah.

01:08:09.840 --> 01:08:13.400
Technology is making people more powerful every day.

01:08:13.400 --> 01:08:21.960
I think it's great and it's a great time that we can live and enjoy all of these things.

01:08:21.960 --> 01:08:31.880
The last question literally is, if you come in contact with a species from another civilization,

01:08:31.880 --> 01:08:42.680
with alien per se, intelligent aliens, what would be the biggest achievement that you

01:08:42.680 --> 01:08:49.240
would mention to that intelligent alien that we've made and we've achieved as a race?

01:08:49.240 --> 01:08:54.680
And what would be the biggest mistake that we've made?

01:08:54.680 --> 01:08:56.640
Wow.

01:08:56.640 --> 01:09:05.720
Big questions.

01:09:05.720 --> 01:09:11.920
I would offer actually the World Wide Web is our greatest achievement.

01:09:11.920 --> 01:09:17.160
The technology that makes self-expression possible and collaboration.

01:09:17.160 --> 01:09:21.800
I think it's instigated a renaissance across the world.

01:09:21.800 --> 01:09:24.320
It's amazing.

01:09:24.320 --> 01:09:26.280
And in a sense, it's only getting started.

01:09:26.280 --> 01:09:34.080
So ask me 10 years from now and I'll say the successor for the web, whatever that is.

01:09:34.080 --> 01:09:43.400
And as for our worst mistake, I think it's the war machines that we worship as our nation

01:09:43.400 --> 01:09:49.160
states, that they've caused more death, destruction, and suffering than anything else in human

01:09:49.160 --> 01:09:50.720
history.

01:09:50.720 --> 01:09:57.040
And most people are blind to it, that they're proud citizens, they're proud of their nationality,

01:09:57.040 --> 01:10:02.840
they're patriots, and they're brainwashed into thinking that this is a good idea.

01:10:02.840 --> 01:10:09.520
I hope the aliens can shed some perspective on that.

01:10:09.520 --> 01:10:13.040
I hope they've overcome it themselves and if they've come here, I'm pretty sure they

01:10:13.040 --> 01:10:16.640
have destroyed themselves.

01:10:16.640 --> 01:10:22.240
So one more thing, I want to thank you very much for having me as your first guest.

01:10:22.240 --> 01:10:23.240
I'm really flattered.

01:10:23.240 --> 01:10:24.440
Yeah, my pleasure, man.

01:10:24.440 --> 01:10:26.440
And it's been a blast.

01:10:26.440 --> 01:10:27.440
Yeah.

01:10:27.440 --> 01:10:28.440
It's been excellent.

01:10:28.440 --> 01:10:29.440
Glad to hear.

01:10:29.440 --> 01:10:30.440
Thanks a lot.

01:10:30.440 --> 01:10:31.440
You're welcome.

01:10:31.440 --> 01:10:33.440
Thanks for having me.

