1
00:00:00,000 --> 00:00:02,600
Like I said, our entire government believes in an afterlife.

2
00:00:02,720 --> 00:00:04,880
No wonder they don't care about transhumanism.

3
00:00:05,000 --> 00:00:08,720
No wonder they don't care about living far longer because they believe there's

4
00:00:08,720 --> 00:00:11,440
an afterlife out there and they're going to be singing with angels as soon as

5
00:00:11,440 --> 00:00:14,400
they die. And, you know, I just, I don't believe that at all.

6
00:00:21,640 --> 00:00:25,680
Hello and welcome to the 39th episode of New Human Podcasts.

7
00:00:25,680 --> 00:00:29,160
I'm Agabahari, an egologist on Twitter and Instagram,

8
00:00:29,160 --> 00:00:33,200
and you can follow the show on liveinlimbo.com, iTunes, and YouTube.

9
00:00:33,760 --> 00:00:38,560
I recently had the opportunity to have a live conversation via Skype with Zoltan

10
00:00:38,600 --> 00:00:42,040
Isfan as part of an event for the Toronto Transhumanist Meetup,

11
00:00:42,440 --> 00:00:43,880
which I also co-organize.

12
00:00:44,520 --> 00:00:46,880
Zoltan has been on the New Human Podcasts before,

13
00:00:46,880 --> 00:00:49,320
and it's always a pleasure to welcome him back.

14
00:00:49,960 --> 00:00:53,360
Okay. So we have with us today Zoltan Isfan,

15
00:00:53,400 --> 00:00:56,920
who most of you should know who he is,

16
00:00:56,920 --> 00:01:01,200
but for the less informed among us, Zoltan, why don't we start with hearing a little

17
00:01:01,200 --> 00:01:04,000
bit about your background, the work you've done and what you're focusing on now

18
00:01:04,000 --> 00:01:05,200
these days, and we'll take it from there.

19
00:01:06,800 --> 00:01:11,440
Sure. Well, I think, if you take a step back,

20
00:01:12,320 --> 00:01:17,240
I began my futurist career in 2013 when I published

21
00:01:17,240 --> 00:01:19,240
my novel, The Transhumanist Wager.

22
00:01:19,920 --> 00:01:23,560
And that book did, I guess, quite well.

23
00:01:23,560 --> 00:01:29,040
And after that, I sort of became a public figure in the movement

24
00:01:29,320 --> 00:01:32,120
and then in the transhumanist movement.

25
00:01:32,360 --> 00:01:35,480
And from there, I sort of just said, well, what can I do to actually help it?

26
00:01:35,480 --> 00:01:38,040
And since I was a journalist, I began writing a ton of articles.

27
00:01:38,440 --> 00:01:43,400
And after that, I said, well, you know, maybe I should run for president

28
00:01:43,400 --> 00:01:47,760
because it's a 2000, you know, the 2016 elections are coming.

29
00:01:47,760 --> 00:01:56,120
And it's a pretty unique opportunity to get my message, the transhumanist

30
00:01:56,120 --> 00:01:58,600
message, out there when everyone's watching.

31
00:01:58,600 --> 00:02:01,920
And so I ran for president under the formation of the Transhumanist Party.

32
00:02:02,400 --> 00:02:06,160
And lo and behold, the campaign did very, very well.

33
00:02:06,160 --> 00:02:07,680
It was very, very visible.

34
00:02:08,120 --> 00:02:10,040
And I did that for over two years.

35
00:02:10,040 --> 00:02:13,640
And it did so well that, of course, I didn't win.

36
00:02:13,640 --> 00:02:16,560
I did so well, but that I thought I'd run for governor.

37
00:02:16,560 --> 00:02:19,480
Now of California, I'm running as a libertarian this time, instead of

38
00:02:19,480 --> 00:02:22,080
as under the Transhumanist Party, but of course, I'm still running

39
00:02:22,080 --> 00:02:23,280
a transhumanist platform.

40
00:02:23,520 --> 00:02:26,360
So that sort of brings everyone up to speed, I guess, to how this happened.

41
00:02:26,360 --> 00:02:29,760
But a lot of it began with the novel I published called The Transhumanist Wager.

42
00:02:31,040 --> 00:02:34,720
Yeah, we're going to talk about your run as a governor, but I want to ask you,

43
00:02:34,720 --> 00:02:38,240
since you ran as a presidential candidate in the Shet Show, that was

44
00:02:38,400 --> 00:02:42,720
presidential campaign of 2016, and you went across the country and talked to

45
00:02:43,040 --> 00:02:45,280
many different people from different backgrounds.

46
00:02:45,280 --> 00:02:47,600
Why don't you tell us what is happening in America?

47
00:02:47,600 --> 00:02:51,080
Because a lot of people are just amazed and surprised and confused.

48
00:02:51,080 --> 00:02:53,080
And what is the forecast, in your opinion?

49
00:02:53,080 --> 00:02:53,560
What's coming?

50
00:02:56,200 --> 00:03:01,120
Well, you mean what is coming politically or what is coming in the transhumanist world?

51
00:03:01,120 --> 00:03:07,680
Why isn't a transhumanist world depend or depend directly to what's happening politically?

52
00:03:08,480 --> 00:03:13,440
Well, I'm not optimistic at the moment because I feel with Republican and

53
00:03:13,440 --> 00:03:22,480
Congress in the executive branch, we have a potential problem, because, let's be honest,

54
00:03:22,480 --> 00:03:30,720
conservatives generally will hold back technology more than other types of politicians will.

55
00:03:30,720 --> 00:03:34,320
And that presents a problem because, for example, Mike Pence has already expressed some,

56
00:03:34,880 --> 00:03:39,360
at least that I've heard, some angst at genetic editing, and genetic editing is potentially

57
00:03:39,360 --> 00:03:43,520
the most important transhumanist and science of the 21st century.

58
00:03:43,520 --> 00:03:47,200
So if we have conservatives in government that want to hold back stuff like that, then

59
00:03:47,360 --> 00:03:48,960
we're in very big trouble.

60
00:03:48,960 --> 00:03:53,680
On the other hand, I think generally Trump will be okay for science because he's a capitalist.

61
00:03:53,680 --> 00:03:56,640
And it is capitalism that moves forward science.

62
00:03:56,640 --> 00:04:01,680
The problem, though, is really, does only some parts move forward?

63
00:04:01,680 --> 00:04:05,680
Like AI seems to be moving forward, but if genetic editing doesn't go forward, then maybe

64
00:04:05,680 --> 00:04:07,680
we don't get the longevity that I want.

65
00:04:07,680 --> 00:04:09,680
Instead, we get only the technology.

66
00:04:09,680 --> 00:04:11,680
So these are some of the worries that I have.

67
00:04:11,680 --> 00:04:15,680
I mean, ultimately, it would have been better to just have somebody who was very pro-science

68
00:04:15,680 --> 00:04:22,480
and pro-capitalism, I think, when you talk about the long-term ramifications of transhumanism.

69
00:04:22,480 --> 00:04:26,480
Maybe capitalism can survive and be on 10 or 20 more years.

70
00:04:26,480 --> 00:04:30,480
But the question was to try to answer the environment today.

71
00:04:30,480 --> 00:04:34,480
The reason, you know, I'm not a Trump supporter, just everybody knows that.

72
00:04:34,480 --> 00:04:37,680
But the NASDAQ and the stock markets have been hitting new highs.

73
00:04:37,680 --> 00:04:42,480
People are optimistic about money filtering into the companies like Google and Apple and

74
00:04:42,480 --> 00:04:44,480
other companies that make the technology.

75
00:04:44,480 --> 00:04:48,480
It is an environment that a lot of stuff can come out.

76
00:04:48,480 --> 00:04:55,280
That said, if we get into a position where all of a sudden fascism takes over or, you

77
00:04:55,280 --> 00:05:00,480
know, people like Mike Pence, the vice president, really want to hold back science, then we

78
00:05:00,480 --> 00:05:04,480
could be in for a very terrible scenario.

79
00:05:04,480 --> 00:05:08,480
It's not unfolding like I wanted, but right now we're still doing okay.

80
00:05:08,480 --> 00:05:10,480
But there are plenty of things to worry about in the horizon.

81
00:05:10,480 --> 00:05:12,480
A lot of challenges, yeah.

82
00:05:12,480 --> 00:05:16,480
You said that you're still running on a transhumanist platform.

83
00:05:16,480 --> 00:05:22,480
So please explain what is a transhumanist platform that you're running on and why are

84
00:05:22,480 --> 00:05:26,480
you running as a libertarian in a solid Democrat state?

85
00:05:26,480 --> 00:05:28,480
What are you trying to achieve?

86
00:05:28,480 --> 00:05:32,480
Well, you know, to be honest, I'm a left-leaning libertarian.

87
00:05:32,480 --> 00:05:34,480
I've been very honest about that from the beginning.

88
00:05:34,480 --> 00:05:39,480
I support a universal basic income and I support a lot of the policies of the Democratic Party.

89
00:05:39,480 --> 00:05:43,480
However, I'm also quite libertarian in many ways.

90
00:05:43,480 --> 00:05:49,480
And I just felt like I had a better chance of making a real impact in the California

91
00:05:49,480 --> 00:05:51,480
gubernatorial race as a libertarian.

92
00:05:51,480 --> 00:05:55,480
I mean, after all, there's already like 10 other candidates that are running as Democrats.

93
00:05:55,480 --> 00:05:59,480
And frankly, some of them are, you know, seasoned politicians.

94
00:05:59,480 --> 00:06:03,480
Whereas, you know, by coming in as a libertarian, I came in as sort of the leader of the pack.

95
00:06:03,480 --> 00:06:09,480
And that was a great, from a point of view of making an impact, that's really important.

96
00:06:09,480 --> 00:06:13,480
I think, though, a transhumanist platform, where my platform becomes quite different,

97
00:06:13,480 --> 00:06:17,480
is that I'm, you know, a number one goal of mine is still longevity.

98
00:06:17,480 --> 00:06:19,480
And it's also very much healthcare.

99
00:06:19,480 --> 00:06:23,480
Even though I don't support a universal healthcare, I support a universal basic income

100
00:06:23,480 --> 00:06:28,480
with the idea that all this extra money can pay so everybody has healthcare.

101
00:06:28,480 --> 00:06:33,480
And I just feel like it's the right of the nation and the right of the citizenry

102
00:06:33,480 --> 00:06:36,480
to fight for its own people's longevity.

103
00:06:36,480 --> 00:06:40,480
And this is something that's, you know, very, very important to me.

104
00:06:40,480 --> 00:06:44,480
I'm not going to give that up just because, you know, as a libertarian,

105
00:06:44,480 --> 00:06:48,480
I'm not supposed to want government in everybody's, you know, plates and bedrooms or whatever.

106
00:06:48,480 --> 00:06:50,480
I don't want that.

107
00:06:50,480 --> 00:06:56,480
But at the same time, I do feel very strongly that a national agenda should be longevity.

108
00:06:56,480 --> 00:06:59,480
A national agenda should be moving the species forward

109
00:06:59,480 --> 00:07:02,480
and making people's lives better through science and technology.

110
00:07:02,480 --> 00:07:08,480
Yeah, longevity has been on one of the premier policies that you've been following.

111
00:07:08,480 --> 00:07:14,480
What steps have you taken to make aging to be recognized as a disease?

112
00:07:14,480 --> 00:07:17,480
And what are the obstacles and opportunities ahead of us?

113
00:07:17,480 --> 00:07:20,480
Well, and that's the number one thing. In my opinion,

114
00:07:20,480 --> 00:07:23,480
you really need to make aging recognized as a disease

115
00:07:23,480 --> 00:07:25,480
because otherwise there's zero funding for it.

116
00:07:25,480 --> 00:07:28,480
I mean, right now the amount of funding that is going into,

117
00:07:28,480 --> 00:07:31,480
from the NIH, National Institute of Health,

118
00:07:31,480 --> 00:07:33,480
you know, which gives the billions and billions of dollars,

119
00:07:33,480 --> 00:07:37,480
is just not giving much money to people.

120
00:07:37,480 --> 00:07:40,480
Not to researchers, not to universities, not to corporations,

121
00:07:40,480 --> 00:07:44,480
because anti-aging is somewhat against government policy.

122
00:07:44,480 --> 00:07:47,480
You have to understand, in America, 535 members of Congress,

123
00:07:47,480 --> 00:07:52,480
all nine Supreme Court justices and our president and vice president, are religious.

124
00:07:52,480 --> 00:07:54,480
They believe in an afterlife.

125
00:07:54,480 --> 00:07:57,480
So they're not going to take government money

126
00:07:57,480 --> 00:08:01,480
and say, let's put it towards something that wants everybody to live, you know, forever,

127
00:08:01,480 --> 00:08:03,480
or at least thousands of years.

128
00:08:03,480 --> 00:08:05,480
That's just sort of anti-religious.

129
00:08:05,480 --> 00:08:08,480
What's important, though, is what I'm trying to do is change the culture.

130
00:08:08,480 --> 00:08:11,480
If you can classify aging as a disease,

131
00:08:11,480 --> 00:08:14,480
then all of a sudden funding will fund from the government,

132
00:08:14,480 --> 00:08:16,480
and also culture will start changing.

133
00:08:16,480 --> 00:08:21,480
People may elect politicians that are more interested in

134
00:08:21,480 --> 00:08:25,480
practices that would make people live a lot longer and maybe even overcome death.

135
00:08:25,480 --> 00:08:27,480
You have to be careful, because like I said,

136
00:08:27,480 --> 00:08:32,480
right now 100% of our government, at least on paper, says they believe in an afterlife.

137
00:08:32,480 --> 00:08:36,480
And when I talk about ending death, that's very,

138
00:08:36,480 --> 00:08:39,480
that's sort of like changing the institution entirely.

139
00:08:39,480 --> 00:08:41,480
And that's exactly what I was going to ask you.

140
00:08:41,480 --> 00:08:44,480
Do we have a problem with the foundation of a political system

141
00:08:44,480 --> 00:08:48,480
that we have in the United States, which is corrupted, very slow,

142
00:08:48,480 --> 00:08:51,480
and as you said, extremely religious?

143
00:08:51,480 --> 00:08:53,480
I remember you were telling me you were going to the South,

144
00:08:53,480 --> 00:08:55,480
and everybody were saying you have a chip in your hand,

145
00:08:55,480 --> 00:08:58,480
so this is a mark of the beast, you're anti-Christ, and all of,

146
00:08:58,480 --> 00:09:01,480
like what, how are we going to change those people who, you know,

147
00:09:01,480 --> 00:09:04,480
voted for Trump when he stood up there and said,

148
00:09:04,480 --> 00:09:07,480
I know the system best, so I'm the only one who can change it,

149
00:09:07,480 --> 00:09:09,480
and he got all those votes.

150
00:09:09,480 --> 00:09:12,480
How are we going to tell them that, hey, you don't need to die,

151
00:09:12,480 --> 00:09:15,480
and you don't need to go to heaven and hell, and Jesus might be good for you,

152
00:09:15,480 --> 00:09:18,480
but don't shove it down our throats.

153
00:09:18,480 --> 00:09:20,480
How are we going to get there?

154
00:09:20,480 --> 00:09:25,480
It seems to just go a very long, long, far, far away.

155
00:09:25,480 --> 00:09:27,480
Well, one thing I think we just got to wait it out,

156
00:09:27,480 --> 00:09:31,480
because it does seem like a lot of millennials are far less religious.

157
00:09:31,480 --> 00:09:35,480
And I also think we need to fight back, and we have to fight back with technology.

158
00:09:35,480 --> 00:09:40,480
It's a lot harder to justify Christianity in the technological age

159
00:09:40,480 --> 00:09:41,480
or in the machine age.

160
00:09:41,480 --> 00:09:44,480
Questions like, should artificial intelligence believe in Jesus?

161
00:09:44,480 --> 00:09:46,480
That's such an absurd question.

162
00:09:46,480 --> 00:09:48,480
As soon as you start thinking about that question,

163
00:09:48,480 --> 00:09:50,480
you realize how ridiculous religion is.

164
00:09:50,480 --> 00:09:53,480
And these are the things that technology might actually make

165
00:09:53,480 --> 00:09:55,480
the religious question obsolete to some extent.

166
00:09:55,480 --> 00:09:58,480
Now, I'm not saying that people shouldn't be religious.

167
00:09:58,480 --> 00:10:01,480
What I'm just saying, though, is the fundamentalism has to change.

168
00:10:01,480 --> 00:10:04,480
They need to stop going, you know, if they want to believe in Jesus

169
00:10:04,480 --> 00:10:07,480
as some kind of overriding spiritual power.

170
00:10:07,480 --> 00:10:10,480
Because even I must say, you know, even though I say I'm an atheist,

171
00:10:10,480 --> 00:10:13,480
if you really ask me downright, do I know if there's an afterlife or not,

172
00:10:13,480 --> 00:10:15,480
I don't know. Come on.

173
00:10:15,480 --> 00:10:17,480
I mean, I'm not that smart. Nobody's that smart.

174
00:10:17,480 --> 00:10:21,480
Anyone that says they do is honestly lying.

175
00:10:21,480 --> 00:10:27,480
But the reality is I could accept a much bigger version of God,

176
00:10:27,480 --> 00:10:32,480
but I can't accept one that follows a Bible word for word,

177
00:10:32,480 --> 00:10:36,480
phrase for phrase, and then takes those phrases and applies them to government.

178
00:10:36,480 --> 00:10:37,480
This is insane to me.

179
00:10:37,480 --> 00:10:40,480
This is when we need, you know, the scientific method is what I base

180
00:10:40,480 --> 00:10:43,480
my campaign on, what I base all my philosophies on,

181
00:10:43,480 --> 00:10:46,480
is proving these ideas again and again.

182
00:10:46,480 --> 00:10:51,480
And if an idea proves very useful, you can use it.

183
00:10:51,480 --> 00:10:54,480
But at some point, you have to be understanding that it might not be useful,

184
00:10:54,480 --> 00:10:56,480
and then it's time to upgrade that idea.

185
00:10:56,480 --> 00:10:59,480
That's how a humble person does it, a normal person does it.

186
00:10:59,480 --> 00:11:01,480
If something's wrong, they fix it.

187
00:11:01,480 --> 00:11:04,480
A virgin can be wrong. It's not like we got everything right.

188
00:11:04,480 --> 00:11:07,480
Maybe there is a God. I'll be the first to say that.

189
00:11:07,480 --> 00:11:12,480
But to pinpoint it down on some Judeo-Christian person with a red beard

190
00:11:12,480 --> 00:11:16,480
or long hair and, you know, says that you can only be forgiven your sins

191
00:11:16,480 --> 00:11:19,480
and go through Christ to reach heaven,

192
00:11:19,480 --> 00:11:21,480
this is not a system I want to teach my children.

193
00:11:21,480 --> 00:11:23,480
It's not a system I want to live in.

194
00:11:23,480 --> 00:11:28,480
So we have to fight against that and rail against that with media,

195
00:11:28,480 --> 00:11:31,480
you know, what you're doing today with your podcast.

196
00:11:31,480 --> 00:11:33,480
I mean, these are the kinds of things that make a difference.

197
00:11:33,480 --> 00:11:36,480
And we're winning. Don't for a second think we're not.

198
00:11:36,480 --> 00:11:37,480
When you look at the younger generation,

199
00:11:37,480 --> 00:11:41,480
there's never been so much lack of religiosity in this nation,

200
00:11:41,480 --> 00:11:45,480
and already 50% of Europe is atheism.

201
00:11:45,480 --> 00:11:46,480
So we're winning.

202
00:11:46,480 --> 00:11:51,480
There's no question that, you know, secularism to some extent is winning.

203
00:11:51,480 --> 00:11:55,480
And it may not be secularism. It just might be less fundamentalism.

204
00:11:55,480 --> 00:12:00,480
So I'm encouraged, but it's going to be 20 or 30 years

205
00:12:00,480 --> 00:12:02,480
before we really start to see some real progress.

206
00:12:02,480 --> 00:12:06,480
That's still, I think, a pretty optimistic timeframe.

207
00:12:06,480 --> 00:12:10,480
I'm going to ask you the question that David McPherson wanted to ask you,

208
00:12:10,480 --> 00:12:15,480
but I'm going to also mention, because you quite correctly, I think,

209
00:12:15,480 --> 00:12:19,480
brought up how absurd Christian transhumanism is.

210
00:12:19,480 --> 00:12:23,480
And I've had Lincoln Cannon from Mormon Transhumanist Association

211
00:12:23,480 --> 00:12:27,480
and Christopher Benwick from the Christian Transhumanist Association,

212
00:12:27,480 --> 00:12:29,480
both on the podcast.

213
00:12:29,480 --> 00:12:33,480
And to me, it seems like they're using transhumanism

214
00:12:33,480 --> 00:12:36,480
to justify their religious belief.

215
00:12:36,480 --> 00:12:40,480
But one thing that they do have in common is that they both,

216
00:12:40,480 --> 00:12:43,480
and James Hughes is not the person I talked to,

217
00:12:43,480 --> 00:12:48,480
they all are against you to run as a transhumanist figure, as I'm sure you know.

218
00:12:48,480 --> 00:12:51,480
So David McPherson is asking, with that in mind,

219
00:12:51,480 --> 00:12:57,480
why do you think you're such a polarizing figure within the transhumanist community?

220
00:12:57,480 --> 00:13:03,480
I'm not a big fan of talking about, I guess, myself and this conflict,

221
00:13:03,480 --> 00:13:05,480
but I'll just try to be honest.

222
00:13:05,480 --> 00:13:07,480
But this is a community, right?

223
00:13:07,480 --> 00:13:12,480
If these people in the community are just throwing rocks on your way,

224
00:13:12,480 --> 00:13:14,480
why do you think that is?

225
00:13:14,480 --> 00:13:18,480
I don't know. It's a bummer, too, because I feel like we're all in this for longevity.

226
00:13:18,480 --> 00:13:22,480
That's one of the cruxes of the situation of our community,

227
00:13:22,480 --> 00:13:24,480
is that we all don't want to die.

228
00:13:24,480 --> 00:13:27,480
When people get in the way of other people,

229
00:13:27,480 --> 00:13:30,480
everyone says, oh, I damaged the movement,

230
00:13:30,480 --> 00:13:36,480
but I made the movement quite large because I was sort of the sole mainstream journalist.

231
00:13:36,480 --> 00:13:41,480
I put out 200 articles almost in the last three years in huge places,

232
00:13:41,480 --> 00:13:43,480
Gizmodo, VICE, Newsweek, Wired.

233
00:13:43,480 --> 00:13:46,480
It went around the world.

234
00:13:46,480 --> 00:13:49,480
I was just looking yesterday at one of my new videos,

235
00:13:49,480 --> 00:13:51,480
or the videos from the last week.

236
00:13:51,480 --> 00:13:55,480
In two weeks, it went up from 14 million views to 16 million views.

237
00:13:55,480 --> 00:14:02,480
You have to understand that's more traffic than Humanity Plus gets in an entire 365 days,

238
00:14:02,480 --> 00:14:05,480
what I often get in a day or two now.

239
00:14:05,480 --> 00:14:09,480
Are they just jealous?

240
00:14:09,480 --> 00:14:11,480
I don't know.

241
00:14:11,480 --> 00:14:17,480
What I think is, honestly, there has never been a journalist in the movement,

242
00:14:17,480 --> 00:14:19,480
and I appeared and all of a sudden,

243
00:14:19,480 --> 00:14:23,480
journalists have a way of making things happen in a different way.

244
00:14:23,480 --> 00:14:25,480
We have an amazing amount of scientists.

245
00:14:25,480 --> 00:14:29,480
We have an amazing amount of engineers, an amazing amount of technologists,

246
00:14:29,480 --> 00:14:32,480
but we also need popularizers.

247
00:14:32,480 --> 00:14:34,480
We need provocateurs.

248
00:14:34,480 --> 00:14:37,480
We need people that actually go out there with a coffin bus

249
00:14:37,480 --> 00:14:40,480
and drive around and spread it to those people in the South

250
00:14:40,480 --> 00:14:42,480
who really don't want to hear it.

251
00:14:42,480 --> 00:14:44,480
Then you get those people in the South,

252
00:14:44,480 --> 00:14:47,480
put you on Infowars and all this other crazy stuff.

253
00:14:47,480 --> 00:14:50,480
In the meantime, what happens is it starts building,

254
00:14:50,480 --> 00:14:51,480
and you get recognition.

255
00:14:51,480 --> 00:14:53,480
Now, the recognition may not be good at first,

256
00:14:53,480 --> 00:14:56,480
but a lot of the recognition will never be good.

257
00:14:56,480 --> 00:15:01,480
To the Trump people, Hillary was never a good person.

258
00:15:01,480 --> 00:15:04,480
It's going to be polarizing no matter how it goes.

259
00:15:04,480 --> 00:15:07,480
I think what's important, though, is the recognition.

260
00:15:07,480 --> 00:15:10,480
If you hear the word transhumanism enough times,

261
00:15:10,480 --> 00:15:13,480
and you hear that science and technology can defeat death,

262
00:15:13,480 --> 00:15:16,480
you start to believe in it or you start to hate it.

263
00:15:16,480 --> 00:15:19,480
Whatever it is, at least it invokes a kind of a reaction.

264
00:15:19,480 --> 00:15:23,480
I guess my coming on the scene and doing that so dramatically

265
00:15:23,480 --> 00:15:25,480
really got a lot of people upset.

266
00:15:25,480 --> 00:15:28,480
Maybe it was jealousy. Maybe it was just, I don't know,

267
00:15:28,480 --> 00:15:31,480
maybe they didn't like my sense. I don't know.

268
00:15:31,480 --> 00:15:33,480
It's hard to know exactly why,

269
00:15:33,480 --> 00:15:38,480
but obviously I caused a big hoo-ha in the whole community.

270
00:15:38,480 --> 00:15:41,480
I think it's jealousy, but we'll see.

271
00:15:41,480 --> 00:15:44,480
I don't like to say that just because I'm not sure

272
00:15:44,480 --> 00:15:46,480
what there's really to be jealous of.

273
00:15:46,480 --> 00:15:48,480
It's like we're all going to live longer,

274
00:15:48,480 --> 00:15:50,480
and the movement has grown into something

275
00:15:50,480 --> 00:15:52,480
that's almost mainstream now.

276
00:15:52,480 --> 00:15:56,480
I see the New York Times using the word transhumanism.

277
00:15:56,480 --> 00:15:58,480
They don't even think about it anymore.

278
00:15:58,480 --> 00:16:00,480
This is now a real movement.

279
00:16:00,480 --> 00:16:03,480
What they're saying basically is that because of your book,

280
00:16:03,480 --> 00:16:05,480
I think that you want to become a totalitarian,

281
00:16:05,480 --> 00:16:07,480
transhumanist king who wants to chip everyone,

282
00:16:07,480 --> 00:16:10,480
because you also mentioned about refugees from Syria.

283
00:16:10,480 --> 00:16:13,480
It's one of the ways they can control it.

284
00:16:13,480 --> 00:16:16,480
I don't know if anyone's ever read the ending of the book,

285
00:16:16,480 --> 00:16:20,480
but the totalitarian king gives back the entire world

286
00:16:20,480 --> 00:16:23,480
to a free, democratic environment

287
00:16:23,480 --> 00:16:26,480
and goes to live in the woods and writes philosophy.

288
00:16:26,480 --> 00:16:29,480
In many ways, that's what a strong armed leader would do.

289
00:16:29,480 --> 00:16:32,480
A strong armed CEO will sometimes do that.

290
00:16:32,480 --> 00:16:35,480
He creates a company, he's done what he needs to do,

291
00:16:35,480 --> 00:16:37,480
and then he leaves.

292
00:16:37,480 --> 00:16:40,480
In the meantime, everybody's gained a whole bunch more freedoms.

293
00:16:40,480 --> 00:16:43,480
Sometimes it does, and this is just the novel I'm speaking of,

294
00:16:43,480 --> 00:16:47,480
but I think sometimes it's okay to push those extra boundaries.

295
00:16:47,480 --> 00:16:49,480
That's how change occurs.

296
00:16:49,480 --> 00:16:52,480
I just want to point out that the guy in the book

297
00:16:52,480 --> 00:16:54,480
ends up not being a totalitarian king,

298
00:16:54,480 --> 00:16:58,480
but just a humble philosopher who willingly, openly gave

299
00:16:58,480 --> 00:17:00,480
the world back to the world.

300
00:17:00,480 --> 00:17:02,480
Yeah, they just make whatever they want out of it

301
00:17:02,480 --> 00:17:04,480
the same way they're doing the Bible.

302
00:17:04,480 --> 00:17:08,480
For the records, you told me, I spoke to you about a year ago,

303
00:17:08,480 --> 00:17:10,480
and you told me that you're going to step down

304
00:17:10,480 --> 00:17:12,480
from transhumanist party leadership

305
00:17:12,480 --> 00:17:14,480
and just give it to the community,

306
00:17:14,480 --> 00:17:16,480
and that's exactly what you did,

307
00:17:16,480 --> 00:17:20,480
because you're not necessarily part of transhumanist leadership,

308
00:17:20,480 --> 00:17:22,480
transhumanist party leadership anymore, right?

309
00:17:22,480 --> 00:17:24,480
Yeah, yeah, no, I'm not.

310
00:17:24,480 --> 00:17:26,480
I'm an advisor to the transhumanist party,

311
00:17:26,480 --> 00:17:28,480
and I still strongly believe in it,

312
00:17:28,480 --> 00:17:32,480
and maybe I'll try to help at all times,

313
00:17:32,480 --> 00:17:34,480
but maybe I'll take a leadership role in the future.

314
00:17:34,480 --> 00:17:37,480
I don't know, but right now I handed it over

315
00:17:37,480 --> 00:17:41,480
to Gennady Stolerov, and he's done an excellent job,

316
00:17:41,480 --> 00:17:43,480
and I think he democratized it.

317
00:17:43,480 --> 00:17:45,480
He did a better job democratizing it than I did.

318
00:17:45,480 --> 00:17:47,480
That's okay to say,

319
00:17:47,480 --> 00:17:50,480
and I like a lot of the new policies that have gone on.

320
00:17:50,480 --> 00:17:52,480
The problem, though, is that right now

321
00:17:52,480 --> 00:17:54,480
we're still trying to build the party,

322
00:17:54,480 --> 00:17:56,480
it's still quite small,

323
00:17:56,480 --> 00:17:58,480
it's not getting the same amount of media attention,

324
00:17:58,480 --> 00:18:00,480
and so there were some trade-offs,

325
00:18:00,480 --> 00:18:03,480
but I'm happy to see that the transhumanist party continues,

326
00:18:03,480 --> 00:18:05,480
and I'm a firm believer

327
00:18:05,480 --> 00:18:08,480
that it's a very needed political institution out there

328
00:18:08,480 --> 00:18:11,480
that can actually play a real role in history,

329
00:18:11,480 --> 00:18:14,480
maybe not in the next two years or four years,

330
00:18:14,480 --> 00:18:16,480
but certainly in the next decade or two decades.

331
00:18:16,480 --> 00:18:18,480
Right, I agree.

332
00:18:18,480 --> 00:18:20,480
Let's talk about unemployment,

333
00:18:20,480 --> 00:18:25,480
which is a big subject in the past campaign.

334
00:18:25,480 --> 00:18:28,480
Trump blamed, not refugees,

335
00:18:28,480 --> 00:18:30,480
but illegal immigrants

336
00:18:30,480 --> 00:18:34,480
and people who are working and taking jobs away from Americans,

337
00:18:34,480 --> 00:18:37,480
but the reality is a lot of those jobs are not coming back

338
00:18:37,480 --> 00:18:39,480
due to automation,

339
00:18:39,480 --> 00:18:42,480
but nobody really talked about automation.

340
00:18:42,480 --> 00:18:46,480
So do you think over the next two, three years,

341
00:18:46,480 --> 00:18:49,480
when Trump won't be able to deliver the number of jobs

342
00:18:49,480 --> 00:18:51,480
and the increase in economy that he has promised,

343
00:18:51,480 --> 00:18:54,480
the attention will be shift towards technology

344
00:18:54,480 --> 00:18:58,480
and automation as the main scapegoat?

345
00:18:58,480 --> 00:19:01,480
Yeah, look, Trump, I'm not saying Trump lied,

346
00:19:01,480 --> 00:19:04,480
maybe he just didn't know, but the bottom line, he was wrong.

347
00:19:04,480 --> 00:19:06,480
I mean, this was never about immigrants.

348
00:19:06,480 --> 00:19:08,480
It was crazy to name immigrants as the issue.

349
00:19:08,480 --> 00:19:10,480
I mean, certainly that's something that, like,

350
00:19:10,480 --> 00:19:13,480
when you had outsourcing of jobs a long time ago

351
00:19:13,480 --> 00:19:15,480
to Asia and place Mexico and whatnot,

352
00:19:15,480 --> 00:19:16,480
that made a lot of sense.

353
00:19:16,480 --> 00:19:18,480
Like, you could see the jobs going,

354
00:19:18,480 --> 00:19:21,480
but this time around, it really didn't have to do with immigrants.

355
00:19:21,480 --> 00:19:23,480
If you just followed the numbers, you would say, wow,

356
00:19:23,480 --> 00:19:26,480
I mean, jobs are being replaced because technology is increasing,

357
00:19:26,480 --> 00:19:30,480
and it's not increasing in certain, like, just in agriculture

358
00:19:30,480 --> 00:19:31,480
or just in healthcare.

359
00:19:31,480 --> 00:19:35,480
It's increasing every single field of the economy that we have.

360
00:19:35,480 --> 00:19:40,480
It's really easy for any CEO to see that technology is replacing workers,

361
00:19:40,480 --> 00:19:43,480
and that's going to become so pronounced.

362
00:19:43,480 --> 00:19:47,480
Like, every single day, another day goes by, that increases.

363
00:19:47,480 --> 00:19:50,480
And at some point, people are going to wake up in four years,

364
00:19:50,480 --> 00:19:52,480
or probably in 2020, and say,

365
00:19:52,480 --> 00:19:54,480
wow, we have a massive problem in our hands,

366
00:19:54,480 --> 00:20:00,480
and building a wall is not going to solve the situation.

367
00:20:00,480 --> 00:20:04,480
The situation is going to be solved by a sort of

368
00:20:04,480 --> 00:20:06,480
post-capitalistic type of environment,

369
00:20:06,480 --> 00:20:09,480
which probably is going to involve a universal basic income of some sorts,

370
00:20:09,480 --> 00:20:11,480
which, of course, I support.

371
00:20:11,480 --> 00:20:14,480
There's no way that we're going to continue

372
00:20:14,480 --> 00:20:16,480
when 4 million truck drivers lose their jobs,

373
00:20:16,480 --> 00:20:20,480
when nurses lose their jobs due to robots, when lawyers lose...

374
00:20:20,480 --> 00:20:23,480
I mean, the whole system's changing, the entire system.

375
00:20:23,480 --> 00:20:24,480
And we can't just all be artists.

376
00:20:24,480 --> 00:20:26,480
I mean, maybe we can be,

377
00:20:26,480 --> 00:20:28,480
but I don't think we can feed ourselves all as artists.

378
00:20:28,480 --> 00:20:30,480
So we're going to have to do something.

379
00:20:30,480 --> 00:20:33,480
And I have a bunch of different policies, including the newest one,

380
00:20:33,480 --> 00:20:35,480
which is the federal land dividend,

381
00:20:35,480 --> 00:20:38,480
which takes some of the federal land and tries to monetize it.

382
00:20:38,480 --> 00:20:41,480
But the bottom line is, however we do it, we're going to need it.

383
00:20:41,480 --> 00:20:43,480
Otherwise, people are going to riot.

384
00:20:43,480 --> 00:20:45,480
And the people that are going to riot are the Trump supporters,

385
00:20:45,480 --> 00:20:48,480
because a lot of them are some of the very first ones in line

386
00:20:48,480 --> 00:20:49,480
to not only lose their job,

387
00:20:49,480 --> 00:20:52,480
but just never be able to get another job again.

388
00:20:52,480 --> 00:20:56,480
So let's talk a little about UBI more in depth.

389
00:20:56,480 --> 00:20:59,480
Where does the money for UBI come from?

390
00:20:59,480 --> 00:21:03,480
And I want you to expand on federal land dividend as a funding source of it.

391
00:21:03,480 --> 00:21:06,480
And is there any other alternative other than UBI?

392
00:21:06,480 --> 00:21:09,480
Because some people are not very happy about UBI either.

393
00:21:09,480 --> 00:21:12,480
Real quickly, there are other alternatives.

394
00:21:12,480 --> 00:21:15,480
I mean, government can get everybody a job that they wanted,

395
00:21:15,480 --> 00:21:17,480
but it's the same sort of system.

396
00:21:17,480 --> 00:21:20,480
I guess you might be able to use some kind of blockchain technology

397
00:21:20,480 --> 00:21:22,480
to give certain types of money,

398
00:21:22,480 --> 00:21:24,480
and that could produce some kind of income.

399
00:21:24,480 --> 00:21:27,480
The other thing, I mean, there are a couple different ways of doing it,

400
00:21:27,480 --> 00:21:32,480
but the bottom line is all those are so, in my mind, not really,

401
00:21:32,480 --> 00:21:35,480
there's a negative land tax system.

402
00:21:35,480 --> 00:21:39,480
In my mind, the very simplest thing to do is to understand a very basic concept,

403
00:21:39,480 --> 00:21:45,480
which is 50% of Americans are already on some government support.

404
00:21:45,480 --> 00:21:50,480
To increase that to 100% is not as far as a lot of people think.

405
00:21:50,480 --> 00:21:53,480
It doesn't have to be a huge amount to begin with.

406
00:21:53,480 --> 00:21:56,480
It can only be something that supplements our income,

407
00:21:56,480 --> 00:21:58,480
gives people a little bit of a floor.

408
00:21:58,480 --> 00:22:01,480
But in my opinion, there's two ways to do it,

409
00:22:01,480 --> 00:22:04,480
and that's going to be to raise taxes, or you could maybe tax the robots, whatever.

410
00:22:04,480 --> 00:22:06,480
It's almost the same thing.

411
00:22:06,480 --> 00:22:10,480
Or what I would suggest doing is my federal land dividend,

412
00:22:10,480 --> 00:22:14,480
which Canada probably has the same situation, maybe even more so,

413
00:22:14,480 --> 00:22:22,480
where we have $150 trillion worth of federal land available in America right now

414
00:22:22,480 --> 00:22:24,480
that's basically untouched or unused.

415
00:22:24,480 --> 00:22:28,480
Our national debt is around $20 trillion or a little bit more.

416
00:22:28,480 --> 00:22:32,480
So we have six times the national debt of land sitting out there,

417
00:22:32,480 --> 00:22:37,480
unoccupied resources, minerals, even fisheries and things like that.

418
00:22:37,480 --> 00:22:39,480
People don't want to touch that because they call it nature.

419
00:22:39,480 --> 00:22:41,480
They want to save it for a thousand years into the future

420
00:22:41,480 --> 00:22:44,480
when their great-great-great-great-grandkids are here.

421
00:22:44,480 --> 00:22:47,480
And I understand that thinking until we got to the transhumanist age,

422
00:22:47,480 --> 00:22:52,480
when I have to ask myself is, A, will America survive beyond the next 20 or 30 years

423
00:22:52,480 --> 00:22:55,480
through a singularity? Will we even be humans?

424
00:22:55,480 --> 00:22:59,480
Will we appreciate land in the same way we do when we live in virtual reality environments

425
00:22:59,480 --> 00:23:01,480
where we're leaving planet Earth to go to other?

426
00:23:01,480 --> 00:23:04,480
There's a whole bunch of reasons that thinking a thousand years in the future

427
00:23:04,480 --> 00:23:06,480
isn't very rational anymore.

428
00:23:06,480 --> 00:23:11,480
However, we have 45 million people living in poverty in America today,

429
00:23:11,480 --> 00:23:12,480
many of them who are hungry.

430
00:23:12,480 --> 00:23:16,480
About 15 million children go to Hungary every night in America.

431
00:23:16,480 --> 00:23:22,480
This is something that we can deal with today if we took that $150 trillion worth

432
00:23:22,480 --> 00:23:25,480
of federal land and started to monetize it.

433
00:23:25,480 --> 00:23:29,480
Now, the problem with that idea is, and this is huge, just to give you an idea,

434
00:23:29,480 --> 00:23:33,480
we have 45 million unused acres in California.

435
00:23:33,480 --> 00:23:37,480
That's almost half of California is essentially unused land.

436
00:23:37,480 --> 00:23:43,480
And yes, California is beautiful and nobody wants to build a mall on Yosemite.

437
00:23:43,480 --> 00:23:45,480
I've heard all the arguments.

438
00:23:45,480 --> 00:23:49,480
But at the same time, there are so many poor people in California.

439
00:23:49,480 --> 00:23:57,480
About 40% of Californians live with an income that is less than $24,000.

440
00:23:57,480 --> 00:24:02,480
So that is a very significant problem.

441
00:24:02,480 --> 00:24:08,480
We have to essentially create some kind of income so that those people can get out of poverty.

442
00:24:08,480 --> 00:24:12,480
Well, if we monetize that land out there, that 45 million acres,

443
00:24:12,480 --> 00:24:17,480
whether it's forestry, whether it's minerals, whether it's even just tourism,

444
00:24:17,480 --> 00:24:22,480
we could start paying those 19 million Californians just in California alone,

445
00:24:22,480 --> 00:24:26,480
19 million Californians who live in poverty or who live very near the poverty line.

446
00:24:26,480 --> 00:24:31,480
$24,000 for a household is a very small amount, I have to be honest.

447
00:24:31,480 --> 00:24:34,480
I'm not sure what the Canadian dollar is like,

448
00:24:34,480 --> 00:24:41,480
but if a household in poverty in California only has $24,000 of income,

449
00:24:41,480 --> 00:24:44,480
I can't even see how they could survive anywhere near the Bay Area that I live in.

450
00:24:44,480 --> 00:24:46,480
There's no way to feed yourself on that.

451
00:24:46,480 --> 00:24:48,480
So we need to do something.

452
00:24:48,480 --> 00:24:53,480
And this system that I've devised running for governor worked really good in California,

453
00:24:53,480 --> 00:24:57,480
it can also be applied nationally and even better, it can be applied globally

454
00:24:57,480 --> 00:25:00,480
because many governments are sitting on huge untapped resources.

455
00:25:00,480 --> 00:25:03,480
And the best thing about the plan is it's bipartisan.

456
00:25:03,480 --> 00:25:07,480
I don't try to create plans that like, you know, I mean, I've heard all the things,

457
00:25:07,480 --> 00:25:09,480
give the land all back to the people, it'll be fine.

458
00:25:09,480 --> 00:25:12,480
You know, the reality is the rich people, the conservatives and whatnot,

459
00:25:12,480 --> 00:25:15,480
most of them are in charge, they run the corporations.

460
00:25:15,480 --> 00:25:18,480
But if you want to give them something so that they will say,

461
00:25:18,480 --> 00:25:20,480
you know what, a basic income makes sense,

462
00:25:20,480 --> 00:25:24,480
give them more business opportunity and just say, we just want to be covered.

463
00:25:24,480 --> 00:25:27,480
That's the system that's bipartisan that maybe you might actually be able

464
00:25:27,480 --> 00:25:30,480
to get through Congress someday between both the Democrats and the Republicans.

465
00:25:30,480 --> 00:25:33,480
So this is my way of doing that.

466
00:25:33,480 --> 00:25:36,480
Have you had any conversation with members of either of the parties

467
00:25:36,480 --> 00:25:39,480
about your approach to this problem?

468
00:25:39,480 --> 00:25:42,480
And have you found any kind of alliance in either of the parties?

469
00:25:42,480 --> 00:25:47,480
And if so, which party you found to be more in line with what you're talking about?

470
00:25:47,480 --> 00:25:49,480
Well, it's very tough.

471
00:25:49,480 --> 00:25:51,480
The answer, the short answer is no.

472
00:25:51,480 --> 00:25:52,480
The Democrats...

473
00:25:52,480 --> 00:25:55,480
No, you haven't talked to them or you haven't found any alliance?

474
00:25:55,480 --> 00:25:58,480
Well, I've tried and haven't found any alliances.

475
00:25:58,480 --> 00:26:00,480
I do have friends in parties.

476
00:26:00,480 --> 00:26:02,480
They're not really necessarily that high up.

477
00:26:02,480 --> 00:26:05,480
But, you know, I wouldn't be surprised if Bernie Sanders begins to support

478
00:26:05,480 --> 00:26:08,480
a basic income of some sort coming soon,

479
00:26:08,480 --> 00:26:12,480
maybe in 2018 or certainly in 2020 if he considers another run.

480
00:26:12,480 --> 00:26:16,480
I know that there's certain kind of sympathies there.

481
00:26:16,480 --> 00:26:19,480
But has anyone actually said yea or nay? No.

482
00:26:19,480 --> 00:26:23,480
Right now, it seems the Democrats are too worried about the environmental consequences.

483
00:26:23,480 --> 00:26:26,480
And the Republicans are saying,

484
00:26:26,480 --> 00:26:30,480
well, why don't we just use the federal land and just let the country become richer?

485
00:26:30,480 --> 00:26:33,480
Do we really need to give it back to the poor?

486
00:26:33,480 --> 00:26:36,480
But the thing you have to understand about $150 trillion worth of federal land

487
00:26:36,480 --> 00:26:40,480
is that if you divide that by about 300 million Americans,

488
00:26:40,480 --> 00:26:42,480
that's a half million dollars each.

489
00:26:42,480 --> 00:26:46,480
Every single American individual basically in America should have

490
00:26:46,480 --> 00:26:49,480
approximately a half million dollar net worth.

491
00:26:49,480 --> 00:26:51,480
So this is a lot of money.

492
00:26:51,480 --> 00:26:55,480
I mean, over 50% of Americans don't have a net worth over $10,000.

493
00:26:55,480 --> 00:26:57,480
So when you talk about giving them a half million,

494
00:26:57,480 --> 00:27:01,480
you're talking about making their net worth 50 times what it is essentially.

495
00:27:01,480 --> 00:27:03,480
I mean, it's a dramatic change.

496
00:27:03,480 --> 00:27:05,480
We're talking about eliminating poverty.

497
00:27:05,480 --> 00:27:07,480
So all the parties are interested in it.

498
00:27:07,480 --> 00:27:09,480
And I've had some major things.

499
00:27:09,480 --> 00:27:13,480
I mean, now this future will have a major video out on it today or tomorrow.

500
00:27:13,480 --> 00:27:16,480
The Times of London did a big story where I was involved.

501
00:27:16,480 --> 00:27:17,480
It hasn't come out yet.

502
00:27:17,480 --> 00:27:19,480
But there's been quite a few things written about it.

503
00:27:19,480 --> 00:27:22,480
And I think it's going to continue growing.

504
00:27:22,480 --> 00:27:25,480
I was talking with HBO about it as well.

505
00:27:25,480 --> 00:27:28,480
But whether it's something that could be implemented,

506
00:27:28,480 --> 00:27:30,480
it's so tough in government.

507
00:27:30,480 --> 00:27:33,480
It takes forever to get these things through.

508
00:27:33,480 --> 00:27:35,480
Well, it's amazing to get rid of poverty.

509
00:27:35,480 --> 00:27:39,480
But the reality is that the current system in the U.S. seems to be extremely corrupt

510
00:27:39,480 --> 00:27:42,480
and extremely, as you said, religious and conservative.

511
00:27:42,480 --> 00:27:47,480
What everyday individual can do to change the system?

512
00:27:47,480 --> 00:27:49,480
Because the way I see it, the Constitution itself,

513
00:27:49,480 --> 00:27:52,480
it starts with saying, we the people, right?

514
00:27:52,480 --> 00:27:54,480
So people as this human people?

515
00:27:54,480 --> 00:27:57,480
Or are we talking about transhumans as people as well?

516
00:27:57,480 --> 00:28:00,480
So all these changes that you're following at some point

517
00:28:00,480 --> 00:28:03,480
will hit a brick wall because of the Constitution.

518
00:28:03,480 --> 00:28:09,480
So how can regular individuals, what can they do?

519
00:28:09,480 --> 00:28:12,480
And how can they approach this subject that will affect all of us

520
00:28:12,480 --> 00:28:16,480
in order to change the entire system fundamentally,

521
00:28:16,480 --> 00:28:18,480
which is absolutely needed?

522
00:28:18,480 --> 00:28:21,480
I mean, why should we be limited to a piece of document

523
00:28:21,480 --> 00:28:28,480
that's been written by feathers before discovery of electricity?

524
00:28:28,480 --> 00:28:29,480
Yes.

525
00:28:29,480 --> 00:28:32,480
No, I couldn't agree with you more.

526
00:28:32,480 --> 00:28:34,480
In my opinion, I've said this before,

527
00:28:34,480 --> 00:28:37,480
rewriting the Constitution is mandatory.

528
00:28:37,480 --> 00:28:40,480
People in the Libertarian Party get very upset when I say that,

529
00:28:40,480 --> 00:28:42,480
but I don't think they quite understand.

530
00:28:42,480 --> 00:28:45,480
Without rewriting the rules,

531
00:28:45,480 --> 00:28:47,480
the rules applied when America was a tiny nation,

532
00:28:47,480 --> 00:28:49,480
and there wasn't all this great technology.

533
00:28:49,480 --> 00:28:52,480
But now we have so many third parties, lobbyists,

534
00:28:52,480 --> 00:28:54,480
things that are creating corruption,

535
00:28:54,480 --> 00:29:00,480
I think it's absolutely imperative that we create a new system.

536
00:29:00,480 --> 00:29:02,480
It's okay to rewrite something.

537
00:29:02,480 --> 00:29:05,480
It's okay to say we can do better than we did two or 300 years ago.

538
00:29:05,480 --> 00:29:09,480
The question was asked that how do you monetize land?

539
00:29:09,480 --> 00:29:12,480
The monetizing thing is one of the most difficult questions,

540
00:29:12,480 --> 00:29:17,480
and this is where it really takes a lot of analysts and a lot of advisors

541
00:29:17,480 --> 00:29:19,480
that I'm kind of working on recruiting.

542
00:29:19,480 --> 00:29:23,480
For example, California, let's just stay with California

543
00:29:23,480 --> 00:29:24,480
as a good example right now,

544
00:29:24,480 --> 00:29:27,480
has an amazing amount of coastal land that has never been developed

545
00:29:27,480 --> 00:29:30,480
because the Coastal Commission in California is incredibly tight.

546
00:29:30,480 --> 00:29:34,480
Now, they've done a wonderful job protecting California to such a point

547
00:29:34,480 --> 00:29:36,480
that you can literally drive up and down the coast

548
00:29:36,480 --> 00:29:40,480
and not see houses for hours on end most times in many places.

549
00:29:40,480 --> 00:29:42,480
And while this is great,

550
00:29:42,480 --> 00:29:46,480
the fact of the matter is that the land overlooking the ocean

551
00:29:46,480 --> 00:29:50,480
for miles and miles and miles is worth trillions of dollars alone.

552
00:29:50,480 --> 00:29:53,480
I mean, we could take out 20%, 30% probably of the national debt

553
00:29:53,480 --> 00:29:56,480
just with the coastal land in California

554
00:29:56,480 --> 00:29:59,480
if we were to develop it and have people live there.

555
00:29:59,480 --> 00:30:01,480
But that's one way to monetize it.

556
00:30:01,480 --> 00:30:04,480
But then, of course, the environmental groups bring up other good problems.

557
00:30:04,480 --> 00:30:05,480
Okay, fine.

558
00:30:05,480 --> 00:30:08,480
In a year where California has enough water, that works fine.

559
00:30:08,480 --> 00:30:10,480
But what about the years when California has a drought?

560
00:30:10,480 --> 00:30:12,480
So it's complicated.

561
00:30:12,480 --> 00:30:15,480
It's not as easy as just say, okay, go to Exxon

562
00:30:15,480 --> 00:30:18,480
and go take over that five million acres of that forest

563
00:30:18,480 --> 00:30:20,480
and do what you want to it.

564
00:30:20,480 --> 00:30:23,480
In my leasing project, I never say...

565
00:30:23,480 --> 00:30:25,480
When I talk about monetizing federal land,

566
00:30:25,480 --> 00:30:28,480
I never want to give land away or sell it.

567
00:30:28,480 --> 00:30:30,480
I only talk about leasing land.

568
00:30:30,480 --> 00:30:32,480
So in my case, I would say to the forestry industry,

569
00:30:32,480 --> 00:30:35,480
we're going to give you five million acres of California timber,

570
00:30:35,480 --> 00:30:38,480
but in 25 years, you need to regrow it

571
00:30:38,480 --> 00:30:41,480
and return it to exactly the same state it was.

572
00:30:41,480 --> 00:30:46,480
And that's the only conditions that you can lease that land from us.

573
00:30:46,480 --> 00:30:48,480
And you're never going to own it.

574
00:30:48,480 --> 00:30:50,480
And should they default on that,

575
00:30:50,480 --> 00:30:52,480
then we would take over their companies or something like that.

576
00:30:52,480 --> 00:30:54,480
My plan only allows for leasing.

577
00:30:54,480 --> 00:30:56,480
And it also doesn't touch national parks.

578
00:30:56,480 --> 00:30:58,480
I made a comment about Yosemite earlier

579
00:30:58,480 --> 00:31:00,480
because everybody loves to joke about it when talking about this,

580
00:31:00,480 --> 00:31:02,480
but I would never touch national parks.

581
00:31:02,480 --> 00:31:06,480
Most of this land is, of course, not national parks of the federal land.

582
00:31:06,480 --> 00:31:08,480
So, you know, Nevada, for example,

583
00:31:08,480 --> 00:31:12,480
has some people say almost as many resources as Afghanistan

584
00:31:12,480 --> 00:31:14,480
when it concerns minerals.

585
00:31:14,480 --> 00:31:16,480
Now, we've been fighting trillion-dollar war in Afghanistan

586
00:31:16,480 --> 00:31:19,480
for a long time or at least, you know, protecting our interests.

587
00:31:19,480 --> 00:31:22,480
And you can say it's for the people, and I wish it was,

588
00:31:22,480 --> 00:31:24,480
but I don't really believe it is.

589
00:31:24,480 --> 00:31:26,480
I think it's for the mineral rights.

590
00:31:26,480 --> 00:31:31,480
Nevada is about 96% unoccupied, meaning most of the land is just empty,

591
00:31:31,480 --> 00:31:33,480
and we have huge mineral resources.

592
00:31:33,480 --> 00:31:36,480
When is the American government going to take those resources

593
00:31:36,480 --> 00:31:40,480
and use them for something that is actually applicable in today's world,

594
00:31:40,480 --> 00:31:42,480
especially fighting poverty?

595
00:31:42,480 --> 00:31:44,480
I mean, do they really think we're going to be sitting here

596
00:31:44,480 --> 00:31:46,480
in human flesh in 100 years?

597
00:31:46,480 --> 00:31:50,480
No, man, we're going to be something probably very different in 100 years.

598
00:31:50,480 --> 00:31:52,480
We have people starting to, to some extent,

599
00:31:52,480 --> 00:31:54,480
merge with machines, driverless cars.

600
00:31:54,480 --> 00:31:56,480
As soon as we're going to come five, 10 years,

601
00:31:56,480 --> 00:31:58,480
a bionic arm is going to be better than an arm of flesh.

602
00:31:58,480 --> 00:32:01,480
And, of course, Elon Musk is working on the neural lace

603
00:32:01,480 --> 00:32:04,480
along with other people, too, like the company colonel.

604
00:32:04,480 --> 00:32:08,480
The age of machines and merging with them is upon us.

605
00:32:08,480 --> 00:32:12,480
In 15 or 20 years, I don't expect really to be that human anymore.

606
00:32:12,480 --> 00:32:16,480
And what I'm trying to say is holding onto resources that we have

607
00:32:16,480 --> 00:32:18,480
and not just trying to give them to the highest bidder,

608
00:32:18,480 --> 00:32:20,480
at least in a leasing form, is crazy.

609
00:32:20,480 --> 00:32:22,480
And we're going to have nanotechnology,

610
00:32:22,480 --> 00:32:24,480
and we're going to have genetic engineering,

611
00:32:24,480 --> 00:32:26,480
we're going to have bioengineering,

612
00:32:26,480 --> 00:32:29,480
this great idea that you can control the weather and control nature.

613
00:32:29,480 --> 00:32:32,480
You know, China is already experimenting with controlling their weather,

614
00:32:32,480 --> 00:32:35,480
seeding the clouds with things so they can, you know,

615
00:32:35,480 --> 00:32:38,480
you can make rainstorms in Los Angeles when you need rain.

616
00:32:38,480 --> 00:32:40,480
The point is this is all right here.

617
00:32:40,480 --> 00:32:43,480
It's either happening or coming in the next five or 10 or 15 years.

618
00:32:43,480 --> 00:32:47,480
To sit on resources for some thousand-year future is insane to me.

619
00:32:47,480 --> 00:32:50,480
We have people that are hungry.

620
00:32:50,480 --> 00:32:52,480
We have people that have no education.

621
00:32:52,480 --> 00:32:54,480
We have people that have no health care.

622
00:32:54,480 --> 00:32:56,480
And they need these resources now.

623
00:32:56,480 --> 00:32:58,480
And honestly, it fundamentally belongs to them.

624
00:32:58,480 --> 00:32:59,480
It belongs to the people.

625
00:32:59,480 --> 00:33:02,480
So however we monetize it, we should monetize it.

626
00:33:02,480 --> 00:33:05,480
And, you know, I don't want to say let it be a free-for-all,

627
00:33:05,480 --> 00:33:07,480
because I don't want to ruin the Earth.

628
00:33:07,480 --> 00:33:11,480
I love the pristine beauty of the Earth, and I want to return to what it is.

629
00:33:11,480 --> 00:33:14,480
But I also don't want to see hungry children.

630
00:33:14,480 --> 00:33:16,480
That's unacceptable in America and elsewhere.

631
00:33:16,480 --> 00:33:20,480
And you see this monetization being done by the states,

632
00:33:20,480 --> 00:33:23,480
not the federal government, right?

633
00:33:23,480 --> 00:33:26,480
I think at first it would be best done by the states.

634
00:33:26,480 --> 00:33:29,480
I think states would have to decide if that's something that they want to do.

635
00:33:29,480 --> 00:33:33,480
But let's, you know, I think the strange thing here is that it's really only

636
00:33:33,480 --> 00:33:39,480
the western part of the United States that has massive amounts of federal resources.

637
00:33:39,480 --> 00:33:42,480
So at some point, it was a good experiment in California.

638
00:33:42,480 --> 00:33:44,480
It's an easy experiment.

639
00:33:44,480 --> 00:33:46,480
It's pretty certain to work here.

640
00:33:46,480 --> 00:33:49,480
It wouldn't work in Massachusetts or something or New York,

641
00:33:49,480 --> 00:33:51,480
because it doesn't have that many resources.

642
00:33:51,480 --> 00:33:54,480
And at some point, if you want to take this on a national level,

643
00:33:54,480 --> 00:33:58,480
which I think would be very important, then you would, you know,

644
00:33:58,480 --> 00:34:01,480
California would have to pay its share to the federal government.

645
00:34:01,480 --> 00:34:04,480
And that doesn't sit well as a California governor.

646
00:34:04,480 --> 00:34:07,480
But, you know, I'm also running on a national platform.

647
00:34:07,480 --> 00:34:09,480
I plan to run for the presidency again.

648
00:34:09,480 --> 00:34:13,480
I'm not sure when, but, you know, this will be a significant platform of mine.

649
00:34:13,480 --> 00:34:15,480
We are facing this age of automation.

650
00:34:15,480 --> 00:34:17,480
It's not going away.

651
00:34:17,480 --> 00:34:19,480
This is the question of our time.

652
00:34:19,480 --> 00:34:23,480
And I can tell you that if 30 or 40 percent of the workforce becomes unemployed

653
00:34:23,480 --> 00:34:26,480
and we can't pay them, they're going to pick up their guns and riot.

654
00:34:26,480 --> 00:34:31,480
And this could be the dystopia that, you know, I don't know, whoever was creating.

655
00:34:31,480 --> 00:34:32,480
But I don't want to see that.

656
00:34:32,480 --> 00:34:34,480
I don't want to be responsible for that.

657
00:34:34,480 --> 00:34:35,480
Right.

658
00:34:35,480 --> 00:34:39,480
I want to ask you about what are your plans for security,

659
00:34:39,480 --> 00:34:41,480
national security and cybersecurity?

660
00:34:41,480 --> 00:34:46,480
I mentioned briefly that one of the suggestions that you had was to chip

661
00:34:46,480 --> 00:34:48,480
the Syrian refugees that are coming.

662
00:34:48,480 --> 00:34:52,480
The reality is that we're dealing with terrorism on a daily basis.

663
00:34:52,480 --> 00:35:00,480
And it seems like a portion of the West being the far-left regressive liberals,

664
00:35:00,480 --> 00:35:04,480
whatever you want to call them, they're not even acknowledging the real problem.

665
00:35:04,480 --> 00:35:06,480
Are you acknowledging the real problem?

666
00:35:06,480 --> 00:35:11,480
And what are the solutions to deal with security based on the subject of terror

667
00:35:11,480 --> 00:35:13,480
and cybersecurity?

668
00:35:13,480 --> 00:35:14,480
Sure.

669
00:35:14,480 --> 00:35:18,480
And let me just clarify real quickly about the Syrian refugee chipping.

670
00:35:18,480 --> 00:35:21,480
I'm a former war zone journalist who has been to war zones.

671
00:35:21,480 --> 00:35:24,480
And I didn't say that because I actually wanted to chip refugees.

672
00:35:24,480 --> 00:35:27,480
I actually wouldn't do that if I had an open say.

673
00:35:27,480 --> 00:35:30,480
I would just let a lot of people in and not say anything

674
00:35:30,480 --> 00:35:33,480
because I have a kind of an open border policy.

675
00:35:33,480 --> 00:35:35,480
But my solution was bipartisan.

676
00:35:35,480 --> 00:35:38,480
I was saying, you know, neither the Democrats nor the conservatives

677
00:35:38,480 --> 00:35:41,480
want these people in, but is there any set of circumstances

678
00:35:41,480 --> 00:35:43,480
where they would want them in?

679
00:35:43,480 --> 00:35:46,480
And let's say chipping was a way we can monitor them.

680
00:35:46,480 --> 00:35:50,480
Well, now you're solving a humanitarian crisis while resting with a lot more

681
00:35:50,480 --> 00:35:53,480
security because you can follow these people through a central mainframe.

682
00:35:53,480 --> 00:35:56,480
And that was really that idea about chipping Syrian refugees.

683
00:35:56,480 --> 00:35:58,480
It wasn't something that I wanted to do.

684
00:35:58,480 --> 00:36:01,480
What I want to do is having been to war zones, seeing, you know,

685
00:36:01,480 --> 00:36:05,480
let's say 300,000 people have already died.

686
00:36:05,480 --> 00:36:07,480
What's important to me is saving lives.

687
00:36:07,480 --> 00:36:09,480
You know, as a transhumanist and a longevity activist,

688
00:36:09,480 --> 00:36:12,480
I don't believe in letting lives go.

689
00:36:12,480 --> 00:36:17,480
And there are methods, and those methods might seem totalitarian by nature,

690
00:36:17,480 --> 00:36:20,480
but it was not to keep them chipped forever.

691
00:36:20,480 --> 00:36:24,480
It was just like three years we let you in because your country's been destroyed

692
00:36:24,480 --> 00:36:27,480
by a dictator or whatever, and all of a sudden, you know,

693
00:36:27,480 --> 00:36:30,480
if you show you can produce and, you know, join the workforce

694
00:36:30,480 --> 00:36:33,480
or do whatever you're going to do here, then all of a sudden it's like,

695
00:36:33,480 --> 00:36:35,480
yeah, take your chip out and you're free to stay.

696
00:36:35,480 --> 00:36:38,480
And this was a humanitarian thing to save lives.

697
00:36:38,480 --> 00:36:43,480
And I broadly think that that's a good policy with immigration as well.

698
00:36:43,480 --> 00:36:47,480
I don't think that anyone should have free rein to just come into America

699
00:36:47,480 --> 00:36:49,480
because what if they don't do good things?

700
00:36:49,480 --> 00:36:53,480
However, I want to invite everyone in, and I want them to make America

701
00:36:53,480 --> 00:36:55,480
stronger and stronger and stronger.

702
00:36:55,480 --> 00:36:58,480
So what are some methods of making sure that they can do that?

703
00:36:58,480 --> 00:37:01,480
Well, there might be some technological methods like chipping

704
00:37:01,480 --> 00:37:05,480
or just heightened security or things like that that you can give immigrants here.

705
00:37:05,480 --> 00:37:09,480
I mean, let's be honest, the country was built on a strong immigrant population.

706
00:37:09,480 --> 00:37:11,480
I'm the son of an immigrant.

707
00:37:11,480 --> 00:37:17,480
And, you know, people came here wanting to live this American dream.

708
00:37:17,480 --> 00:37:22,480
I still believe broadly they do, but we just need to maybe use technology

709
00:37:22,480 --> 00:37:28,480
to make that a little bit more excessive, a little bit more so that the conservatives

710
00:37:28,480 --> 00:37:31,480
and the Democrats can swallow that without freaking out.

711
00:37:31,480 --> 00:37:35,480
And I think, you know, chipping technology is something that's great.

712
00:37:35,480 --> 00:37:37,480
I have a chip. It doesn't bother me, doesn't scare me.

713
00:37:37,480 --> 00:37:39,480
I use it for a lot of things.

714
00:37:39,480 --> 00:37:41,480
I think everyone's going to have one in the future.

715
00:37:41,480 --> 00:37:44,480
You know, what's the difference between a chip and a cell phone?

716
00:37:44,480 --> 00:37:47,480
Honestly, it's just not that big of a difference except one's tiny.

717
00:37:47,480 --> 00:37:50,480
And we're all being tracked by our cell phones already,

718
00:37:50,480 --> 00:37:52,480
whether they want to admit it or not.

719
00:37:52,480 --> 00:37:53,480
Facebook is tracking us.

720
00:37:53,480 --> 00:37:56,480
Skype is tracking this call for sure on my tablet.

721
00:37:56,480 --> 00:37:58,480
You know, all these different things are already happening.

722
00:37:58,480 --> 00:38:05,480
So I think the idea of privacy we might have to get over for the better benefit of security.

723
00:38:05,480 --> 00:38:07,480
What are we trying to hide from?

724
00:38:07,480 --> 00:38:08,480
I mean, I don't know.

725
00:38:08,480 --> 00:38:12,480
I mean, maybe it's like let everyone have as many guns as they want.

726
00:38:12,480 --> 00:38:16,480
Let everyone also be completely, you know, watch what they're doing.

727
00:38:16,480 --> 00:38:22,480
For me, I don't really understand why we're trying to retain privacy and retain rights.

728
00:38:22,480 --> 00:38:27,480
If we're going to live in a very public world with all this digital technology,

729
00:38:27,480 --> 00:38:32,480
we'd be safer to just be totally honest with ourselves and let a lot of our lives just be as it is,

730
00:38:32,480 --> 00:38:35,480
which is incredibly visible, incredibly trackable.

731
00:38:35,480 --> 00:38:40,480
And if we just allowed a bit more of that, I think life would get a lot more safe.

732
00:38:40,480 --> 00:38:43,480
And don't get me wrong, when it concerns government,

733
00:38:43,480 --> 00:38:46,480
more than ever I think President Trump should be wearing a thing

734
00:38:46,480 --> 00:38:49,480
that shows exactly where he is at every single moment.

735
00:38:49,480 --> 00:38:52,480
I think we should see all his discussions.

736
00:38:52,480 --> 00:38:56,480
Every single Congress, every single senator, every single politician should have something.

737
00:38:56,480 --> 00:39:00,480
If you want to be a public person, you should be on camera all the time.

738
00:39:00,480 --> 00:39:02,480
We should know exactly what you're doing.

739
00:39:02,480 --> 00:39:03,480
No backroom deals.

740
00:39:03,480 --> 00:39:04,480
We know you're lobbying.

741
00:39:04,480 --> 00:39:05,480
We hear that. We get you.

742
00:39:05,480 --> 00:39:09,480
This is the kind of society that I think is actually a lot more acceptable

743
00:39:09,480 --> 00:39:15,480
than the society where we all fight for our privacy and then we have bad things happen.

744
00:39:15,480 --> 00:39:21,480
Full transparency for everyone so nobody's basically missing out on it.

745
00:39:21,480 --> 00:39:26,480
Yes. And I think what people have to understand is we're moving towards a full transparent society.

746
00:39:26,480 --> 00:39:29,480
Whether we like it or not, this is happening.

747
00:39:29,480 --> 00:39:32,480
And you can fight it all you want.

748
00:39:32,480 --> 00:39:36,480
This is why as a libertarian it works very well to have a fully transparent society

749
00:39:36,480 --> 00:39:41,480
because then you have rights to everything you want to do, whatever it is you want to do.

750
00:39:41,480 --> 00:39:44,480
But you're also going to be, you know, the public can see you.

751
00:39:44,480 --> 00:39:46,480
People can know where you are.

752
00:39:46,480 --> 00:39:51,480
It sounds crazy, but it's a very libertarian-esque idea I think at the core of it.

753
00:39:51,480 --> 00:39:55,480
Yeah. It sounds very similar to what Eric Schmidt said,

754
00:39:55,480 --> 00:39:58,480
that if you're doing something that you don't want anybody else to know,

755
00:39:58,480 --> 00:40:00,480
maybe you shouldn't be doing that thing.

756
00:40:00,480 --> 00:40:02,480
I'm going to ask two more questions.

757
00:40:02,480 --> 00:40:06,480
The first one is from Luna Yeltsma.

758
00:40:06,480 --> 00:40:10,480
I hope that I haven't bastardized the name.

759
00:40:10,480 --> 00:40:17,480
He or she is asking, how do you see the concept of money and value evolve in the coming years and decades?

760
00:40:17,480 --> 00:40:23,480
And then I want to ask you because every time me and my friends are talking about policies of either of the parties,

761
00:40:23,480 --> 00:40:29,480
we get to the result that you have to follow the money and see who is funding them.

762
00:40:29,480 --> 00:40:32,480
Who is funding you?

763
00:40:32,480 --> 00:40:34,480
Are you asking me who's funding me?

764
00:40:34,480 --> 00:40:35,480
Sure.

765
00:40:35,480 --> 00:40:37,480
Well, I mean, I fund myself.

766
00:40:37,480 --> 00:40:40,480
I haven't taken donations from my governor run at all yet.

767
00:40:40,480 --> 00:40:45,480
It's entirely self-funded, your libertarian campaign and transhumanist campaign.

768
00:40:45,480 --> 00:40:48,480
Yes, so far entirely self-funded.

769
00:40:48,480 --> 00:40:52,480
We did take money for the transhumist party, but we never, this is embarrassing,

770
00:40:52,480 --> 00:40:57,480
we never even collected more than $5,000 over a two-year haul.

771
00:40:57,480 --> 00:41:04,480
The bus, though, the bus somebody we did, we had a kickstarter and that bus was for $27,000.

772
00:41:04,480 --> 00:41:08,480
But the bus was different because it paid for the bus and it paid for the food and the gas,

773
00:41:08,480 --> 00:41:12,480
the gas, for example, which was $7,000 to cross the country.

774
00:41:12,480 --> 00:41:17,480
So, yeah, nobody pays for my own political campaign, so at least not yet.

775
00:41:17,480 --> 00:41:18,480
I'd like to.

776
00:41:18,480 --> 00:41:23,480
I'm actually working on trying to see if the governor campaign can be quite different.

777
00:41:23,480 --> 00:41:26,480
I'm trying to work out managers and things like that.

778
00:41:26,480 --> 00:41:28,480
It really requires money up front.

779
00:41:28,480 --> 00:41:32,480
And then it'll be a very different question if you ask me this after I've done that.

780
00:41:32,480 --> 00:41:35,480
Because right now I can say anything I want.

781
00:41:35,480 --> 00:41:39,480
Party leadership, the libertarian party leadership came and told me already,

782
00:41:39,480 --> 00:41:42,480
be careful with the basic income, it's not our platform.

783
00:41:42,480 --> 00:41:44,480
And, you know, they warned me about it.

784
00:41:44,480 --> 00:41:49,480
But, you know, because I'm not beholden to anyone, I can kind of put those things forward.

785
00:41:49,480 --> 00:41:55,480
I do think, though, and I've said this before in my presidential run,

786
00:41:55,480 --> 00:41:59,480
I had no funding whatsoever, I just funded it myself,

787
00:41:59,480 --> 00:42:04,480
that we should either, it's okay to allow all money to go in the system,

788
00:42:04,480 --> 00:42:06,480
but if you're going to allow third-party candidates,

789
00:42:06,480 --> 00:42:12,480
maybe the government should have some kind of system that can promote some of the top third-party candidates

790
00:42:12,480 --> 00:42:15,480
to make sure that they have an equal playing field.

791
00:42:15,480 --> 00:42:21,480
It's in the best interest of the American people that the third-party candidates can be competitive

792
00:42:21,480 --> 00:42:26,480
against some of the top candidates who are working for all the corporations and getting all the lobbying money.

793
00:42:26,480 --> 00:42:29,480
And, you know, that just sounds fair to me.

794
00:42:29,480 --> 00:42:31,480
And even though I don't want government support,

795
00:42:31,480 --> 00:42:35,480
in the end of the day, if that's what makes it fair, that makes it fair.

796
00:42:35,480 --> 00:42:38,480
And if you can briefly answer Luna's question,

797
00:42:38,480 --> 00:42:43,480
how do you see the concept of money and value evolve in the coming years and decades?

798
00:42:43,480 --> 00:42:46,480
So it's very interesting watching what's happening with Bitcoin right now,

799
00:42:46,480 --> 00:42:53,480
you know, it's exploding on the market and whatnot, but whether it will continue to do so

800
00:42:53,480 --> 00:43:00,480
and become the currency of choice is a very, you know, that's a different game.

801
00:43:00,480 --> 00:43:05,480
I've often speculated, you know, what could be the real foundation of money in the future.

802
00:43:05,480 --> 00:43:11,480
I've often wondered, in fact, if DNA will end up as something like the real money of the future,

803
00:43:11,480 --> 00:43:15,480
or some kind of, maybe not DNA, maybe it's actually software or coding.

804
00:43:15,480 --> 00:43:17,480
It depends on what you're interested in.

805
00:43:17,480 --> 00:43:21,480
But the real future of money is that we're probably going to continue living underneath

806
00:43:21,480 --> 00:43:25,480
the American dollar, the whole world, for the next 10 or 20 years,

807
00:43:25,480 --> 00:43:30,480
unless some kind of electronic currency can become really powerful.

808
00:43:30,480 --> 00:43:35,480
But I think at some point, people might even try to tag the dollar to something electronic.

809
00:43:35,480 --> 00:43:37,480
And things will be so transparent,

810
00:43:37,480 --> 00:43:41,480
like Bitcoin will just transfer really into dollars and dollars into other things.

811
00:43:41,480 --> 00:43:45,480
We're not even sure that there will be one central currency.

812
00:43:45,480 --> 00:43:50,480
Value will always still be there, just very quick exchange rates.

813
00:43:50,480 --> 00:43:55,480
I have advocated for a central currency in my book and elsewhere,

814
00:43:55,480 --> 00:43:59,480
because I thought a single language and a single currency help bond people.

815
00:43:59,480 --> 00:44:02,480
But I'm not sure that that's actually ever going to happen,

816
00:44:02,480 --> 00:44:08,480
just given how fast technology changes and transfers just so instantaneous.

817
00:44:08,480 --> 00:44:11,480
It's crazy how quickly you can go get anything now.

818
00:44:11,480 --> 00:44:14,480
Right. And to conclude our conversation, Zoltan,

819
00:44:14,480 --> 00:44:18,480
then it's a proven fact that any innovation or development work

820
00:44:18,480 --> 00:44:23,480
as good as a society that adapts that development and innovation.

821
00:44:23,480 --> 00:44:26,480
How do you see us doing as a society?

822
00:44:26,480 --> 00:44:29,480
How good of a job are we doing adapting to new changes

823
00:44:29,480 --> 00:44:32,480
and educating ourselves about new changes?

824
00:44:32,480 --> 00:44:36,480
And what additional steps we can take just to catch up with the changes

825
00:44:36,480 --> 00:44:39,480
that are happening on a daily basis now?

826
00:44:39,480 --> 00:44:44,480
Yeah, we're sorry, but we're doing awful. We're terrible.

827
00:44:44,480 --> 00:44:47,480
It's amazing how backwards of a system we lived in.

828
00:44:47,480 --> 00:44:51,480
When I told you that 535 Congress members,

829
00:44:51,480 --> 00:44:53,480
nine Supreme Court justices, president, vice president,

830
00:44:53,480 --> 00:44:57,480
all believe in an afterlife, what I'm really saying is, are we kidding us?

831
00:44:57,480 --> 00:45:00,480
I mean, is this insane? This is truly insane.

832
00:45:00,480 --> 00:45:04,480
Now, if they all said, oh, well, you know, I have a broader definition of spirituality,

833
00:45:04,480 --> 00:45:08,480
I'd say fine. But we're talking like at least 95% of them would say

834
00:45:08,480 --> 00:45:12,480
something fundamental when it comes to religion or something like that.

835
00:45:12,480 --> 00:45:15,480
We live in a system that nobody wants to change

836
00:45:15,480 --> 00:45:19,480
because the power that they gathered was based on stepping on that system

837
00:45:19,480 --> 00:45:21,480
and preserving that system.

838
00:45:21,480 --> 00:45:24,480
And that's part of the reason how, you know, they got that power in the first place.

839
00:45:24,480 --> 00:45:27,480
I talk a lot about this in my book called baggage culture,

840
00:45:27,480 --> 00:45:29,480
where we carry our baggage with us everywhere.

841
00:45:29,480 --> 00:45:32,480
And sometimes the one who carries the most baggage

842
00:45:32,480 --> 00:45:34,480
actually ends up being the strongest person

843
00:45:34,480 --> 00:45:38,480
because he has the best amount of suitcases of baggage to step on.

844
00:45:38,480 --> 00:45:42,480
It's a sad story, whereas innovation, you have to struggle and fight.

845
00:45:42,480 --> 00:45:46,480
And you see someone even like me who comes into the movement with some new ideas

846
00:45:46,480 --> 00:45:50,480
even gets bashed in what's supposed to be a very progressive,

847
00:45:50,480 --> 00:45:52,480
very forward-thinking movement.

848
00:45:52,480 --> 00:45:57,480
So I'm very disappointed with how society is moving forward.

849
00:45:57,480 --> 00:46:01,480
And I wouldn't be surprised if something awful happens,

850
00:46:01,480 --> 00:46:06,480
either I'm pretty amazed right now that there hasn't been a terrible nuclear outbreak of some sort

851
00:46:06,480 --> 00:46:10,480
or whether it's a virus, something that takes out something or something else.

852
00:46:10,480 --> 00:46:15,480
You know, I mean, there are so many people out there that to me seem totally insane.

853
00:46:15,480 --> 00:46:21,480
And I'm amazed that more of them don't do bad things to harm society and harm the world.

854
00:46:21,480 --> 00:46:24,480
And I think a lot of it comes from the fact that we're not adjusting

855
00:46:24,480 --> 00:46:26,480
to how fast technology is progressing.

856
00:46:26,480 --> 00:46:29,480
And at some point, it's just going to leave us totally behind.

857
00:46:29,480 --> 00:46:33,480
You know, when inequality grows, that's a problem.

858
00:46:33,480 --> 00:46:36,480
It's growing because nobody can keep up.

859
00:46:36,480 --> 00:46:42,480
We need to make sure that all the levels of the population stay in harmony and work together.

860
00:46:42,480 --> 00:46:50,480
And that democracy is something that we don't have just because it makes sense or because it's useful.

861
00:46:50,480 --> 00:46:54,480
We have it because we don't want to face the alternative of democracy.

862
00:46:54,480 --> 00:46:58,480
And unless you've been to war zones, you forget what that alternative is like.

863
00:46:58,480 --> 00:47:02,480
That alternative is somebody comes in, rapes your wife, kills your children,

864
00:47:02,480 --> 00:47:03,480
and then buries you in the backyard.

865
00:47:03,480 --> 00:47:04,480
That's the alternative.

866
00:47:04,480 --> 00:47:07,480
I think a lot of people forget that or haven't seen that,

867
00:47:07,480 --> 00:47:10,480
especially our generation as a younger amount of Americans and Canadians

868
00:47:10,480 --> 00:47:14,480
who may not have been off to war recently.

869
00:47:14,480 --> 00:47:19,480
And with that, ladies and gentlemen, please give it up for Zoltanistan.

870
00:47:19,480 --> 00:47:21,480
Thank you.

871
00:47:21,480 --> 00:47:23,480
So...

872
00:47:27,480 --> 00:47:28,480
Oh, yeah.

873
00:47:28,480 --> 00:47:30,480
I asked Zoltan that before the first time he was.

874
00:47:30,480 --> 00:47:33,480
Let me just ask you the last question I ask everybody,

875
00:47:33,480 --> 00:47:37,480
that if you come across an intelligent alien from a different civilization,

876
00:47:37,480 --> 00:47:41,480
what would you say is the worst thing humanity has done,

877
00:47:41,480 --> 00:47:51,480
and what would you say is humanity's greatest achievement?

878
00:47:53,480 --> 00:47:57,480
Well, look, I think the greatest achievement would say would be that

879
00:47:57,480 --> 00:48:01,480
we have discovered love.

880
00:48:01,480 --> 00:48:04,480
I think love is very important in terms of democracy,

881
00:48:04,480 --> 00:48:10,480
in terms of ideologies of why we do things like come together and want to help.

882
00:48:10,480 --> 00:48:13,480
Without this mammalian idea of wanting to help one another,

883
00:48:13,480 --> 00:48:18,480
empathy and compassion, then I think we would be out to lunch.

884
00:48:18,480 --> 00:48:20,480
This is going to be one of the biggest challenges

885
00:48:20,480 --> 00:48:23,480
about teaching machines and artificial intelligence.

886
00:48:23,480 --> 00:48:27,480
How do you actually get a robot to love something and really love it,

887
00:48:27,480 --> 00:48:29,480
like want to defend it, want to give up its life for it,

888
00:48:29,480 --> 00:48:32,480
want to do some of these different things?

889
00:48:32,480 --> 00:48:41,480
I think the worst thing that we have done as a society,

890
00:48:41,480 --> 00:48:45,480
I don't mean to bash religion, but I'm going to just say,

891
00:48:45,480 --> 00:48:48,480
I think the worst thing we've done recently,

892
00:48:48,480 --> 00:48:50,480
at least in the last few millennia,

893
00:48:50,480 --> 00:48:53,480
is that we've formalized religion to such a point

894
00:48:53,480 --> 00:48:57,480
that it's now become our outlook on everything in life.

895
00:48:57,480 --> 00:48:59,480
You cannot wake up in the morning in America

896
00:48:59,480 --> 00:49:03,480
and I salute the flag under God or it's on our money.

897
00:49:03,480 --> 00:49:07,480
It's everywhere. Our biggest holidays are about Jesus.

898
00:49:07,480 --> 00:49:12,480
It's insane to me that our biggest holidays are not about scientists

899
00:49:12,480 --> 00:49:16,480
or about innovation, things that have changed people's lives.

900
00:49:16,480 --> 00:49:20,480
The guy who made IVF, now we have 4 million extra babies

901
00:49:20,480 --> 00:49:23,480
because an innovator out there said,

902
00:49:23,480 --> 00:49:26,480
you know what, we can do test tube babies, we can create more life.

903
00:49:26,480 --> 00:49:29,480
These should be the holidays that we celebrate as national holidays.

904
00:49:29,480 --> 00:49:33,480
And unfortunately, we live in a country in a western world

905
00:49:33,480 --> 00:49:38,480
so very Judeo-Christian that I worry it's been holding back innovation

906
00:49:38,480 --> 00:49:39,480
for a long time.

907
00:49:39,480 --> 00:49:42,480
It's not that it needs to be fundamentally atheist at all.

908
00:49:42,480 --> 00:49:44,480
No, I wouldn't want that either.

909
00:49:44,480 --> 00:49:47,480
But I just feel like America, like I said,

910
00:49:47,480 --> 00:49:49,480
our entire government believes in an afterlife.

911
00:49:49,480 --> 00:49:51,480
No wonder they don't care about transhumanism.

912
00:49:51,480 --> 00:49:54,480
No wonder they don't care about living far longer

913
00:49:54,480 --> 00:49:56,480
because they believe there's an afterlife out there

914
00:49:56,480 --> 00:49:59,480
and they're going to be singing with angels as soon as they die.

915
00:49:59,480 --> 00:50:26,480
You know, I don't believe that at all.

916
00:50:29,480 --> 00:50:33,480
.

